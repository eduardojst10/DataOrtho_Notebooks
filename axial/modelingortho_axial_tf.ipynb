{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataOrtho Axial TF\n",
    "\n",
    "Axial Subset Modeling Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eduardo\\miniconda3\\envs\\dataortho_env\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 2.10.0\n",
      "tfa: 0.20.0\n",
      "GPU devices:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import  Callback,ModelCheckpoint,TensorBoard, EarlyStopping # ,LearningRateScheduler - using dynamic one\n",
    "\n",
    "\n",
    "print('tf:',tf.__version__)\n",
    "print('tfa:',tfa.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        print('GPU devices: ',gpus)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vars and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resampled_dir  = 'C:/Users/Eduardo/Desktop/DataOrtho_Resampled/'\n",
    "tfrecords_dir = 'C:/Users/Eduardo/Desktop/DataOrtho_Serialized/'\n",
    "logs_dir = 'C:/Users/Eduardo/Desktop/dataortho_edu/logs/' \n",
    "\n",
    "# Cross validation vars\n",
    "fold_idx = 1\n",
    "n_folds = 5\n",
    "\n",
    "# Training parameters\n",
    "params = {'augment':True,\n",
    "          'mode': tf.estimator.ModeKeys.TRAIN, \n",
    "          'seed':42,\n",
    "          'subset':'DATASET_AXIAL',\n",
    "          'interpolation':'Linear Interpolation',\n",
    "          'normalization': 'batchnorm',#'batchnorm',\n",
    "          'total_train_samples':0, # value attributed in dataset_split\n",
    "          'total_val_samples':0,   # value attributed in dataset_split\n",
    "          'lr': 0.0001, \n",
    "          'loss':'dice+ce',\n",
    "          'dropout':0.2,\n",
    "          'batch_size':2,\n",
    "          'norm_params_minmax':None,\n",
    "          'norm_params_meanstd':None\n",
    "          }\n",
    "# Direct vars\n",
    "batch_size = 2\n",
    "seed = 42 \n",
    "\n",
    "#Number of channel for each subset\n",
    "num_channels = {'DATASET_AXIAL': 12,'DATASET_SAGITTAL':8,'DATASET_DYNAMIC':19}\n",
    "\n",
    "# Data Shapes (Before batching) \n",
    "xshape =  {'DATASET_AXIAL': (32,256, 256,1), 'DATASET_SAGITTAL': (32,256, 256,1),'DATASET_DYNAMIC': (64,256, 256,1)}\n",
    "yshape = {'DATASET_AXIAL': (32,256, 256,12), 'DATASET_SAGITTAL': (32,256, 256,8),'DATASET_DYNAMIC': (64, 256, 256, 19)}\n",
    "input_shape={'DATASET_AXIAL': (32,256, 256,1), 'DATASET_SAGITTAL': (32,256, 256,1),'DATASET_DYNAMIC': (64,256, 256,1)} \n",
    "\n",
    "\n",
    "# Test subset individuals\n",
    "test_subjects = {'DATASET_AXIAL': [5, 20, 23, 35, 47, 56, 66, 72, 77, 82, 12, 13, 39, 44, 46, 51, 64, 70]}\n",
    "\n",
    "# Landmark Subset Classes\n",
    "landmarkClasses = { 'DATASET_AXIAL':\n",
    "                       {0:'A0',\n",
    "                        1:'A1', \n",
    "                        2:'A2', \n",
    "                        3:'A3', \n",
    "                        4:'A4', \n",
    "                        5:'A5', \n",
    "                        6:'A6', \n",
    "                        7:'A7', \n",
    "                        8:'A8', \n",
    "                        9:'A9', \n",
    "                        10:'A10', \n",
    "                        11:'AB'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4D (channels dimension) Visualization \n",
    "- Help functions for Data augmentation Visualization\n",
    "- Help functions for Evaluation Visualization\n",
    "- String path refactor for Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_montage_mri_4D_channel(mri_volume,heatmaps_masks,channel, start_slice, end_slice, step=1):\n",
    "    num_landmarks = heatmaps_masks.shape[-1] \n",
    "    \n",
    "    fig, axarr = plt.subplots(1, (end_slice - start_slice) // step, figsize=(20, 5*num_landmarks))\n",
    "    \n",
    "    max_intensity_idx = np.unravel_index(np.argmax(heatmaps_masks[..., channel]), heatmaps_masks[..., channel].shape)\n",
    "    \n",
    "    print('Intensity masks: ', heatmaps_masks[max_intensity_idx[0],max_intensity_idx[1],max_intensity_idx[2], channel])\n",
    "    print('Intensity volume: ', mri_volume[max_intensity_idx[0],max_intensity_idx[1],max_intensity_idx[2], 0])\n",
    "\n",
    "    print(f\"Channel {channel} has maximum intensity at slice: {max_intensity_idx[0]}\")\n",
    "    max_intensity = np.argmax(heatmaps_masks[..., channel])\n",
    "    print('max: ', max_intensity)\n",
    "    for i, idx in enumerate(range(start_slice, end_slice, step)):\n",
    "        axarr[i].imshow(mri_volume[idx,:], cmap='gray') \n",
    "        axarr[i].imshow(heatmaps_masks[idx,:, :,channel], cmap='jet', alpha=0.5,vmin = 0, vmax=1)  # specific landmark heatmap overlay\n",
    "        axarr[i].axis('off')\n",
    "        if i == 0:\n",
    "            if channel == num_landmarks - 1:\n",
    "                axarr[i].set_ylabel(f'Background')\n",
    "            else:\n",
    "                axarr[i].set_ylabel(f'Landmark {channel + 1}')\n",
    "            \n",
    "        axarr[i].set_title(f'Slice: {idx}')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_specific_slice_4Dmask(slice_idx,channel,mri_volume, masks):\n",
    "    fig, axarr = plt.subplots(1, figsize=(16, 8))\n",
    "    axarr.imshow(mri_volume[slice_idx,:,:],cmap='gray')\n",
    "    axarr.imshow(masks[slice_idx,:, :,  channel], cmap='jet', alpha=0.5,vmin = 0, vmax=1)\n",
    "    axarr.set_title(f'Slice: {slice_idx}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#---------- Help functions for Data augmentation Visualization ----------#\n",
    "# Function to visualize a single slice\n",
    "def visualize_slice(volume_slice, mask_slice=None, cmap='gray'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(volume_slice, cmap=cmap)\n",
    "    plt.title('Volume Slice')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if mask_slice is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mask_slice, cmap=cmap)\n",
    "        plt.title('Mask Slice')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#---------- Help functions for Evaluation Visualization ----------#\n",
    "\n",
    "def visualize_learning_curves(epochs,train_loss,val_loss):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "    #plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# not needed in ubuntu\n",
    "def refactor_path(path_example):\n",
    "    return path_example.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# returns the maximum intensity for each channel slice \n",
    "def analyze_heatmaps_predictions(heatmaps_masks,subset):\n",
    "    num_channels = heatmaps_masks.shape[-1] # Number of landmarks (channels)\n",
    "    max_intensity_slices = []\n",
    "    landmarksNames = landmarkClasses[subset]\n",
    "    for channel in range(num_channels):\n",
    "        # Find the index of maximum intensity in the channel\n",
    "        max_intensity_idx = np.unravel_index(np.argmax(heatmaps_masks[..., channel]), \n",
    "                                             heatmaps_masks[..., channel].shape)\n",
    "        # Get the slice number (depth) with maximum intensity\n",
    "        slice_with_max_intensity = max_intensity_idx[0]\n",
    "\n",
    "        max_intensity_slices.append((channel, slice_with_max_intensity))\n",
    "    \n",
    "    for channel, slice_idx in max_intensity_slices:\n",
    "        print(f\"Landmark {landmarksNames[channel]} has maximum intensity at slice: {slice_idx}\")\n",
    "    #return max_intensity_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D procedures from Architecture were analysed and used as base for the following:\n",
    "\n",
    "- random_horizontal_flip()\n",
    "- random_rotate_3d() \n",
    "- random_translate_3d() : 2D only\n",
    "- blur()\n",
    "- noising()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validated**\n",
    "- Random Horizontal Flip 3D - tf.image.flip_up_down\n",
    "- Random Rotate 3D \n",
    "- Random Translate 3D\n",
    "- Blur \n",
    "- Noising\n",
    "\n",
    "**process_augmentation** - main Augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_horizontal_flip(samples, labels, threshold=0.3):\n",
    "    h_flip = tf.random.uniform([]) > threshold \n",
    "    def hflip_volume(volume):\n",
    "        return tf.image.flip_left_right(volume)\n",
    "\n",
    "    samples = tf.cond(h_flip, lambda: hflip_volume(samples), lambda: samples)\n",
    "    labels = tf.cond(h_flip, lambda: hflip_volume(labels), lambda: labels)\n",
    "    return samples, labels\n",
    "\n",
    "# rotate\n",
    "def random_rotate_3d(samples,labels,n_channels_samples,n_channels_labels,angle_range=(-0.7,0.7)):\n",
    "    angle = tf.random.uniform([], minval=angle_range[0], maxval=angle_range[1])\n",
    "    perform_augmentation = tf.random.uniform([]) > 0.2\n",
    "    samples = tf.cond(perform_augmentation, lambda: rotate_volume(samples, angle,n_channels_samples), lambda: samples)\n",
    "    labels = tf.cond(perform_augmentation, lambda: rotate_volume(labels, angle,n_channels_labels), lambda: labels)\n",
    "    return samples, labels\n",
    "\n",
    "\n",
    "def rotate_volume(volume,angle,n_channels):\n",
    "    def rotate_slice(slice):\n",
    "        # ensure the number of channels is known\n",
    "        # angle comes from higher lvl fnction\n",
    "        rotated_channels = [tfa.image.rotate(slice[:, :, c], angle) for c in range(n_channels)]\n",
    "        return tf.stack(rotated_channels, axis=-1)\n",
    "    # Apply the rotation to each slice in the volume or mask\n",
    "    rotated_volume = tf.map_fn(rotate_slice, volume, dtype=volume.dtype)\n",
    "    return rotated_volume\n",
    "\n",
    "# translate\n",
    "def random_translate_3d(samples, labels,n_slices,n_channels_samples,n_channels_labels, threshold=10):\n",
    "    perform_augmentation = tf.random.uniform([]) > 0.3 # type: ignore\n",
    "    translations = tf.random.uniform([2], minval=-threshold, maxval=threshold)\n",
    "    samples = tf.cond(perform_augmentation, lambda: translate_volume(samples, translations,n_slices,n_channels_samples), lambda: samples) \n",
    "    labels = tf.cond(perform_augmentation, lambda: translate_volume(labels, translations,n_slices,n_channels_labels), lambda: labels)\n",
    "    return samples, labels\n",
    "\n",
    "\n",
    "def translate_volume(volume, translations,n_slices, n_channels):\n",
    "    # collect the translated slices\n",
    "    translated_slices = []\n",
    "\n",
    "    # over the depth dimension and translate each 2D slice\n",
    "    for i in range(n_slices):\n",
    "        if n_channels == 1:\n",
    "            # Translate the 2D slice and keep the channel dimension as the last dimension.\n",
    "            slice_2d = volume[i, :, :,0]  # Extract the 2D slice, removed:,0.\n",
    "            translated_slice = tfa.image.translate(slice_2d, translations)\n",
    "            translated_slice = tf.expand_dims(translated_slice, axis=-1)  # Add the channel dimension back.\n",
    "        else:\n",
    "            \n",
    "            slice_3d = volume[i, :, :, :]  # Extract the 3D slice (depth,height, width, channels).\n",
    "            translated_slice = [tfa.image.translate(slice_3d[:, :, c], translations) for c in range(n_channels)]\n",
    "            translated_slice = tf.stack(translated_slice, axis=-1)\n",
    "\n",
    "        # append the translated slice to the list.\n",
    "        translated_slices.append(translated_slice)\n",
    "\n",
    "    # stack the translated slices along the depth dimension.\n",
    "    translated_volume = tf.stack(translated_slices, axis=0)\n",
    "    \n",
    "    return translated_volume\n",
    "\n",
    "def blur(samples, labels, sigma=2.0):\n",
    "    def blur_slice(slice):\n",
    "        return tfa.image.gaussian_filter2d(slice, sigma=sigma)\n",
    "    \n",
    "    perform_blurring = tf.random.uniform([]) > 0.4 # type: ignore\n",
    "    blurred_samples = tf.cond(perform_blurring,\n",
    "                              lambda: tf.map_fn(blur_slice, samples, dtype=samples.dtype),\n",
    "                              lambda: samples)\n",
    "    return blurred_samples, labels\n",
    "\n",
    "def noising(samples, labels, mean=0.0, stddev=0.01):\n",
    "    perform_noising = tf.random.uniform([]) > 0.4 # type: ignore\n",
    "    noise = tf.random.normal(shape=tf.shape(samples), mean=mean, stddev=stddev)\n",
    "    noised_samples = tf.cond(perform_noising,\n",
    "                            lambda: samples + noise,\n",
    "                            lambda: samples)\n",
    "    return noised_samples, labels\n",
    "\n",
    "def process_augmentation(samples,labels):\n",
    "    samples,labels = random_rotate_3d(samples,labels,xshape[params['subset']][-1],yshape[params['subset']][-1])\n",
    "    samples, labels = random_horizontal_flip(samples, labels)\n",
    "    samples, labels = random_translate_3d(samples, labels,xshape[params['subset']][0],xshape[params['subset']][-1],yshape[params['subset']][-1])\n",
    "    #samples, labels = zoom_3d(samples, labels) not completed\n",
    "    samples, labels = blur(samples, labels)\n",
    "    samples, labels = noising(samples, labels)\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volumes augmentation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset('C:/Users/Eduardo/Desktop/DataOrtho_Serialized/DATASET_AXIAL/1/LEFT/pd_tse_fs_tra_320_3/pd_tse_fs_tra_320_3.tfrecord')\n",
    "dataset = dataset.map(parse_tfrecord)\n",
    "\n",
    "for volume, mask in dataset.take(1):\n",
    "    print(f'Volume shape: {volume.shape}')\n",
    "    print(f'Mask shape: {mask.shape}')\n",
    "# ds = load_tfr_subject_test('C:/Users/Eduardo/Desktop/DataOrtho_Serialized/DATASET_AXIAL/1/LEFT/pd_tse_fs_tra_320_3/pd_tse_fs_tra_320_3.tfrecord',parms['norm_params_minmax'],norm_type=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples,labels = random_rotate_3d(volume,mask,xshape[params['subset']][-1],yshape[params['subset']][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_3d_stack(heatmaps):\n",
    "    depth, height, width, _ = heatmaps.shape\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for i in range(depth):\n",
    "        # Normalize the heatmap slice to range [0, 1]\n",
    "        slice_normalized = (heatmaps[i, :, :, 0] - np.min(heatmaps[i, :, :, 0])) / (np.max(heatmaps[i, :, :, 0]) - np.min(heatmaps[i, :, :, 0]))\n",
    "        x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "        z = np.full_like(x, i)\n",
    "        \n",
    "        # Map the heatmap values to a colormap\n",
    "        colors = cm.hot(slice_normalized)\n",
    "        ax.plot_surface(x, y, z, rstride=1, cstride=1, facecolors=colors, shade=False)\n",
    "\n",
    "    #ax.set_xlabel('X axis')\n",
    "    #ax.set_ylabel('Y axis')\n",
    "    #ax.set_zlabel('Slice index')\n",
    "    ax.set_axis_off()\n",
    "    fig.patch.set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_3d_stack(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_specific_slice_4Dmask(1,0,volume, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Not Validated** - Zoom 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_3d(samples, labels, xshape, yshape, zoom_range=(0.8, 1.6)):\n",
    "    zoom_factor = tf.random.uniform([], minval=zoom_range[0], maxval=zoom_range[1])\n",
    "\n",
    "    # Define the zoom function for a single 2D slice\n",
    "    def zoom_slice(slice_2d, zoom_factor, output_size):\n",
    "        # Add a channel dimension to slice_2d if it doesn't have it\n",
    "        if len(slice_2d.shape) == 2:\n",
    "            slice_2d = tf.expand_dims(slice_2d, axis=-1)\n",
    "        \n",
    "        new_size = tf.cast(tf.cast(tf.shape(slice_2d)[:2], tf.float32) * zoom_factor, tf.int32)\n",
    "        resized_slice = tf.image.resize(slice_2d, new_size)\n",
    "        # Resize back to the output size and remove the added channel dimension if it was not originally present\n",
    "        resized_slice = tf.image.resize(resized_slice, output_size)\n",
    "        if resized_slice.shape[-1] == 1:\n",
    "            resized_slice = tf.squeeze(resized_slice, axis=-1)\n",
    "        return resized_slice\n",
    "\n",
    "    # Apply the zoom to each slice for samples\n",
    "    zoomed_samples = tf.map_fn(\n",
    "        lambda slc: zoom_slice(slc, zoom_factor, xshape[:2]), \n",
    "        samples, \n",
    "        dtype=samples.dtype\n",
    "    )\n",
    "\n",
    "    # Apply the zoom to each slice for labels, handling each channel separately\n",
    "    if labels is not None:\n",
    "        def zoom_label_slices(label_3d):\n",
    "            return tf.map_fn(\n",
    "                lambda slc: zoom_slice(slc, zoom_factor, yshape[:2]), \n",
    "                label_3d, \n",
    "                dtype=labels.dtype\n",
    "            )\n",
    "        zoomed_labels = tf.map_fn(\n",
    "            zoom_label_slices, \n",
    "            labels, \n",
    "            dtype=labels.dtype\n",
    "        )\n",
    "\n",
    "    # Set the shapes to match the target shapes\n",
    "    zoomed_samples.set_shape(xshape)\n",
    "    if labels is not None:\n",
    "        zoomed_labels.set_shape(yshape)\n",
    "\n",
    "    return zoomed_samples, zoomed_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input and processing - TFRecords format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input, Load and Normalization\n",
    " - mean and standard deviation calculation for normalization.\n",
    " - type 0 normalization with min and max\n",
    " - type 1 or else for normalization with mean and stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(serialized_sequence):\n",
    "    feature_description = {\n",
    "        'volume': tf.io.FixedLenFeature([], tf.string),\n",
    "        'mask': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    sequence = tf.io.parse_single_example(serialized_sequence,feature_description)\n",
    "    volume = tf.io.parse_tensor(sequence['volume'], out_type=tf.float32)\n",
    "    mask = tf.io.parse_tensor(sequence['mask'], out_type=tf.float32)\n",
    "\n",
    "    volume = tf.transpose(volume, perm=[1, 0, 2, 3])  \n",
    "    mask = tf.transpose(mask, perm=[1, 0, 2, 3])\n",
    "    return volume,mask\n",
    "\n",
    "def get_norm_params(tfrecords_paths, norm_type=0):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecords_paths)\n",
    "    dataset = dataset.map(parse_tfrecord,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    global_min = tf.constant(float('inf'), tf.float32)\n",
    "    global_max = tf.constant(float('-inf'), tf.float32)\n",
    "\n",
    "    for vol, _ in dataset:\n",
    "        batch_min = tf.reduce_min(vol)\n",
    "        batch_max = tf.reduce_max(vol)\n",
    "        \n",
    "        global_min = tf.reduce_min([global_min, batch_min])\n",
    "        global_max = tf.reduce_max([global_max, batch_max])\n",
    "    \n",
    "    # Convert TensorFlow tensors to numpy values before returning\n",
    "    return global_min.numpy(), global_max.numpy()\n",
    "\n",
    "\n",
    "def tf_min_max_normalize(volume, min_val, max_val):\n",
    "    return (volume - min_val) / (max_val - min_val)\n",
    "\n",
    "def tf_standard_normalize(volume, mean, std):\n",
    "    return (volume - mean) / std\n",
    "\n",
    "# load tfrecords function \n",
    "def load_tfr_dataset(tfrecords_paths, normalization_params, norm_type=0):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecords_paths)\n",
    "    dataset = dataset.map(parse_tfrecord,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if norm_type == 0:\n",
    "        _min, _max = normalization_params\n",
    "        dataset = dataset.map(lambda volume_file, mask_file: (tf_min_max_normalize(volume_file,_min,_max),mask_file))\n",
    "            \n",
    "    else:\n",
    "        mean, std = normalization_params            \n",
    "        dataset = dataset.map(\n",
    "            lambda volume_file, mask_file: (tf_standard_normalize(volume_file, mean, std), mask_file))\n",
    "    \n",
    "    volume_shape = xshape[params['subset']]\n",
    "    mask_shape = yshape[params['subset']]\n",
    "\n",
    "    dataset = dataset.map(lambda volume, mask: (tf.ensure_shape(volume, volume_shape),\n",
    "                                                tf.ensure_shape(mask, mask_shape)))\n",
    "    return dataset\n",
    "\n",
    "def parse_test_tfrecords(data_dir,test_subjects):\n",
    "    sequence_files = []\n",
    "     \n",
    "    for individual in os.listdir(data_dir):\n",
    "        if int(individual) in test_subjects:\n",
    "            individual_sequence = os.path.join(data_dir, individual)\n",
    "            for knee in os.listdir(individual_sequence):\n",
    "                    knee_sequence = os.path.join(individual_sequence, knee)\n",
    "                    for sequence in os.listdir(knee_sequence):\n",
    "                        sequence_path = os.path.join(knee_sequence, sequence)\n",
    "                        file_path = os.path.join(sequence_path, sequence + '.tfrecord')\n",
    "                        sequence_files.append(file_path)\n",
    "\n",
    "    return sequence_files\n",
    "\n",
    "def load_tfr_subject_test(subject_path,normalization_params,norm_type=0):\n",
    "    data = tf.data.TFRecordDataset(subject_path)\n",
    "    data = data.map(parse_tfrecord,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if norm_type == 0:\n",
    "        _min, _max = normalization_params\n",
    "        data = data.map(lambda volume_file, mask_file: (tf_min_max_normalize(volume_file,_min,_max),mask_file))\n",
    "            \n",
    "    else:\n",
    "        mean, std = normalization_params            \n",
    "        dataset = data.map(\n",
    "            lambda volume_file, mask_file: (tf_standard_normalize(volume_file, mean, std), mask_file))\n",
    "    \n",
    "    volume_shape = xshape[params['subset']]\n",
    "    mask_shape = yshape[params['subset']]\n",
    "    data = data.map(lambda vol, mask: (tf.ensure_shape(vol,volume_shape),\n",
    "                                       tf.ensure_shape(mask,mask_shape)))\n",
    "    # input dimension for predict call is 5D\n",
    "    data = data.batch(1)\n",
    "    return data\n",
    "\n",
    "# List of tuples, where each tuple contains the path to a volume file and its corresponding mask file.\n",
    "def create_subject_tfrpaths(subset_dir,test_subjects):\n",
    "    sequence_files = []\n",
    "\n",
    "    for individual in os.listdir(subset_dir):\n",
    "        if int(individual) not in test_subjects:\n",
    "            individual_sequences = os.path.join(subset_dir, individual) \n",
    "            for knee in os.listdir(individual_sequences):\n",
    "                knee_sequences = os.path.join(individual_sequences, knee)\n",
    "                for sequence in os.listdir(knee_sequences):\n",
    "                    sequence_file = os.path.join(knee_sequences, sequence,sequence + '.tfrecord')\n",
    "                    sequence_files.append(sequence_file)\n",
    "                         \n",
    "    return sequence_files\n",
    "\n",
    "def subset_cross_validation_tfr(subset_dir, test_subjects,fold_idx, n_folds):\n",
    "    # get all subject paths\n",
    "    tfrecords_paths = create_subject_tfrpaths(subset_dir,test_subjects)\n",
    "    # convert to numpy array for easy manipulation\n",
    "    \n",
    "    # perform cross-validation\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    folds = list(kf.split(tfrecords_paths))\n",
    "    \n",
    "    # get the current fold data\n",
    "    train_indices, val_indices = folds[fold_idx]\n",
    "    train_paths = [tfrecords_paths[i] for i in train_indices]\n",
    "    val_paths = [tfrecords_paths[i] for i in val_indices]\n",
    "\n",
    "    return train_paths, val_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tfr_fn(subject_paths,normalization_params_train,norm_type,batch_size,seed,params):\n",
    "        \"\"\" Create dataset for training \"\"\"\n",
    "        dataset = load_tfr_dataset(subject_paths,normalization_params_train,norm_type)\n",
    "\n",
    "        if params['augment']:\n",
    "            dataset = dataset.map(\n",
    "                map_func=lambda x, y: process_augmentation(x, y),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "            )\n",
    "        dataset = dataset.shuffle(100, seed)\n",
    "        dataset = dataset.batch(batch_size,\n",
    "                                drop_remainder=True)\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "def val_tfr_fn(val_paths,normalization_params,batch_size):\n",
    "    \"\"\" Create dataset for Validation \"\"\"\n",
    "    dataset = load_tfr_dataset(val_paths, normalization_params)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=False) # not\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def test_tfr_fn(test_paths,normalization_params):\n",
    "    \"\"\" Create dataset for Test\"\"\"\n",
    "    dataset = load_tfr_dataset(test_paths, normalization_params)\n",
    "    dataset = dataset.batch(1)\n",
    "\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    #print_dataset_shapes(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def validate_dataset(filenames, reader_opts=None):\n",
    "    \"\"\"\n",
    "    Attempt to iterate over every record in the supplied iterable of TFRecord filenames\n",
    "    :param filenames: iterable of filenames to read\n",
    "    :param reader_opts: (optional) tf.python_io.TFRecordOptions to use when constructing the record iterator\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    corrupts = []\n",
    "    corrupt = 0\n",
    "    for fname in filenames:\n",
    "        #print('validating ', fname)\n",
    "        record_iterator = tf.compat.v1.io.tf_record_iterator(path=fname, options=reader_opts)\n",
    "        try:\n",
    "            for _ in record_iterator:\n",
    "                i += 1\n",
    "        except Exception as e:\n",
    "            print('error in {} at record {}'.format(fname, i))\n",
    "            corrupt = 1\n",
    "            corrupts.append(fname)\n",
    "            print(e)\n",
    "    \n",
    "    return corrupt\n",
    "\n",
    "def dataset_tfr_split():\n",
    "    data_dir = os.path.join(tfrecords_dir,params['subset'])\n",
    "\n",
    "    test_paths = parse_test_tfrecords(data_dir,test_subjects[params['subset']])\n",
    "    # perform cross-validation on the paths that are valid for training,\n",
    "    # subset_cross_validation must make sure that trains_paths and val_paths return without\n",
    "    # any of the subject indicated on test_subjects list \n",
    "    train_paths, val_paths  = subset_cross_validation_tfr(data_dir, test_subjects[params['subset']], fold_idx, n_folds) #separate norm_params training and validation\n",
    "    \n",
    "    if params['norm_params_minmax']: \n",
    "        normalization_params_train = params['norm_params_minmax']\n",
    "    else:\n",
    "        normalization_params_train = get_norm_params(train_paths,0)\n",
    "    print(\"Number of training tuple paths:\", len(train_paths))\n",
    "    print(\"Number of validation tuple paths:\", len(val_paths))\n",
    "    print(\"Number of test tuple paths:\", len(test_paths))\n",
    "    print(\"Normalization parameters training:\", normalization_params_train)\n",
    "    \n",
    "    # defined for number of steps on the model fit\n",
    "    params['total_train_samples'] = len(train_paths)\n",
    "    params['total_val_samples'] =  len(val_paths)\n",
    "    train_ds = None\n",
    "    val_ds = None\n",
    "    # create the train_ds input and tensorflow.python.data.ops.map_op._MapDataset Dataset\n",
    "    if validate_dataset(train_paths) == 0:\n",
    "        train_ds = train_tfr_fn(train_paths,normalization_params_train,0,batch_size,seed,params)\n",
    "        val_ds = val_tfr_fn(val_paths,normalization_params_train,batch_size)\n",
    "    \n",
    "        return train_paths,val_paths,train_ds,val_ds, test_paths ,normalization_params_train\n",
    "    else:\n",
    "        print('Corrupted files')\n",
    "        return train_paths,val_paths,train_ds,val_ds, test_paths ,normalization_params_train\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the tfrecords dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_inspect_tfrecord(file_path):\n",
    "    feature_description = {\n",
    "        'volume': tf.io.FixedLenFeature([], tf.string),\n",
    "        'mask': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    try:\n",
    "        raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening file {file_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    for i, serialized_example in enumerate(raw_dataset):\n",
    "        try:\n",
    "            parsed_example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "            volume = tf.io.parse_tensor(parsed_example['volume'], out_type=tf.float32)\n",
    "            mask = tf.io.parse_tensor(parsed_example['mask'], out_type=tf.float32)\n",
    "            inspect_data(volume, f'Volume {i}')\n",
    "            inspect_data(mask, f'Mask {i}')\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing record {i}: {e}\")\n",
    "    \n",
    "def inspect_data(data, label):\n",
    "    print(f\"Inspecting {label}:\")\n",
    "    print(f\"Shape: {data.shape}, Dtype: {data.dtype}\")\n",
    "    print(f\"Max: {np.max(data)}, Min: {np.min(data)}\")\n",
    "    print(f\"NaNs: {np.isnan(data).sum()}, Infs: {np.isinf(data).sum()}\")\n",
    "\n",
    "def validate_tfrecord(file_path):\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    record_count = 0\n",
    "    try:\n",
    "        for raw_record in raw_dataset:\n",
    "            record_count += 1\n",
    "    except tf.errors.DataLossError as e:\n",
    "        print(f\"Error reading record {record_count}: {e}\")\n",
    "        return False\n",
    "    print(f\"All {record_count} records read successfully.\")\n",
    "    return True\n",
    "\n",
    "def is_tfrecord_corrupted(tfrecord_file):\n",
    "    try:\n",
    "        for record in tf.data.TFRecordDataset(tfrecord_file):\n",
    "            # Attempt to parse the record\n",
    "            _ = tf.train.Example.FromString(record.numpy())\n",
    "    except tf.errors.DataLossError as e:\n",
    "        print(f\"DataLossError encountered: {e}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt = 'C:/Users/Eduardo/Desktop/DataOrtho_Serialized/DATASET_AXIAL/1/LEFT/pd_tse_fs_tra_320_3/pd_tse_fs_tra_320_3.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Volume 0:\n",
      "Shape: (256, 32, 256, 1), Dtype: <dtype: 'float32'>\n",
      "Max: 1034.109375, Min: 0.0\n",
      "NaNs: 0, Infs: 0\n",
      "Inspecting Mask 0:\n",
      "Shape: (256, 32, 256, 12), Dtype: <dtype: 'float32'>\n",
      "Max: 1.0, Min: 0.0\n",
      "NaNs: 0, Infs: 0\n"
     ]
    }
   ],
   "source": [
    "parse_and_inspect_tfrecord(corrupt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Layers\n",
    "\n",
    "Methods based on basic 3D U-Net architecture [https://catalog.ngc.nvidia.com/orgs/nvidia/resources/unet3d_medical_for_tensorflow](https://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:lightblue\"> Lower level methods </span>\n",
    "\n",
    "Convolution, normalization and activation methods:\n",
    " - more control of the architecture\n",
    " - use of regularization (?): Kernel Initialiser: how the weights of the kernels are initially set before training begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:lightblue\"> Higher Level methods </span>\n",
    "\n",
    "Not using MaxPooling! The key difference between using strided convolutions and MaxPooling for downsampling is that strided convolutions involve learnable parameters and can learn to downsample in a more data-driven manner, whereas MaxPooling is a fixed operation that simply takes the maximum value over the pooling window.\n",
    "\n",
    "By not applying normalization or activation immediately after upsampling, you allow the model to first merge these upsampled features with the skip connection features. This can be important because the skip connections carry high-resolution spatial information from the encoder, which can be more effectively integrated with the upsampled features before any further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalization(inputs, name, mode):\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    if name == 'instancenorm':\n",
    "        return tf.keras.layers.LayerNormalization(\n",
    "            axis=[1, 2, 3],  # Normalizing across the spatial dimensions\n",
    "            center=True,\n",
    "            scale=True,\n",
    "            epsilon=1e-6)(inputs)\n",
    "\n",
    "    if name == 'groupnorm':\n",
    "        return tfa.layers.GroupNormalization(\n",
    "            groups=4,\n",
    "            axis=-1,  # Channel axis\n",
    "            epsilon=1e-5)(inputs)\n",
    "\n",
    "    if name == 'batchnorm':\n",
    "        return tf.keras.layers.BatchNormalization(axis=-1, #channels index is the last one\n",
    "                                                  trainable=True,\n",
    "                                                  virtual_batch_size=None)(inputs, training=training)\n",
    "    if name == 'none':\n",
    "        return inputs\n",
    "\n",
    "    raise ValueError('Invalid normalization layer')\n",
    "\n",
    "\n",
    "def _activation(out, activation):\n",
    "    if activation == 'relu':\n",
    "        return tf.keras.layers.ReLU()(out)\n",
    "    if activation == 'leaky_relu':\n",
    "        return tf.keras.layers.LeakyReLU(alpha=0.01)(out)\n",
    "    if activation == 'sigmoid':\n",
    "        return tf.keras.layers.Activation('sigmoid')(out)\n",
    "    if activation == 'softmax':\n",
    "        return tf.keras.layers.Activation('softmax')(out)\n",
    "    if activation == 'none':\n",
    "        return out\n",
    "\n",
    "    raise ValueError(\"Unknown activation {}\".format(activation))\n",
    "\n",
    "def convolution(inputs,  \n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                normalization='batchnorm',\n",
    "                activation='relu',\n",
    "                transpose=False):\n",
    "\n",
    "    if transpose:\n",
    "        conv = tf.keras.layers.Conv3DTranspose\n",
    "    else:\n",
    "        conv = tf.keras.layers.Conv3D\n",
    "    regularizer = None #tf.keras.regularizers.l2(1e-5) # trying L2 Regularization\n",
    "\n",
    "    use_bias = normalization == \"none\"\n",
    "    inputs = conv(filters=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=stride,\n",
    "                  activation=None,\n",
    "                  padding='same',\n",
    "                  data_format='channels_last',\n",
    "                  kernel_initializer=tf.compat.v1.initializers.he_uniform(), # use HE with ReLU\n",
    "                  kernel_regularizer=regularizer,\n",
    "                  bias_initializer='zeros',\n",
    "                  bias_regularizer=regularizer,\n",
    "                  use_bias=use_bias)(inputs)\n",
    "    \n",
    "    # batch normalization before each activation\n",
    "    inputs = _normalization(inputs, normalization, mode)\n",
    "    return _activation(inputs, activation)\n",
    "\n",
    "\n",
    "''' Padding and Cropping (Not currently used)'''\n",
    "# if feature maps align perfectly, we dont need this method\n",
    "def dynamic_crop_and_concat(up_conv,skip_feature):\n",
    "    print('Skip feature before crop :',up_conv.shape)\n",
    "\n",
    "    crop_size = [(up_conv.shape[i+1] - skip_feature.shape[i+1]) // 2 for i in range(3)]\n",
    "    additional_crop = [(up_conv.shape[i+1] - skip_feature.shape[i+1]) % 2 for i in range(3)]\n",
    "    crop_size = [(crop_size[i], crop_size[i] + additional_crop[i]) for i in range(3)]\n",
    "    \n",
    "    # Concatenate along the feature axis\n",
    "    cropped_up_conv = tf.keras.layers.Cropping3D(cropping=crop_size)(up_conv)\n",
    "    print('INPUT SHAPE cropped to CONCATENATE:',cropped_up_conv.shape,'Skip feature to CONCATENATE:',skip_feature.shape)\n",
    "\n",
    "    return tf.keras.layers.Concatenate(axis=-1)([cropped_up_conv, skip_feature])\n",
    "\n",
    "'''Encoding'''\n",
    "# Input block\n",
    "def input_block(inputs, out_channels, normalization, mode):\n",
    "    #stride = 1 kernel_size= 3\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    return inputs\n",
    "\n",
    "# Downsample with Residual blocks\n",
    "def downsample_Residual_block(inputs, out_channels, normalization, mode):\n",
    "    # Convolutional path\n",
    "    #the next convolution imitates the maxpooling behaviour\n",
    "    # offering additional benefits in feature learning and representation\n",
    "    conv_path = convolution(inputs, out_channels=out_channels, normalization=normalization, \n",
    "                            mode=mode, stride=2)\n",
    "    conv_path = convolution(conv_path, out_channels=out_channels, normalization=normalization, \n",
    "                            mode=mode)\n",
    "\n",
    "    # Residual path modification adds a residual connection that includes a 1x1x1 \n",
    "    # convolution with a stride of 2 to downsample the input before adding  it \n",
    "    # to the output of the convolutional layers within the block\n",
    "    # previous kernel = 3\n",
    "    residual_path = convolution(inputs, out_channels=out_channels, kernel_size=1, stride=2,\n",
    "                                normalization=normalization, mode=mode, activation='none')\n",
    "    \n",
    "    # Add the residual connection\n",
    "    out = tf.keras.layers.Add()([conv_path, residual_path])\n",
    "    out = _activation(out, 'relu')\n",
    "\n",
    "    return out\n",
    "\n",
    "# classic U-Net\n",
    "def downsample_block(inputs, out_channels, normalization, mode):\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode, stride=2)\n",
    "    print('Input shape after downsample:',inputs.shape)\n",
    "    return convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "\n",
    "\n",
    "'''Decoding'''\n",
    "\n",
    "def attention_gate(inputs,attention,inter_channel):\n",
    "    theta_x = tf.keras.layers.Conv3D(inter_channel,kernel_size=2,strides=2,padding='same')(inputs)\n",
    "    phi_g = tf.keras.layers.Conv3D(inter_channel, kernel_size=1, padding='same')(attention)\n",
    "\n",
    "    concat_xg = tf.keras.layers.Add()([theta_x, phi_g])\n",
    "    act_xg = tf.keras.layers.Activation('relu')(concat_xg)\n",
    "    psi = tf.keras.layers.Conv3D(1, kernel_size=1, padding='same')(act_xg)\n",
    "    sigmoid_xg = tf.keras.layers.Activation('sigmoid')(psi)\n",
    "    \n",
    "    upsample_psi = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(sigmoid_xg)\n",
    "    scale_attention = tf.keras.layers.Multiply()([upsample_psi, inputs])\n",
    "\n",
    "    return scale_attention\n",
    "\n",
    "# Upsample with attention gates\n",
    "def upsample_attention_block(inputs, skip_connection, out_channels, normalization, mode):\n",
    "    # attention gate where we give special importance to features that are the most revelant\n",
    "    attention = attention_gate(skip_connection,inputs,out_channels//2)\n",
    "    inputs = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                         normalization='none', activation='none', transpose=True)\n",
    "\n",
    "    # Use dynamic crop and concat\n",
    "    #inputs = dynamic_crop_and_concat(inputs, skip_connection)\n",
    "    inputs = tf.keras.layers.Concatenate(axis=-1)([inputs, attention])\n",
    "    \n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    print('Input shape AFTER concatenate:',inputs.shape)\n",
    "    return inputs\n",
    "\n",
    "# Upsample with residual block\n",
    "def upsample_Residual_block(inputs, skip_connection, out_channels, normalization, mode, residual_kernel=1):\n",
    "    main_path = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                            normalization=normalization, activation='none', transpose=True)\n",
    "    main_path = tf.keras.layers.Concatenate(axis=-1)([main_path, skip_connection])\n",
    "    main_path = convolution(main_path, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    main_path = convolution(main_path, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "\n",
    "    # Residual path: Transposed convolution (or another upsampling technique) to match the dimensions\n",
    "    residual_path = convolution(inputs, out_channels=out_channels, kernel_size=residual_kernel, stride=2,\n",
    "                                normalization=normalization, mode=mode, activation='none', transpose=True)\n",
    "    \n",
    "\n",
    " \n",
    "    #residual_path = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(inputs)\n",
    "    #residual_path = convolution(residual_path, out_channels=out_channels, kernel_size=1, normalization=normalization, mode=mode)\n",
    "\n",
    "    # Add the residual connection\n",
    "    out = tf.keras.layers.Add()([main_path, residual_path])\n",
    "    out = _activation(out, 'relu')\n",
    "    return out\n",
    "\n",
    "# Upsample Layer with Residual block and attention gates\n",
    "def upsample_ResidualAttention_block(inputs, skip_connection,out_channels,normalization,mode):\n",
    "\n",
    "    attention = attention_gate(skip_connection,inputs,out_channels//2)\n",
    "\n",
    "    upsampled = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                         normalization='none', activation='none', transpose=True)\n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate(axis=-1)([upsampled, attention])\n",
    "\n",
    "    # Convolutional path\n",
    "    conv_path = convolution(concat, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    conv_path = convolution(conv_path, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "\n",
    "    residual_path = convolution(inputs, out_channels=out_channels, kernel_size=1, stride=2,\n",
    "                                normalization=normalization, mode=mode, activation='none', transpose=True)\n",
    "    \n",
    "    out = tf.keras.layers.Add()([conv_path, residual_path])\n",
    "    out = _activation(out, 'relu')\n",
    "    return out\n",
    "\n",
    "# normal 3D U-Net upsample block\n",
    "def upsample_block(inputs, skip_connection, out_channels, normalization, mode):\n",
    "    inputs = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                         normalization='none', activation='none', transpose=True)\n",
    "\n",
    "    inputs = tf.keras.layers.Concatenate(axis=-1)([inputs, skip_connection])\n",
    "    \n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    return inputs\n",
    "\n",
    "def output_layer(inputs, out_channels, activation):\n",
    "    return convolution(inputs, out_channels=out_channels, kernel_size=3, normalization='none', activation=activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures\n",
    "- param n_classes: Number of output channels\n",
    "- param mode: Estimator's execution mode\n",
    "- param normalization: Name of the normalization layer    \n",
    "- param features: Input features\n",
    "- return: Output of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      Simple UNet3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet3d_ubuntu(n_classes,mode,features,normalization='none'):\n",
    "\n",
    "        skip_128 = input_block(inputs=features,\n",
    "                               out_channels=32,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        skip_64 = downsample_block(inputs=skip_128,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_32 = downsample_block(inputs=skip_64,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_16 = downsample_block(inputs=skip_32,\n",
    "                                   out_channels=256,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        # bridge\n",
    "        out = downsample_block(inputs=skip_16,\n",
    "                               out_channels=320,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "        #out = tf.keras.layers.Dropout(params['dropout'])(out)\n",
    "\n",
    "\n",
    "        out = upsample_block(out, skip_16,\n",
    "                             out_channels=256,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_32,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_64,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_128,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')\n",
    "\n",
    "def unet_orig(n_classes,mode,features,normalization='none'):\n",
    "\n",
    "        skip_128 = input_block(inputs=features,\n",
    "                               out_channels=32,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        skip_64 = downsample_block(inputs=skip_128,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_32 = downsample_block(inputs=skip_64,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_16 = downsample_block(inputs=skip_32,\n",
    "                                   out_channels=256,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_8 = downsample_block(inputs=skip_16,\n",
    "                                  out_channels=320,\n",
    "                                  normalization=normalization,\n",
    "                                  mode=mode)\n",
    "\n",
    "        out = downsample_block(inputs=skip_8,\n",
    "                               out_channels=320,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_8,\n",
    "                             out_channels=320,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_16,\n",
    "                             out_channels=256,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_32,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_64,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_128,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')\n",
    "\n",
    "\n",
    "def unet3d_mod(n_classes,mode,features,normalization='none'):\n",
    "\n",
    "        skip_1 = input_block(inputs=features,\n",
    "                               out_channels=16,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        skip_2 = downsample_block(inputs=skip_1,\n",
    "                                   out_channels=32,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_3 = downsample_block(inputs=skip_2,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_4 = downsample_block(inputs=skip_3,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # bridge\n",
    "        out = downsample_block(inputs=skip_4,\n",
    "                               out_channels=512,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        out = tf.keras.layers.Dropout(params['dropout'])(out)\n",
    "\n",
    "        out = upsample_block(out, skip_4,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_3,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_2,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_1,\n",
    "                             out_channels=16,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The features (input volumes) are represented as 5D tensor with the shape \n",
    "**[batch_size, depth, height, width, channels]**. Since medical volumes are often single-channel (grayscale), this last dimension might be 1.\n",
    "\n",
    "- The labels (masks), being a multi-class segmentation where each channel represents a different class, the channels dimension typically is the last dimension. So the masks are shaped as **[batch_size, depth, height, width, channels]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    Residual 3D U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unet3d(n_classes, mode, features, normalization='batchnorm'):\n",
    "    skip_connections = []\n",
    "    out_channels_sequence = [16,32,64,128]\n",
    "\n",
    "    # input block\n",
    "    features = input_block(inputs=features,\n",
    "                           out_channels=out_channels_sequence[0],\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    skip_connections.append(features)\n",
    "    \n",
    "    # downsampling blocks\n",
    "    for out_channels in out_channels_sequence[1:]:  # first one used on the input_block\n",
    "        features = downsample_Residual_block(inputs=features,\n",
    "                                             out_channels=out_channels,\n",
    "                                             normalization=normalization,\n",
    "                                             mode=mode)\n",
    "        skip_connections.append(features)\n",
    "    \n",
    "    # Bottom layer add residual to this one \n",
    "    out = downsample_Residual_block(inputs=features,\n",
    "                           out_channels=512,\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    \n",
    "    # upsampling blocks\n",
    "    for out_channels, skip_connection in zip(reversed(out_channels_sequence), reversed(skip_connections)):\n",
    "        out = upsample_Residual_block(inputs=out,\n",
    "                             skip_connection=skip_connection,\n",
    "                             out_channels=out_channels,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)       \n",
    "    # output layer\n",
    "    out = output_layer(out, out_channels=n_classes, activation='softmax')\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    3D U-Net with Attention Gates on Decoder path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the weights also get trained making the model pay more attention to relevant regions. It adds weights to voxels based on the relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttUnet3dFirst(n_classes, mode, features, normalization='batchnorm'):\n",
    "    skip_connections = []\n",
    "    out_channels_sequence = [16,32,64,128]\n",
    "\n",
    "    # input block\n",
    "    features = input_block(inputs=features,\n",
    "                           out_channels=out_channels_sequence[0],\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    skip_connections.append(features)\n",
    "    \n",
    "    # downsampling blocks\n",
    "    for out_channels in out_channels_sequence[1:]:  # first one used on the input_block\n",
    "        features = downsample_block(inputs=features,\n",
    "                                             out_channels=out_channels,\n",
    "                                             normalization=normalization,\n",
    "                                             mode=mode)\n",
    "        #features = tf.keras.layers.Dropout(params['dropout'])(features, training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "        skip_connections.append(features)\n",
    "    \n",
    "    # Bottom layer add residual to this one \n",
    "    bottleneck = downsample_block(inputs=features,\n",
    "                           out_channels= 512,\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    \n",
    "    # upsampling blocks with attention mechanioms: attention gates\n",
    "    for out_channels, skip_connection in zip(reversed(out_channels_sequence), reversed(skip_connections)):\n",
    "        bottleneck = upsample_attention_block(inputs=bottleneck, skip_connection=skip_connection, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    \n",
    "    # Output layer\n",
    "    output = output_layer(bottleneck, out_channels=n_classes, activation='softmax')\n",
    "    return output\n",
    "\n",
    "def AttUnet3d(n_classes, mode, features, normalization):\n",
    "        skip_1 = input_block(inputs=features,\n",
    "                               out_channels=16,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "        #skip_64\n",
    "        skip_2 = downsample_block(inputs=skip_1,\n",
    "                                   out_channels=32,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_32\n",
    "        skip_3 = downsample_block(inputs=skip_2,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_16\n",
    "        skip_4 = downsample_block(inputs=skip_3,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        # bridge\n",
    "        out = downsample_block(inputs=skip_4,\n",
    "                               out_channels=512,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        out = tf.keras.layers.Dropout(params['dropout'])(out)\n",
    "\n",
    "        out = upsample_attention_block(out, skip_4,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_attention_block(out, skip_3,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_attention_block(out, skip_2,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_attention_block(out, skip_1,\n",
    "                             out_channels=16,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    Residual Attention 3D U-Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resAtt_unet3d(n_classes, mode, features, normalization='batchnorm'):\n",
    "        #skip_128\n",
    "        skip_1 = input_block(inputs=features,\n",
    "                               out_channels=16,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "        #skip_64\n",
    "        skip_2 = downsample_Residual_block(inputs=skip_1,\n",
    "                                   out_channels=32,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_32\n",
    "        skip_3 = downsample_Residual_block(inputs=skip_2,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_16\n",
    "        skip_4 = downsample_Residual_block(inputs=skip_3,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        # bridge\n",
    "        out = downsample_Residual_block(inputs=skip_4,\n",
    "                               out_channels=320,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        out = tf.keras.layers.Dropout(params['dropout'])(out)\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_4,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_3,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_2,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_1,\n",
    "                             out_channels=16,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Metrics for Landmark Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Categorical Loss entropy: perhaps good on 2D problems. \n",
    "- Dice Similarity Coefficient: Commonly used for segmentation tasks, it measures the spatial overlap between predicted and ground truth landmarks.\n",
    "- Mean Squared Error (MSE) between predicted and ground truth heatmaps can be used (Heatmap-based metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loss(y_true, y_pred):\n",
    "    \"\"\" Factory method for loss functions\n",
    "\n",
    "    :param params: Dict with additional parameters\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: Loss\n",
    "    \"\"\"\n",
    "    if params['loss'] == 'dice':\n",
    "        return _dice(y_true, y_pred)\n",
    "    if params['loss'] == 'ce':\n",
    "        return _ce(y_true, y_pred)\n",
    "    if params['loss'] == 'dice+ce':\n",
    "        return tf.add(_ce(y_true, y_pred), _dice(y_true, y_pred), name=\"total_loss_ref\")\n",
    "    if params['loss'] == 'mse':\n",
    "        return _mse(y_true, y_pred)\n",
    "\n",
    "    raise ValueError('Unknown loss: {}'.format(params['loss']))\n",
    "\n",
    "\n",
    "def _ce(y_true, y_pred):\n",
    "    \"\"\" Crossentropy\n",
    "\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    return tf.reduce_sum(\n",
    "        tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tf.cast(y_true, tf.float32), y_pred), axis=[0, 1, 2, 3]),\n",
    "        name='crossentropy_loss_ref')\n",
    "\n",
    "def _mse(y_true, y_pred):\n",
    "    \"\"\" Mean Squared Error loss.\n",
    "    \n",
    "    :param y_true: Ground truth labels.\n",
    "    :param y_pred: Predicted labels.\n",
    "    :return: MSE loss.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "def _dice(y_true, y_pred):\n",
    "    \"\"\" Training dice\n",
    "\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    return tf.reduce_sum(dice_loss(predictions=y_pred, targets=y_true), name='dice_loss_ref')\n",
    "\n",
    "def eval_dice(y_true, y_pred):\n",
    "    \"\"\" Evaluation dice\n",
    "\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    return eval_dice_loss(predictions=y_pred, targets=y_true)\n",
    "\n",
    "\n",
    "def eval_dice_loss(predictions,\n",
    "              targets,\n",
    "              squared_pred=False,\n",
    "              smooth=1e-5,\n",
    "              top_smooth=0.0):\n",
    "    \"\"\" Dice\n",
    "\n",
    "    :param predictions: Predicted labels\n",
    "    :param targets: Ground truth labels\n",
    "    :param squared_pred: Square the predicate\n",
    "    :param smooth: Smooth term for denominator\n",
    "    :param top_smooth: Smooth term for numerator\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    n_len = len(predictions.shape)\n",
    "    #print('n_len:',n_len)\n",
    "    reduce_axis = list(range(1, n_len))\n",
    "    #print(reduce_axis)\n",
    "    intersection = tf.reduce_sum(targets * predictions, axis=reduce_axis)\n",
    "\n",
    "    if squared_pred:\n",
    "        targets = tf.square(targets)\n",
    "        predictions = tf.square(predictions)\n",
    "\n",
    "    y_true_o = tf.reduce_sum(targets, axis=reduce_axis)\n",
    "    y_pred_o = tf.reduce_sum(predictions, axis=reduce_axis)\n",
    "\n",
    "    denominator = y_true_o + y_pred_o \n",
    "\n",
    "    dice = (2.0 * intersection + top_smooth) / (denominator + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice, axis=0)\n",
    "\n",
    "def dice_loss(predictions,\n",
    "              targets,\n",
    "              squared_pred=False,\n",
    "              smooth=1e-5,\n",
    "              top_smooth=0.0):\n",
    "    \"\"\" Dice\n",
    "\n",
    "    :param predictions: Predicted labels\n",
    "    :param targets: Ground truth labels\n",
    "    :param squared_pred: Square the predicate\n",
    "    :param smooth: Smooth term for denominator\n",
    "    :param top_smooth: Smooth term for numerator\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    is_channels_first = False\n",
    "\n",
    "    n_len = len(predictions.get_shape())\n",
    "    reduce_axis = list(range(2, n_len)) if is_channels_first else list(range(1, n_len - 1))\n",
    "    intersection = tf.reduce_sum(targets * predictions, axis=reduce_axis)\n",
    "\n",
    "    if squared_pred:\n",
    "        targets = tf.square(targets)\n",
    "        predictions = tf.square(predictions)\n",
    "\n",
    "    y_true_o = tf.reduce_sum(targets, axis=reduce_axis)\n",
    "    y_pred_o = tf.reduce_sum(predictions, axis=reduce_axis)\n",
    "\n",
    "    denominator = y_true_o + y_pred_o\n",
    "\n",
    "    dice = (2.0 * intersection + top_smooth) / (denominator + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice, axis=0)\n",
    "\n",
    "def total_dice(predictions,\n",
    "               targets,\n",
    "               smooth=1e-5,\n",
    "               top_smooth=0.0):\n",
    "    \"\"\" Total Dice\n",
    "\n",
    "    :param predictions: Predicted labels\n",
    "    :param targets: Ground truth labels\n",
    "    :param smooth: Smooth term for denominator\n",
    "    :param top_smooth: Smooth term for numerator\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    n_len = len(predictions.get_shape())\n",
    "    reduce_axis = list(range(1, n_len-1))\n",
    "    targets = tf.reduce_sum(targets, axis=-1)\n",
    "    predictions = tf.reduce_sum(predictions, axis=-1)\n",
    "    intersection = tf.reduce_sum(targets * predictions, axis=reduce_axis)\n",
    "\n",
    "    y_true_o = tf.reduce_sum(targets, axis=reduce_axis)\n",
    "    y_pred_o = tf.reduce_sum(predictions, axis=reduce_axis)\n",
    "\n",
    "    denominator = y_true_o + y_pred_o\n",
    "\n",
    "    return tf.reduce_mean((2.0 * intersection + top_smooth) / (denominator + smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avoiding overfitting\n",
    "- early stopping when validation accuracy no longer drops for a number of epochs\n",
    "- record session to be available on tensorboard. **cd into log directory and <: tensorboard --logdir (logs/path if not in lod directoy)**\n",
    "- learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminateOnNaN(Callback):\n",
    "    # terminates training when a NaN loss is encountered.\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print('Stopping training due to NaN loss')\n",
    "                self.model.stop_training = True\n",
    "\n",
    "\n",
    "class LearningCurveSaver(Callback):\n",
    "    def __init__(self, save_path):\n",
    "        super(LearningCurveSaver, self).__init__()\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        history = self.model.history.history\n",
    "        learning_curve_data = {\n",
    "            'loss': history['loss'],\n",
    "            'val_loss': history['val_loss']\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(self.save_path, 'learning_curve.json'), 'w') as f:\n",
    "            json.dump(learning_curve_data, f, indent=4)\n",
    "\n",
    "\n",
    "def prepareCallbacks(path,log_and_model_path):\n",
    "\n",
    "    file_path = f'{log_and_model_path}/{path}/cp.ckpt'\n",
    "    \n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath= file_path, \n",
    "                                monitor = 'val_loss',\n",
    "                                verbose=1, \n",
    "                                save_weights_only=True,\n",
    "                                save_best_only=True)\n",
    "\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor='val_loss', min_delta = 0.0001,\n",
    "                                patience = 12, # aumentar \n",
    "                                verbose = 1)\n",
    "\n",
    "    tbCallBack = TensorBoard(log_dir=f'{log_and_model_path}/{path}_log', \n",
    "                            histogram_freq=0, \n",
    "                            write_graph=True, \n",
    "                            write_images=True,\n",
    "                            update_freq='epoch')\n",
    "\n",
    "    # reducing \n",
    "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                  monitor='val_loss', factor=0.2, patience=6, min_lr=1e-6) #aumentar patience\n",
    "    \n",
    "    # nan loss values monitor\n",
    "    terminateNan = TerminateOnNaN()\n",
    "\n",
    "    # store loss image\n",
    "    save_lr_path = f'{log_and_model_path}/{path}'\n",
    "    learnCurve = LearningCurveSaver(save_lr_path)\n",
    "\n",
    "    return file_path, [checkpointer, earlyStopper, tbCallBack, lr_scheduler,terminateNan,learnCurve] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Fit Approach - Axial Subset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input\n",
    "\n",
    "For test data lets get first the paths that we have at our disposal, this way we can get one subject and correctly compare the ground truth with the correspondent subject.\n",
    "\n",
    "Try to use the same runned train_paths and val paths for the same model when testing different normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training tuple paths: 149\n",
      "Number of validation tuple paths: 37\n",
      "Number of test tuple paths: 48\n",
      "Normalization parameters training: (0.0, 2609.4062)\n",
      "WARNING:tensorflow:From C:\\Users\\Eduardo\\AppData\\Local\\Temp\\ipykernel_15268\\3286060820.py:46: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From c:\\Users\\Eduardo\\miniconda3\\envs\\dataortho_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "# tfrecords\n",
    "train_paths,val_paths, train_axial, val_axial,test_paths, norm_params = dataset_tfr_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (TensorSpec(shape=(2, 32, 256, 256, 1), dtype=tf.float32, name=None), TensorSpec(shape=(2, 32, 256, 256, 12), dtype=tf.float32, name=None))\n",
      "Val: (TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 32, 256, 256, 12), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print('Train:',train_axial.element_spec)\n",
    "print('Val:',val_axial.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['normalization'] = 'groupnorm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - Res_unet3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL\n",
      "Training session id: Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\n"
     ]
    }
   ],
   "source": [
    "logs_axial = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "# Define a unique path for this training session\n",
    "training_session_path = 'Sigma3/GroupNorm/residualUnet3d{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_axial)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_axial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual_unet3d input: 12 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\") True groupnorm\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_46 (Conv3D)             (None, 32, 256, 256  432         ['input_3[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_60 (GroupN  (None, 32, 256, 256  32         ['conv3d_46[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_60[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_47 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_52[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_61 (GroupN  (None, 32, 256, 256  32         ['conv3d_47[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_61[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_48 (Conv3D)             (None, 16, 128, 128  13824       ['re_lu_53[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_62 (GroupN  (None, 16, 128, 128  64         ['conv3d_48[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_62[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_49 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_54[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_63 (GroupN  (None, 16, 128, 128  64         ['conv3d_49[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_50 (Conv3D)             (None, 16, 128, 128  512         ['re_lu_53[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_63[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_64 (GroupN  (None, 16, 128, 128  64         ['conv3d_50[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 16, 128, 128  0           ['re_lu_55[0][0]',               \n",
      "                                , 32)                             'group_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 16, 128, 128  0           ['add_16[0][0]']                 \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_51 (Conv3D)             (None, 8, 64, 64, 6  55296       ['re_lu_56[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_65 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_51[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_65[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_52 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_57[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_66 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_52[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_53 (Conv3D)             (None, 8, 64, 64, 6  2048        ['re_lu_56[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_66[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_67 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_53[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 8, 64, 64, 6  0           ['re_lu_58[0][0]',               \n",
      "                                4)                                'group_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 8, 64, 64, 6  0           ['add_17[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_54 (Conv3D)             (None, 4, 32, 32, 1  221184      ['re_lu_59[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_68 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_54[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_68[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_55 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_60[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_69 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_55[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_56 (Conv3D)             (None, 4, 32, 32, 1  8192        ['re_lu_59[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_69[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_70 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_56[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 4, 32, 32, 1  0           ['re_lu_61[0][0]',               \n",
      "                                28)                               'group_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_62 (ReLU)                (None, 4, 32, 32, 1  0           ['add_18[0][0]']                 \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_57 (Conv3D)             (None, 2, 16, 16, 5  1769472     ['re_lu_62[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_71 (GroupN  (None, 2, 16, 16, 5  1024       ['conv3d_57[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_63 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_71[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_58 (Conv3D)             (None, 2, 16, 16, 5  7077888     ['re_lu_63[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_72 (GroupN  (None, 2, 16, 16, 5  1024       ['conv3d_58[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_59 (Conv3D)             (None, 2, 16, 16, 5  65536       ['re_lu_62[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_64 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_72[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_73 (GroupN  (None, 2, 16, 16, 5  1024       ['conv3d_59[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 2, 16, 16, 5  0           ['re_lu_64[0][0]',               \n",
      "                                12)                               'group_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 2, 16, 16, 5  0           ['add_19[0][0]']                 \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_16 (Conv3DTra  (None, 4, 32, 32, 1  1769472    ['re_lu_65[0][0]']               \n",
      " nspose)                        28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_74 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_transpose_16[0][0]']    \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 4, 32, 32, 2  0           ['group_normalization_74[0][0]', \n",
      "                                56)                               're_lu_62[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_60 (Conv3D)             (None, 4, 32, 32, 1  884736      ['concatenate_8[0][0]']          \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_75 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_60[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_75[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_61 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_66[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_76 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_61[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_17 (Conv3DTra  (None, 4, 32, 32, 1  65536      ['re_lu_65[0][0]']               \n",
      " nspose)                        28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_76[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_77 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_transpose_17[0][0]']    \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 4, 32, 32, 1  0           ['re_lu_67[0][0]',               \n",
      "                                28)                               'group_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 4, 32, 32, 1  0           ['add_20[0][0]']                 \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_18 (Conv3DTra  (None, 8, 64, 64, 6  221184     ['re_lu_68[0][0]']               \n",
      " nspose)                        4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_78 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_transpose_18[0][0]']    \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 8, 64, 64, 1  0           ['group_normalization_78[0][0]', \n",
      "                                28)                               're_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_62 (Conv3D)             (None, 8, 64, 64, 6  221184      ['concatenate_9[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_79 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_62[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_79[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_63 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_69[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_80 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_63[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_19 (Conv3DTra  (None, 8, 64, 64, 6  8192       ['re_lu_68[0][0]']               \n",
      " nspose)                        4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_80[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_81 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_transpose_19[0][0]']    \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 8, 64, 64, 6  0           ['re_lu_70[0][0]',               \n",
      "                                4)                                'group_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)                (None, 8, 64, 64, 6  0           ['add_21[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_20 (Conv3DTra  (None, 16, 128, 128  55296      ['re_lu_71[0][0]']               \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_82 (GroupN  (None, 16, 128, 128  64         ['conv3d_transpose_20[0][0]']    \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 16, 128, 128  0           ['group_normalization_82[0][0]', \n",
      "                                , 64)                             're_lu_56[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_64 (Conv3D)             (None, 16, 128, 128  55296       ['concatenate_10[0][0]']         \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_83 (GroupN  (None, 16, 128, 128  64         ['conv3d_64[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_83[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_65 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_72[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_84 (GroupN  (None, 16, 128, 128  64         ['conv3d_65[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_21 (Conv3DTra  (None, 16, 128, 128  2048       ['re_lu_71[0][0]']               \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_84[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_85 (GroupN  (None, 16, 128, 128  64         ['conv3d_transpose_21[0][0]']    \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 16, 128, 128  0           ['re_lu_73[0][0]',               \n",
      "                                , 32)                             'group_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)                (None, 16, 128, 128  0           ['add_22[0][0]']                 \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_22 (Conv3DTra  (None, 32, 256, 256  13824      ['re_lu_74[0][0]']               \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_86 (GroupN  (None, 32, 256, 256  32         ['conv3d_transpose_22[0][0]']    \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 32, 256, 256  0           ['group_normalization_86[0][0]', \n",
      "                                , 32)                             're_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_66 (Conv3D)             (None, 32, 256, 256  13824       ['concatenate_11[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_87 (GroupN  (None, 32, 256, 256  32         ['conv3d_66[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_87[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_67 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_75[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_88 (GroupN  (None, 32, 256, 256  32         ['conv3d_67[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_23 (Conv3DTra  (None, 32, 256, 256  512        ['re_lu_74[0][0]']               \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_88[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_89 (GroupN  (None, 32, 256, 256  32         ['conv3d_transpose_23[0][0]']    \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 32, 256, 256  0           ['re_lu_76[0][0]',               \n",
      "                                , 16)                             'group_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 32, 256, 256  0           ['add_23[0][0]']                 \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_68 (Conv3D)             (None, 32, 256, 256  5196        ['re_lu_77[0][0]']               \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 256, 256  0           ['conv3d_68[0][0]']              \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,712,124\n",
      "Trainable params: 13,712,124\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initial input features\n",
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('residual_unet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'],params['normalization'])\n",
    "output = residual_unet3d(yshape[params['subset']][-1],params['mode'],features,params['normalization'])\n",
    "res_unet_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "res_unet_model.compile(optimizer=Adam(learning_rate=params['lr']), # type: ignore\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])\n",
    "res_unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SESSION ID: Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41 groupnorm\n",
      "Epoch 1/90\n",
      "      6/Unknown - 56s 943ms/step - loss: 14.6147 - eval_dice: 0.9228WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1962s vs `on_train_batch_end` time: 0.7722s). Check your callbacks.\n",
      "     74/Unknown - 119s 936ms/step - loss: 12.2031 - eval_dice: 0.4739\n",
      "Epoch 1: val_loss improved from inf to 11.20179, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 128s 1s/step - loss: 12.2031 - eval_dice: 0.4739 - val_loss: 11.2018 - val_eval_dice: 0.1075 - lr: 1.0000e-04\n",
      "Epoch 2/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1866 - eval_dice: 0.1283\n",
      "Epoch 2: val_loss improved from 11.20179 to 11.15972, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 118s 1s/step - loss: 11.1866 - eval_dice: 0.1283 - val_loss: 11.1597 - val_eval_dice: 0.0813 - lr: 1.0000e-04\n",
      "Epoch 3/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1436 - eval_dice: 0.1066\n",
      "Epoch 3: val_loss improved from 11.15972 to 11.11967, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 113s 909ms/step - loss: 11.1436 - eval_dice: 0.1066 - val_loss: 11.1197 - val_eval_dice: 0.0600 - lr: 1.0000e-04\n",
      "Epoch 4/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1315 - eval_dice: 0.1022\n",
      "Epoch 4: val_loss improved from 11.11967 to 11.10246, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 100s 858ms/step - loss: 11.1315 - eval_dice: 0.1022 - val_loss: 11.1025 - val_eval_dice: 0.0529 - lr: 1.0000e-04\n",
      "Epoch 5/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1247 - eval_dice: 0.1058\n",
      "Epoch 5: val_loss improved from 11.10246 to 11.10137, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 100s 857ms/step - loss: 11.1247 - eval_dice: 0.1058 - val_loss: 11.1014 - val_eval_dice: 0.0475 - lr: 1.0000e-04\n",
      "Epoch 6/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1079 - eval_dice: 0.0898\n",
      "Epoch 6: val_loss did not improve from 11.10137\n",
      "74/74 [==============================] - 100s 852ms/step - loss: 11.1079 - eval_dice: 0.0898 - val_loss: 11.1175 - val_eval_dice: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 7/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1020 - eval_dice: 0.0872\n",
      "Epoch 7: val_loss did not improve from 11.10137\n",
      "74/74 [==============================] - 100s 850ms/step - loss: 11.1020 - eval_dice: 0.0872 - val_loss: 11.1142 - val_eval_dice: 0.0536 - lr: 1.0000e-04\n",
      "Epoch 8/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1158 - eval_dice: 0.1001\n",
      "Epoch 8: val_loss improved from 11.10137 to 11.06818, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 100s 866ms/step - loss: 11.1158 - eval_dice: 0.1001 - val_loss: 11.0682 - val_eval_dice: 0.0357 - lr: 1.0000e-04\n",
      "Epoch 9/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1226 - eval_dice: 0.1070\n",
      "Epoch 9: val_loss did not improve from 11.06818\n",
      "74/74 [==============================] - 102s 868ms/step - loss: 11.1226 - eval_dice: 0.1070 - val_loss: 11.1050 - val_eval_dice: 0.0477 - lr: 1.0000e-04\n",
      "Epoch 10/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1273 - eval_dice: 0.1074\n",
      "Epoch 10: val_loss did not improve from 11.06818\n",
      "74/74 [==============================] - 103s 858ms/step - loss: 11.1273 - eval_dice: 0.1074 - val_loss: 11.1094 - val_eval_dice: 0.0550 - lr: 1.0000e-04\n",
      "Epoch 11/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1222 - eval_dice: 0.1082\n",
      "Epoch 11: val_loss improved from 11.06818 to 11.05960, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 101s 848ms/step - loss: 11.1222 - eval_dice: 0.1082 - val_loss: 11.0596 - val_eval_dice: 0.0268 - lr: 1.0000e-04\n",
      "Epoch 12/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1303 - eval_dice: 0.1189\n",
      "Epoch 12: val_loss improved from 11.05960 to 11.02884, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 99s 836ms/step - loss: 11.1303 - eval_dice: 0.1189 - val_loss: 11.0288 - val_eval_dice: 0.0335 - lr: 1.0000e-04\n",
      "Epoch 13/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1193 - eval_dice: 0.1144\n",
      "Epoch 13: val_loss did not improve from 11.02884\n",
      "74/74 [==============================] - 97s 825ms/step - loss: 11.1193 - eval_dice: 0.1144 - val_loss: 11.1012 - val_eval_dice: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 14/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1176 - eval_dice: 0.1122\n",
      "Epoch 14: val_loss improved from 11.02884 to 10.96719, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 98s 843ms/step - loss: 11.1176 - eval_dice: 0.1122 - val_loss: 10.9672 - val_eval_dice: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 15/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1480 - eval_dice: 0.1225\n",
      "Epoch 15: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 99s 829ms/step - loss: 11.1480 - eval_dice: 0.1225 - val_loss: 11.0605 - val_eval_dice: 0.0291 - lr: 1.0000e-04\n",
      "Epoch 16/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1298 - eval_dice: 0.1187\n",
      "Epoch 16: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 98s 828ms/step - loss: 11.1298 - eval_dice: 0.1187 - val_loss: 11.0411 - val_eval_dice: 0.0326 - lr: 1.0000e-04\n",
      "Epoch 17/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1258 - eval_dice: 0.1133\n",
      "Epoch 17: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 98s 828ms/step - loss: 11.1258 - eval_dice: 0.1133 - val_loss: 11.0422 - val_eval_dice: 0.0392 - lr: 1.0000e-04\n",
      "Epoch 18/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1092 - eval_dice: 0.1084\n",
      "Epoch 18: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 98s 829ms/step - loss: 11.1092 - eval_dice: 0.1084 - val_loss: 11.0170 - val_eval_dice: 0.0318 - lr: 1.0000e-04\n",
      "Epoch 19/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1109 - eval_dice: 0.1099\n",
      "Epoch 19: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 99s 829ms/step - loss: 11.1109 - eval_dice: 0.1099 - val_loss: 11.0184 - val_eval_dice: 0.0374 - lr: 1.0000e-04\n",
      "Epoch 20/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1008 - eval_dice: 0.1061\n",
      "Epoch 20: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 97s 829ms/step - loss: 11.1008 - eval_dice: 0.1061 - val_loss: 11.0080 - val_eval_dice: 0.0324 - lr: 1.0000e-04\n",
      "Epoch 21/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0791 - eval_dice: 0.0972\n",
      "Epoch 21: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 98s 831ms/step - loss: 11.0791 - eval_dice: 0.0972 - val_loss: 10.9849 - val_eval_dice: 0.0250 - lr: 2.0000e-05\n",
      "Epoch 22/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0960 - eval_dice: 0.1071\n",
      "Epoch 22: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 98s 824ms/step - loss: 11.0960 - eval_dice: 0.1071 - val_loss: 10.9843 - val_eval_dice: 0.0300 - lr: 2.0000e-05\n",
      "Epoch 23/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0809 - eval_dice: 0.1024\n",
      "Epoch 23: val_loss did not improve from 10.96719\n",
      "74/74 [==============================] - 98s 830ms/step - loss: 11.0809 - eval_dice: 0.1024 - val_loss: 10.9734 - val_eval_dice: 0.0252 - lr: 2.0000e-05\n",
      "Epoch 24/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0889 - eval_dice: 0.1045\n",
      "Epoch 24: val_loss improved from 10.96719 to 10.96391, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/17.11.41\\cp.ckpt\n",
      "74/74 [==============================] - 98s 833ms/step - loss: 11.0889 - eval_dice: 0.1045 - val_loss: 10.9639 - val_eval_dice: 0.0248 - lr: 2.0000e-05\n",
      "Epoch 25/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0781 - eval_dice: 0.0974\n",
      "Epoch 25: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 98s 828ms/step - loss: 11.0781 - eval_dice: 0.0974 - val_loss: 10.9728 - val_eval_dice: 0.0285 - lr: 2.0000e-05\n",
      "Epoch 26/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0763 - eval_dice: 0.1006\n",
      "Epoch 26: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 96s 827ms/step - loss: 11.0763 - eval_dice: 0.1006 - val_loss: 11.0772 - val_eval_dice: 0.0711 - lr: 2.0000e-05\n",
      "Epoch 27/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0782 - eval_dice: 0.1000\n",
      "Epoch 27: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 98s 823ms/step - loss: 11.0782 - eval_dice: 0.1000 - val_loss: 10.9977 - val_eval_dice: 0.0441 - lr: 2.0000e-05\n",
      "Epoch 28/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0943 - eval_dice: 0.1080\n",
      "Epoch 28: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 99s 827ms/step - loss: 11.0943 - eval_dice: 0.1080 - val_loss: 10.9788 - val_eval_dice: 0.0359 - lr: 2.0000e-05\n",
      "Epoch 29/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0759 - eval_dice: 0.1032\n",
      "Epoch 29: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 99s 834ms/step - loss: 11.0759 - eval_dice: 0.1032 - val_loss: 10.9695 - val_eval_dice: 0.0256 - lr: 2.0000e-05\n",
      "Epoch 30/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0772 - eval_dice: 0.1004\n",
      "Epoch 30: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 98s 826ms/step - loss: 11.0772 - eval_dice: 0.1004 - val_loss: 10.9989 - val_eval_dice: 0.0487 - lr: 2.0000e-05\n",
      "Epoch 31/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0721 - eval_dice: 0.1003\n",
      "Epoch 31: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 99s 825ms/step - loss: 11.0721 - eval_dice: 0.1003 - val_loss: 10.9912 - val_eval_dice: 0.0444 - lr: 4.0000e-06\n",
      "Epoch 32/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0770 - eval_dice: 0.1042\n",
      "Epoch 32: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 97s 827ms/step - loss: 11.0770 - eval_dice: 0.1042 - val_loss: 10.9876 - val_eval_dice: 0.0406 - lr: 4.0000e-06\n",
      "Epoch 33/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0636 - eval_dice: 0.0965\n",
      "Epoch 33: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 98s 826ms/step - loss: 11.0636 - eval_dice: 0.0965 - val_loss: 10.9834 - val_eval_dice: 0.0385 - lr: 4.0000e-06\n",
      "Epoch 34/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0799 - eval_dice: 0.1016\n",
      "Epoch 34: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 99s 826ms/step - loss: 11.0799 - eval_dice: 0.1016 - val_loss: 10.9829 - val_eval_dice: 0.0390 - lr: 4.0000e-06\n",
      "Epoch 35/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0649 - eval_dice: 0.1010\n",
      "Epoch 35: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 98s 835ms/step - loss: 11.0649 - eval_dice: 0.1010 - val_loss: 10.9783 - val_eval_dice: 0.0357 - lr: 4.0000e-06\n",
      "Epoch 36/90\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0748 - eval_dice: 0.0997\n",
      "Epoch 36: val_loss did not improve from 10.96391\n",
      "74/74 [==============================] - 99s 829ms/step - loss: 11.0748 - eval_dice: 0.0997 - val_loss: 10.9758 - val_eval_dice: 0.0346 - lr: 4.0000e-06\n",
      "Epoch 36: early stopping\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING SESSION ID:', training_session_path, params['normalization'])\n",
    "# Fit the model\n",
    "history1 = res_unet_model.fit(\n",
    "                train_axial,\n",
    "                epochs=90,\n",
    "                validation_data=val_axial,\n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - U-Net3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL\n",
      "Training session id: Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\n"
     ]
    }
   ],
   "source": [
    "logs_axial = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "training_session_path = 'Sigma3/BatchNorm/unet3d_mod{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_axial)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_axial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet3d input: 12 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\") True\n",
      "Input shape after downsample: (None, 16, 128, 128, 32)\n",
      "Input shape after downsample: (None, 8, 64, 64, 64)\n",
      "Input shape after downsample: (None, 4, 32, 32, 128)\n",
      "Input shape after downsample: (None, 2, 16, 16, 320)\n"
     ]
    }
   ],
   "source": [
    "# Initial input features\n",
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('unet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'])\n",
    "output = unet3d_mod(yshape[params['subset']][-1],params['mode'],features,params['normalization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_280 (Conv3D)            (None, 32, 256, 256  432         ['input_10[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 32, 256, 256  64         ['conv3d_280[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_208 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_208[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_281 (Conv3D)            (None, 32, 256, 256  6912        ['re_lu_208[0][0]']              \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 32, 256, 256  64         ['conv3d_281[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_209 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_209[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_282 (Conv3D)            (None, 16, 128, 128  13824       ['re_lu_209[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 16, 128, 128  128        ['conv3d_282[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_210 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_210[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_283 (Conv3D)            (None, 16, 128, 128  27648       ['re_lu_210[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 16, 128, 128  128        ['conv3d_283[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_211 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_211[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_284 (Conv3D)            (None, 8, 64, 64, 6  55296       ['re_lu_211[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_284[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_212 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_212[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_285 (Conv3D)            (None, 8, 64, 64, 6  110592      ['re_lu_212[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_285[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_213 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_213[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_286 (Conv3D)            (None, 4, 32, 32, 1  221184      ['re_lu_213[0][0]']              \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_286[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_214 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_214[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_287 (Conv3D)            (None, 4, 32, 32, 1  442368      ['re_lu_214[0][0]']              \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_287[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_215 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_215[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_288 (Conv3D)            (None, 2, 16, 16, 3  1105920     ['re_lu_215[0][0]']              \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 2, 16, 16, 3  1280       ['conv3d_288[0][0]']             \n",
      " Normalization)                 20)                                                               \n",
      "                                                                                                  \n",
      " re_lu_216 (ReLU)               (None, 2, 16, 16, 3  0           ['batch_normalization_216[0][0]']\n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " conv3d_289 (Conv3D)            (None, 2, 16, 16, 3  2764800     ['re_lu_216[0][0]']              \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 2, 16, 16, 3  1280       ['conv3d_289[0][0]']             \n",
      " Normalization)                 20)                                                               \n",
      "                                                                                                  \n",
      " re_lu_217 (ReLU)               (None, 2, 16, 16, 3  0           ['batch_normalization_217[0][0]']\n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 2, 16, 16, 3  0           ['re_lu_217[0][0]']              \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_64 (Conv3DTra  (None, 4, 32, 32, 1  1106048    ['dropout_8[0][0]']              \n",
      " nspose)                        28)                                                               \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 4, 32, 32, 2  0           ['conv3d_transpose_64[0][0]',    \n",
      "                                56)                               're_lu_215[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_290 (Conv3D)            (None, 4, 32, 32, 1  884736      ['concatenate_32[0][0]']         \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_290[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_218 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_218[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_291 (Conv3D)            (None, 4, 32, 32, 1  442368      ['re_lu_218[0][0]']              \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_291[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_219 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_219[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_65 (Conv3DTra  (None, 8, 64, 64, 6  221248     ['re_lu_219[0][0]']              \n",
      " nspose)                        4)                                                                \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 8, 64, 64, 1  0           ['conv3d_transpose_65[0][0]',    \n",
      "                                28)                               're_lu_213[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_292 (Conv3D)            (None, 8, 64, 64, 6  221184      ['concatenate_33[0][0]']         \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_292[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_220 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_220[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_293 (Conv3D)            (None, 8, 64, 64, 6  110592      ['re_lu_220[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_293[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_221 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_221[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_66 (Conv3DTra  (None, 16, 128, 128  55328      ['re_lu_221[0][0]']              \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 16, 128, 128  0           ['conv3d_transpose_66[0][0]',    \n",
      "                                , 64)                             're_lu_211[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_294 (Conv3D)            (None, 16, 128, 128  55296       ['concatenate_34[0][0]']         \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 16, 128, 128  128        ['conv3d_294[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_222 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_222[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_295 (Conv3D)            (None, 16, 128, 128  27648       ['re_lu_222[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 16, 128, 128  128        ['conv3d_295[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_223 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_223[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_67 (Conv3DTra  (None, 32, 256, 256  13840      ['re_lu_223[0][0]']              \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 32, 256, 256  0           ['conv3d_transpose_67[0][0]',    \n",
      "                                , 32)                             're_lu_209[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_296 (Conv3D)            (None, 32, 256, 256  13824       ['concatenate_35[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 32, 256, 256  64         ['conv3d_296[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_224 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_224[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_297 (Conv3D)            (None, 32, 256, 256  6912        ['re_lu_224[0][0]']              \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 32, 256, 256  64         ['conv3d_297[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_225 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_225[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_298 (Conv3D)            (None, 32, 256, 256  5196        ['re_lu_225[0][0]']              \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 32, 256, 256  0           ['conv3d_298[0][0]']             \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,919,596\n",
      "Trainable params: 7,916,396\n",
      "Non-trainable params: 3,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet3d_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "unet3d_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])\n",
    "unet3d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session id: Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15 batchnorm\n",
      "Epoch 1/120\n",
      "      6/Unknown - 51s 2s/step - loss: 13.7435 - eval_dice: 0.8759WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3076s vs `on_train_batch_end` time: 1.2726s). Check your callbacks.\n",
      "     37/Unknown - 93s 1s/step - loss: 13.0933 - eval_dice: 0.7724\n",
      "Epoch 1: val_loss improved from inf to 12.56861, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 98s 2s/step - loss: 13.0933 - eval_dice: 0.7724 - val_loss: 12.5686 - val_eval_dice: 0.6262 - lr: 1.0000e-04\n",
      "Epoch 2/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.9012 - eval_dice: 0.4785\n",
      "Epoch 2: val_loss improved from 12.56861 to 11.67711, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 95s 1s/step - loss: 11.9012 - eval_dice: 0.4785 - val_loss: 11.6771 - val_eval_dice: 0.3423 - lr: 1.0000e-04\n",
      "Epoch 3/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.4100 - eval_dice: 0.2749\n",
      "Epoch 3: val_loss improved from 11.67711 to 11.36857, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 92s 1s/step - loss: 11.4100 - eval_dice: 0.2749 - val_loss: 11.3686 - val_eval_dice: 0.2033 - lr: 1.0000e-04\n",
      "Epoch 4/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.2634 - eval_dice: 0.1922\n",
      "Epoch 4: val_loss improved from 11.36857 to 11.28140, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 94s 1s/step - loss: 11.2634 - eval_dice: 0.1922 - val_loss: 11.2814 - val_eval_dice: 0.1556 - lr: 1.0000e-04\n",
      "Epoch 5/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.2087 - eval_dice: 0.1587\n",
      "Epoch 5: val_loss improved from 11.28140 to 11.24065, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 89s 1s/step - loss: 11.2087 - eval_dice: 0.1587 - val_loss: 11.2407 - val_eval_dice: 0.1326 - lr: 1.0000e-04\n",
      "Epoch 6/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1810 - eval_dice: 0.1466\n",
      "Epoch 6: val_loss improved from 11.24065 to 11.20834, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 92s 1s/step - loss: 11.1810 - eval_dice: 0.1466 - val_loss: 11.2083 - val_eval_dice: 0.1160 - lr: 1.0000e-04\n",
      "Epoch 7/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1642 - eval_dice: 0.1314\n",
      "Epoch 7: val_loss improved from 11.20834 to 11.18669, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 93s 1s/step - loss: 11.1642 - eval_dice: 0.1314 - val_loss: 11.1867 - val_eval_dice: 0.1050 - lr: 1.0000e-04\n",
      "Epoch 8/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1422 - eval_dice: 0.1224\n",
      "Epoch 8: val_loss improved from 11.18669 to 11.17160, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 89s 1s/step - loss: 11.1422 - eval_dice: 0.1224 - val_loss: 11.1716 - val_eval_dice: 0.1005 - lr: 1.0000e-04\n",
      "Epoch 9/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1219 - eval_dice: 0.1191\n",
      "Epoch 9: val_loss did not improve from 11.17160\n",
      "37/37 [==============================] - 95s 2s/step - loss: 11.1219 - eval_dice: 0.1191 - val_loss: 11.2163 - val_eval_dice: 0.1181 - lr: 1.0000e-04\n",
      "Epoch 10/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1101 - eval_dice: 0.1120\n",
      "Epoch 10: val_loss improved from 11.17160 to 11.14596, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 99s 2s/step - loss: 11.1101 - eval_dice: 0.1120 - val_loss: 11.1460 - val_eval_dice: 0.0860 - lr: 1.0000e-04\n",
      "Epoch 11/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0938 - eval_dice: 0.1056\n",
      "Epoch 11: val_loss improved from 11.14596 to 11.11731, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 93s 2s/step - loss: 11.0938 - eval_dice: 0.1056 - val_loss: 11.1173 - val_eval_dice: 0.0763 - lr: 1.0000e-04\n",
      "Epoch 12/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0748 - eval_dice: 0.0992\n",
      "Epoch 12: val_loss improved from 11.11731 to 11.11478, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 11.0748 - eval_dice: 0.0992 - val_loss: 11.1148 - val_eval_dice: 0.0775 - lr: 1.0000e-04\n",
      "Epoch 13/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0565 - eval_dice: 0.0959\n",
      "Epoch 13: val_loss improved from 11.11478 to 11.09230, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 97s 2s/step - loss: 11.0565 - eval_dice: 0.0959 - val_loss: 11.0923 - val_eval_dice: 0.0731 - lr: 1.0000e-04\n",
      "Epoch 14/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0383 - eval_dice: 0.0899\n",
      "Epoch 14: val_loss improved from 11.09230 to 11.07312, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 90s 1s/step - loss: 11.0383 - eval_dice: 0.0899 - val_loss: 11.0731 - val_eval_dice: 0.0654 - lr: 1.0000e-04\n",
      "Epoch 15/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0126 - eval_dice: 0.0894\n",
      "Epoch 15: val_loss improved from 11.07312 to 11.05853, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 94s 2s/step - loss: 11.0126 - eval_dice: 0.0894 - val_loss: 11.0585 - val_eval_dice: 0.0676 - lr: 1.0000e-04\n",
      "Epoch 16/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.9359 - eval_dice: 0.0902\n",
      "Epoch 16: val_loss improved from 11.05853 to 10.97137, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 98s 2s/step - loss: 10.9359 - eval_dice: 0.0902 - val_loss: 10.9714 - val_eval_dice: 0.0584 - lr: 1.0000e-04\n",
      "Epoch 17/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8721 - eval_dice: 0.0873\n",
      "Epoch 17: val_loss improved from 10.97137 to 10.90875, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 93s 1s/step - loss: 10.8721 - eval_dice: 0.0873 - val_loss: 10.9087 - val_eval_dice: 0.0483 - lr: 1.0000e-04\n",
      "Epoch 18/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8033 - eval_dice: 0.0817\n",
      "Epoch 18: val_loss did not improve from 10.90875\n",
      "37/37 [==============================] - 100s 2s/step - loss: 10.8033 - eval_dice: 0.0817 - val_loss: 10.9678 - val_eval_dice: 0.0788 - lr: 1.0000e-04\n",
      "Epoch 19/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.7777 - eval_dice: 0.0852\n",
      "Epoch 19: val_loss improved from 10.90875 to 10.87123, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 109s 2s/step - loss: 10.7777 - eval_dice: 0.0852 - val_loss: 10.8712 - val_eval_dice: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 20/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.7235 - eval_dice: 0.0804\n",
      "Epoch 20: val_loss improved from 10.87123 to 10.84428, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 104s 2s/step - loss: 10.7235 - eval_dice: 0.0804 - val_loss: 10.8443 - val_eval_dice: 0.0485 - lr: 1.0000e-04\n",
      "Epoch 21/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.6796 - eval_dice: 0.0743\n",
      "Epoch 21: val_loss improved from 10.84428 to 10.78996, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 104s 2s/step - loss: 10.6796 - eval_dice: 0.0743 - val_loss: 10.7900 - val_eval_dice: 0.0395 - lr: 1.0000e-04\n",
      "Epoch 22/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.6450 - eval_dice: 0.0788\n",
      "Epoch 22: val_loss improved from 10.78996 to 10.77523, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 106s 2s/step - loss: 10.6450 - eval_dice: 0.0788 - val_loss: 10.7752 - val_eval_dice: 0.0376 - lr: 1.0000e-04\n",
      "Epoch 23/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.5866 - eval_dice: 0.0778\n",
      "Epoch 23: val_loss improved from 10.77523 to 10.75736, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 105s 2s/step - loss: 10.5866 - eval_dice: 0.0778 - val_loss: 10.7574 - val_eval_dice: 0.0543 - lr: 1.0000e-04\n",
      "Epoch 24/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.5421 - eval_dice: 0.0751\n",
      "Epoch 24: val_loss improved from 10.75736 to 10.72862, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 105s 2s/step - loss: 10.5421 - eval_dice: 0.0751 - val_loss: 10.7286 - val_eval_dice: 0.0429 - lr: 1.0000e-04\n",
      "Epoch 25/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.4960 - eval_dice: 0.0756\n",
      "Epoch 25: val_loss improved from 10.72862 to 10.68087, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 109s 2s/step - loss: 10.4960 - eval_dice: 0.0756 - val_loss: 10.6809 - val_eval_dice: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 26/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.4371 - eval_dice: 0.0762\n",
      "Epoch 26: val_loss improved from 10.68087 to 10.64425, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 112s 2s/step - loss: 10.4371 - eval_dice: 0.0762 - val_loss: 10.6442 - val_eval_dice: 0.0325 - lr: 1.0000e-04\n",
      "Epoch 27/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.3419 - eval_dice: 0.0693\n",
      "Epoch 27: val_loss improved from 10.64425 to 10.56016, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 111s 2s/step - loss: 10.3419 - eval_dice: 0.0693 - val_loss: 10.5602 - val_eval_dice: 0.0296 - lr: 1.0000e-04\n",
      "Epoch 28/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.2062 - eval_dice: 0.0763\n",
      "Epoch 28: val_loss improved from 10.56016 to 10.46627, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 113s 2s/step - loss: 10.2062 - eval_dice: 0.0763 - val_loss: 10.4663 - val_eval_dice: 0.0395 - lr: 1.0000e-04\n",
      "Epoch 29/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0899 - eval_dice: 0.0763\n",
      "Epoch 29: val_loss improved from 10.46627 to 10.37912, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 107s 2s/step - loss: 10.0899 - eval_dice: 0.0763 - val_loss: 10.3791 - val_eval_dice: 0.0381 - lr: 1.0000e-04\n",
      "Epoch 30/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9948 - eval_dice: 0.0754\n",
      "Epoch 30: val_loss improved from 10.37912 to 10.28563, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 109s 2s/step - loss: 9.9948 - eval_dice: 0.0754 - val_loss: 10.2856 - val_eval_dice: 0.0387 - lr: 1.0000e-04\n",
      "Epoch 31/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8850 - eval_dice: 0.0697\n",
      "Epoch 31: val_loss did not improve from 10.28563\n",
      "37/37 [==============================] - 108s 2s/step - loss: 9.8850 - eval_dice: 0.0697 - val_loss: 10.3004 - val_eval_dice: 0.0547 - lr: 1.0000e-04\n",
      "Epoch 32/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9210 - eval_dice: 0.0741\n",
      "Epoch 32: val_loss improved from 10.28563 to 10.25111, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 109s 2s/step - loss: 9.9210 - eval_dice: 0.0741 - val_loss: 10.2511 - val_eval_dice: 0.0379 - lr: 1.0000e-04\n",
      "Epoch 33/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8427 - eval_dice: 0.0679\n",
      "Epoch 33: val_loss improved from 10.25111 to 10.21623, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 109s 2s/step - loss: 9.8427 - eval_dice: 0.0679 - val_loss: 10.2162 - val_eval_dice: 0.0477 - lr: 1.0000e-04\n",
      "Epoch 34/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8118 - eval_dice: 0.0700\n",
      "Epoch 34: val_loss did not improve from 10.21623\n",
      "37/37 [==============================] - 112s 2s/step - loss: 9.8118 - eval_dice: 0.0700 - val_loss: 10.2207 - val_eval_dice: 0.0577 - lr: 1.0000e-04\n",
      "Epoch 35/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.7545 - eval_dice: 0.0643\n",
      "Epoch 35: val_loss improved from 10.21623 to 10.17268, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 110s 2s/step - loss: 9.7545 - eval_dice: 0.0643 - val_loss: 10.1727 - val_eval_dice: 0.0344 - lr: 1.0000e-04\n",
      "Epoch 36/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.7647 - eval_dice: 0.0702\n",
      "Epoch 36: val_loss improved from 10.17268 to 10.11677, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 113s 2s/step - loss: 9.7647 - eval_dice: 0.0702 - val_loss: 10.1168 - val_eval_dice: 0.0384 - lr: 1.0000e-04\n",
      "Epoch 37/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.7036 - eval_dice: 0.0687\n",
      "Epoch 37: val_loss did not improve from 10.11677\n",
      "37/37 [==============================] - 112s 2s/step - loss: 9.7036 - eval_dice: 0.0687 - val_loss: 10.1326 - val_eval_dice: 0.0440 - lr: 1.0000e-04\n",
      "Epoch 38/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.7353 - eval_dice: 0.0726\n",
      "Epoch 38: val_loss did not improve from 10.11677\n",
      "37/37 [==============================] - 109s 2s/step - loss: 9.7353 - eval_dice: 0.0726 - val_loss: 10.1495 - val_eval_dice: 0.0495 - lr: 1.0000e-04\n",
      "Epoch 39/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.7084 - eval_dice: 0.0716\n",
      "Epoch 39: val_loss did not improve from 10.11677\n",
      "37/37 [==============================] - 108s 2s/step - loss: 9.7084 - eval_dice: 0.0716 - val_loss: 10.1186 - val_eval_dice: 0.0500 - lr: 1.0000e-04\n",
      "Epoch 40/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.6751 - eval_dice: 0.0692\n",
      "Epoch 40: val_loss improved from 10.11677 to 10.09449, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/unet3d_mod(2024-07-17)/18.37.15\\cp.ckpt\n",
      "37/37 [==============================] - 108s 2s/step - loss: 9.6751 - eval_dice: 0.0692 - val_loss: 10.0945 - val_eval_dice: 0.0465 - lr: 1.0000e-04\n",
      "Epoch 41/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.6505 - eval_dice: 0.0737\n",
      "Epoch 41: val_loss did not improve from 10.09449\n",
      "37/37 [==============================] - 107s 2s/step - loss: 9.6505 - eval_dice: 0.0737 - val_loss: 10.1176 - val_eval_dice: 0.0447 - lr: 1.0000e-04\n",
      "Epoch 42/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.6355 - eval_dice: 0.0717\n",
      "Epoch 42: val_loss did not improve from 10.09449\n",
      "37/37 [==============================] - 107s 2s/step - loss: 9.6355 - eval_dice: 0.0717 - val_loss: 10.0953 - val_eval_dice: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 43/120\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.6268 - eval_dice: 0.0738\n",
      "Epoch 43: val_loss did not improve from 10.09449\n",
      "37/37 [==============================] - 93s 1s/step - loss: 9.6268 - eval_dice: 0.0738 - val_loss: 10.1181 - val_eval_dice: 0.0402 - lr: 1.0000e-04\n",
      "Epoch 44/120\n",
      " 8/37 [=====>........................] - ETA: 45s - loss: 9.5974 - eval_dice: 0.0698"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "print('Training session id:', training_session_path, params['normalization'])\n",
    "history1_unet = unet3d_model.fit(\n",
    "                train_axial,\n",
    "                epochs=120,\n",
    "                validation_data=val_axial, \n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - AttUnet3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL\n",
      "Training session id: Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\n"
     ]
    }
   ],
   "source": [
    "logs_axial = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "training_session_path = 'Sigma3/GroupNorm/attunet3d{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_axial)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_axial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttUnet3d input: 12 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\") True\n",
      "Input shape after downsample: (None, 16, 128, 128, 32)\n",
      "Input shape after downsample: (None, 8, 64, 64, 64)\n",
      "Input shape after downsample: (None, 4, 32, 32, 128)\n",
      "Input shape after downsample: (None, 2, 16, 16, 512)\n",
      "Input shape AFTER concatenate: (None, 4, 32, 32, 128)\n",
      "Input shape AFTER concatenate: (None, 8, 64, 64, 64)\n",
      "Input shape AFTER concatenate: (None, 16, 128, 128, 32)\n",
      "Input shape AFTER concatenate: (None, 32, 256, 256, 16)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_62 (Conv3D)             (None, 32, 256, 256  432         ['input_3[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization (GroupNorm  (None, 32, 256, 256  32         ['conv3d_62[0][0]']              \n",
      " alization)                     , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 32, 256, 256  0           ['group_normalization[0][0]']    \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_63 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_36[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_1 (GroupNo  (None, 32, 256, 256  32         ['conv3d_63[0][0]']              \n",
      " rmalization)                   , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_1[0][0]']  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_64 (Conv3D)             (None, 16, 128, 128  13824       ['re_lu_37[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_2 (GroupNo  (None, 16, 128, 128  64         ['conv3d_64[0][0]']              \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_2[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_65 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_38[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_3 (GroupNo  (None, 16, 128, 128  64         ['conv3d_65[0][0]']              \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_3[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_66 (Conv3D)             (None, 8, 64, 64, 6  55296       ['re_lu_39[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_4 (GroupNo  (None, 8, 64, 64, 6  128        ['conv3d_66[0][0]']              \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_4[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_67 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_40[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_5 (GroupNo  (None, 8, 64, 64, 6  128        ['conv3d_67[0][0]']              \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_5[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_68 (Conv3D)             (None, 4, 32, 32, 1  221184      ['re_lu_41[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_6 (GroupNo  (None, 4, 32, 32, 1  256        ['conv3d_68[0][0]']              \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_6[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_69 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_42[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_7 (GroupNo  (None, 4, 32, 32, 1  256        ['conv3d_69[0][0]']              \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_7[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_70 (Conv3D)             (None, 2, 16, 16, 5  1769472     ['re_lu_43[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_8 (GroupNo  (None, 2, 16, 16, 5  1024       ['conv3d_70[0][0]']              \n",
      " rmalization)                   12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_8[0][0]']  \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_71 (Conv3D)             (None, 2, 16, 16, 5  7077888     ['re_lu_44[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_9 (GroupNo  (None, 2, 16, 16, 5  1024       ['conv3d_71[0][0]']              \n",
      " rmalization)                   12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_9[0][0]']  \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 2, 16, 16, 5  0           ['re_lu_45[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_72 (Conv3D)             (None, 2, 16, 16, 6  65600       ['re_lu_43[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_73 (Conv3D)             (None, 2, 16, 16, 6  32832       ['dropout_2[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 2, 16, 16, 6  0           ['conv3d_72[0][0]',              \n",
      "                                4)                                'conv3d_73[0][0]']              \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 2, 16, 16, 6  0           ['add_8[0][0]']                  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_74 (Conv3D)             (None, 2, 16, 16, 1  65          ['activation_18[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 2, 16, 16, 1  0           ['conv3d_74[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_8 (UpSampling3D)  (None, 4, 32, 32, 1  0          ['activation_19[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_8 (Conv3DTran  (None, 4, 32, 32, 1  1769600    ['dropout_2[0][0]']              \n",
      " spose)                         28)                                                               \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 4, 32, 32, 1  0           ['up_sampling3d_8[0][0]',        \n",
      "                                28)                               're_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 4, 32, 32, 2  0           ['conv3d_transpose_8[0][0]',     \n",
      "                                56)                               'multiply_8[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_75 (Conv3D)             (None, 4, 32, 32, 1  884736      ['concatenate_8[0][0]']          \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_10 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_75[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_10[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_76 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_46[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_11 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_76[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_11[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_77 (Conv3D)             (None, 4, 32, 32, 3  16416       ['re_lu_41[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_78 (Conv3D)             (None, 4, 32, 32, 3  4128        ['re_lu_47[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4, 32, 32, 3  0           ['conv3d_77[0][0]',              \n",
      "                                2)                                'conv3d_78[0][0]']              \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 4, 32, 32, 3  0           ['add_9[0][0]']                  \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_79 (Conv3D)             (None, 4, 32, 32, 1  33          ['activation_20[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 4, 32, 32, 1  0           ['conv3d_79[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_9 (UpSampling3D)  (None, 8, 64, 64, 1  0          ['activation_21[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_9 (Conv3DTran  (None, 8, 64, 64, 6  221248     ['re_lu_47[0][0]']               \n",
      " spose)                         4)                                                                \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 8, 64, 64, 6  0           ['up_sampling3d_9[0][0]',        \n",
      "                                4)                                're_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 8, 64, 64, 1  0           ['conv3d_transpose_9[0][0]',     \n",
      "                                28)                               'multiply_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_80 (Conv3D)             (None, 8, 64, 64, 6  221184      ['concatenate_9[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_12 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_80[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_12[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_81 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_48[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_13 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_81[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_13[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_82 (Conv3D)             (None, 8, 64, 64, 1  4112        ['re_lu_39[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_83 (Conv3D)             (None, 8, 64, 64, 1  1040        ['re_lu_49[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 8, 64, 64, 1  0           ['conv3d_82[0][0]',              \n",
      "                                6)                                'conv3d_83[0][0]']              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 64, 64, 1  0           ['add_10[0][0]']                 \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_84 (Conv3D)             (None, 8, 64, 64, 1  17          ['activation_22[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 8, 64, 64, 1  0           ['conv3d_84[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_10 (UpSampling3D  (None, 16, 128, 128  0          ['activation_23[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_10 (Conv3DTra  (None, 16, 128, 128  55328      ['re_lu_49[0][0]']               \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 16, 128, 128  0           ['up_sampling3d_10[0][0]',       \n",
      "                                , 32)                             're_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 16, 128, 128  0           ['conv3d_transpose_10[0][0]',    \n",
      "                                , 64)                             'multiply_10[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_85 (Conv3D)             (None, 16, 128, 128  55296       ['concatenate_10[0][0]']         \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_14 (GroupN  (None, 16, 128, 128  64         ['conv3d_85[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_14[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_86 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_50[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_15 (GroupN  (None, 16, 128, 128  64         ['conv3d_86[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_15[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_87 (Conv3D)             (None, 16, 128, 128  1032        ['re_lu_37[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_88 (Conv3D)             (None, 16, 128, 128  264         ['re_lu_51[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 16, 128, 128  0           ['conv3d_87[0][0]',              \n",
      "                                , 8)                              'conv3d_88[0][0]']              \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 128, 128  0           ['add_11[0][0]']                 \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_89 (Conv3D)             (None, 16, 128, 128  9           ['activation_24[0][0]']          \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 128, 128  0           ['conv3d_89[0][0]']              \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " up_sampling3d_11 (UpSampling3D  (None, 32, 256, 256  0          ['activation_25[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_11 (Conv3DTra  (None, 32, 256, 256  13840      ['re_lu_51[0][0]']               \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 32, 256, 256  0           ['up_sampling3d_11[0][0]',       \n",
      "                                , 16)                             're_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 32, 256, 256  0           ['conv3d_transpose_11[0][0]',    \n",
      "                                , 32)                             'multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_90 (Conv3D)             (None, 32, 256, 256  13824       ['concatenate_11[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_16 (GroupN  (None, 32, 256, 256  32         ['conv3d_90[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_16[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_91 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_52[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_17 (GroupN  (None, 32, 256, 256  32         ['conv3d_91[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_17[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_92 (Conv3D)             (None, 32, 256, 256  5196        ['re_lu_53[0][0]']               \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 32, 256, 256  0           ['conv3d_92[0][0]']              \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,682,904\n",
      "Trainable params: 13,682,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initial input features\n",
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('AttUnet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'])\n",
    "output = AttUnet3d(yshape[params['subset']][-1],params['mode'],features,params['normalization'])\n",
    "attunet_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "attunet_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])\n",
    "attunet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session id: Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55 groupnorm\n",
      "Epoch 1/100\n",
      "     74/Unknown - 103s 792ms/step - loss: 12.6766 - eval_dice: 0.6270\n",
      "Epoch 1: val_loss improved from inf to 11.48156, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 110s 879ms/step - loss: 12.6766 - eval_dice: 0.6270 - val_loss: 11.4816 - val_eval_dice: 0.2546 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.2744 - eval_dice: 0.1917\n",
      "Epoch 2: val_loss improved from 11.48156 to 11.28316, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 104s 891ms/step - loss: 11.2744 - eval_dice: 0.1917 - val_loss: 11.2832 - val_eval_dice: 0.1478 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1840 - eval_dice: 0.1411\n",
      "Epoch 3: val_loss improved from 11.28316 to 11.16333, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 105s 903ms/step - loss: 11.1840 - eval_dice: 0.1411 - val_loss: 11.1633 - val_eval_dice: 0.0844 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1310 - eval_dice: 0.1080\n",
      "Epoch 4: val_loss improved from 11.16333 to 11.12291, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 104s 877ms/step - loss: 11.1310 - eval_dice: 0.1080 - val_loss: 11.1229 - val_eval_dice: 0.0604 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1122 - eval_dice: 0.0961\n",
      "Epoch 5: val_loss did not improve from 11.12291\n",
      "74/74 [==============================] - 100s 812ms/step - loss: 11.1122 - eval_dice: 0.0961 - val_loss: 11.1277 - val_eval_dice: 0.0608 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1008 - eval_dice: 0.0947\n",
      "Epoch 6: val_loss improved from 11.12291 to 11.10752, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 96s 810ms/step - loss: 11.1008 - eval_dice: 0.0947 - val_loss: 11.1075 - val_eval_dice: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0875 - eval_dice: 0.0824\n",
      "Epoch 7: val_loss improved from 11.10752 to 11.08499, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 96s 807ms/step - loss: 11.0875 - eval_dice: 0.0824 - val_loss: 11.0850 - val_eval_dice: 0.0483 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0899 - eval_dice: 0.0869\n",
      "Epoch 8: val_loss improved from 11.08499 to 11.06325, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 98s 807ms/step - loss: 11.0899 - eval_dice: 0.0869 - val_loss: 11.0633 - val_eval_dice: 0.0354 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0779 - eval_dice: 0.0842\n",
      "Epoch 9: val_loss did not improve from 11.06325\n",
      "74/74 [==============================] - 97s 800ms/step - loss: 11.0779 - eval_dice: 0.0842 - val_loss: 11.1386 - val_eval_dice: 0.0775 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0578 - eval_dice: 0.0838\n",
      "Epoch 10: val_loss improved from 11.06325 to 11.05047, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 98s 812ms/step - loss: 11.0578 - eval_dice: 0.0838 - val_loss: 11.0505 - val_eval_dice: 0.0422 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0430 - eval_dice: 0.0845\n",
      "Epoch 11: val_loss improved from 11.05047 to 10.99304, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 96s 811ms/step - loss: 11.0430 - eval_dice: 0.0845 - val_loss: 10.9930 - val_eval_dice: 0.0279 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0072 - eval_dice: 0.0869\n",
      "Epoch 12: val_loss improved from 10.99304 to 10.97083, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 98s 805ms/step - loss: 11.0072 - eval_dice: 0.0869 - val_loss: 10.9708 - val_eval_dice: 0.0437 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9046 - eval_dice: 0.0768\n",
      "Epoch 13: val_loss did not improve from 10.97083\n",
      "74/74 [==============================] - 97s 797ms/step - loss: 10.9046 - eval_dice: 0.0768 - val_loss: 11.0905 - val_eval_dice: 0.0341 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0934 - eval_dice: 0.0880\n",
      "Epoch 14: val_loss did not improve from 10.97083\n",
      "74/74 [==============================] - 96s 805ms/step - loss: 11.0934 - eval_dice: 0.0880 - val_loss: 11.0540 - val_eval_dice: 0.0338 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0783 - eval_dice: 0.0942\n",
      "Epoch 15: val_loss did not improve from 10.97083\n",
      "74/74 [==============================] - 98s 800ms/step - loss: 11.0783 - eval_dice: 0.0942 - val_loss: 11.1364 - val_eval_dice: 0.0968 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9717 - eval_dice: 0.0930\n",
      "Epoch 16: val_loss improved from 10.97083 to 10.77803, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 97s 808ms/step - loss: 10.9717 - eval_dice: 0.0930 - val_loss: 10.7780 - val_eval_dice: 0.0254 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8045 - eval_dice: 0.0828\n",
      "Epoch 17: val_loss improved from 10.77803 to 10.77295, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 96s 809ms/step - loss: 10.8045 - eval_dice: 0.0828 - val_loss: 10.7730 - val_eval_dice: 0.0329 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7541 - eval_dice: 0.0918\n",
      "Epoch 18: val_loss improved from 10.77295 to 10.73527, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 97s 808ms/step - loss: 10.7541 - eval_dice: 0.0918 - val_loss: 10.7353 - val_eval_dice: 0.0286 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6863 - eval_dice: 0.0850\n",
      "Epoch 19: val_loss improved from 10.73527 to 10.66362, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 98s 810ms/step - loss: 10.6863 - eval_dice: 0.0850 - val_loss: 10.6636 - val_eval_dice: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6484 - eval_dice: 0.0805\n",
      "Epoch 20: val_loss improved from 10.66362 to 10.65175, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 97s 807ms/step - loss: 10.6484 - eval_dice: 0.0805 - val_loss: 10.6518 - val_eval_dice: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5793 - eval_dice: 0.0799\n",
      "Epoch 21: val_loss improved from 10.65175 to 10.64717, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 97s 806ms/step - loss: 10.5793 - eval_dice: 0.0799 - val_loss: 10.6472 - val_eval_dice: 0.0242 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5519 - eval_dice: 0.0755\n",
      "Epoch 22: val_loss improved from 10.64717 to 10.57745, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 98s 810ms/step - loss: 10.5519 - eval_dice: 0.0755 - val_loss: 10.5774 - val_eval_dice: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5569 - eval_dice: 0.0746\n",
      "Epoch 23: val_loss did not improve from 10.57745\n",
      "74/74 [==============================] - 95s 805ms/step - loss: 10.5569 - eval_dice: 0.0746 - val_loss: 10.6284 - val_eval_dice: 0.0309 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5633 - eval_dice: 0.0745\n",
      "Epoch 24: val_loss did not improve from 10.57745\n",
      "74/74 [==============================] - 97s 799ms/step - loss: 10.5633 - eval_dice: 0.0745 - val_loss: 10.6193 - val_eval_dice: 0.0290 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5245 - eval_dice: 0.0770\n",
      "Epoch 25: val_loss improved from 10.57745 to 10.56533, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 97s 811ms/step - loss: 10.5245 - eval_dice: 0.0770 - val_loss: 10.5653 - val_eval_dice: 0.0394 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5137 - eval_dice: 0.0793\n",
      "Epoch 26: val_loss did not improve from 10.56533\n",
      "74/74 [==============================] - 102s 869ms/step - loss: 10.5137 - eval_dice: 0.0793 - val_loss: 10.6306 - val_eval_dice: 0.0319 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5042 - eval_dice: 0.0756\n",
      "Epoch 27: val_loss did not improve from 10.56533\n",
      "74/74 [==============================] - 101s 821ms/step - loss: 10.5042 - eval_dice: 0.0756 - val_loss: 10.5783 - val_eval_dice: 0.0409 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4514 - eval_dice: 0.0800\n",
      "Epoch 28: val_loss did not improve from 10.56533\n",
      "74/74 [==============================] - 100s 809ms/step - loss: 10.4514 - eval_dice: 0.0800 - val_loss: 10.5712 - val_eval_dice: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4735 - eval_dice: 0.0842\n",
      "Epoch 29: val_loss did not improve from 10.56533\n",
      "74/74 [==============================] - 95s 799ms/step - loss: 10.4735 - eval_dice: 0.0842 - val_loss: 10.5974 - val_eval_dice: 0.0427 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4447 - eval_dice: 0.0831\n",
      "Epoch 30: val_loss did not improve from 10.56533\n",
      "74/74 [==============================] - 97s 777ms/step - loss: 10.4447 - eval_dice: 0.0831 - val_loss: 10.6278 - val_eval_dice: 0.0289 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5041 - eval_dice: 0.0900\n",
      "Epoch 31: val_loss did not improve from 10.56533\n",
      "74/74 [==============================] - 97s 792ms/step - loss: 10.5041 - eval_dice: 0.0900 - val_loss: 10.5899 - val_eval_dice: 0.0448 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4663 - eval_dice: 0.0887\n",
      "Epoch 32: val_loss improved from 10.56533 to 10.54610, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 94s 787ms/step - loss: 10.4663 - eval_dice: 0.0887 - val_loss: 10.5461 - val_eval_dice: 0.0328 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5051 - eval_dice: 0.0917\n",
      "Epoch 33: val_loss did not improve from 10.54610\n",
      "74/74 [==============================] - 99s 809ms/step - loss: 10.5051 - eval_dice: 0.0917 - val_loss: 10.5967 - val_eval_dice: 0.0463 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4862 - eval_dice: 0.0946\n",
      "Epoch 34: val_loss did not improve from 10.54610\n",
      "74/74 [==============================] - 98s 802ms/step - loss: 10.4862 - eval_dice: 0.0946 - val_loss: 10.5589 - val_eval_dice: 0.0328 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4635 - eval_dice: 0.0871\n",
      "Epoch 35: val_loss improved from 10.54610 to 10.54125, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 95s 795ms/step - loss: 10.4635 - eval_dice: 0.0871 - val_loss: 10.5412 - val_eval_dice: 0.0336 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4472 - eval_dice: 0.0859\n",
      "Epoch 36: val_loss improved from 10.54125 to 10.49878, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 96s 792ms/step - loss: 10.4472 - eval_dice: 0.0859 - val_loss: 10.4988 - val_eval_dice: 0.0242 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4784 - eval_dice: 0.0863\n",
      "Epoch 37: val_loss did not improve from 10.49878\n",
      "74/74 [==============================] - 95s 780ms/step - loss: 10.4784 - eval_dice: 0.0863 - val_loss: 10.6027 - val_eval_dice: 0.0497 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4894 - eval_dice: 0.0920\n",
      "Epoch 38: val_loss did not improve from 10.49878\n",
      "74/74 [==============================] - 95s 791ms/step - loss: 10.4894 - eval_dice: 0.0920 - val_loss: 10.5095 - val_eval_dice: 0.0385 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4265 - eval_dice: 0.0806\n",
      "Epoch 39: val_loss improved from 10.49878 to 10.48606, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 102s 813ms/step - loss: 10.4265 - eval_dice: 0.0806 - val_loss: 10.4861 - val_eval_dice: 0.0237 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4221 - eval_dice: 0.0799\n",
      "Epoch 40: val_loss improved from 10.48606 to 10.47340, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 95s 785ms/step - loss: 10.4221 - eval_dice: 0.0799 - val_loss: 10.4734 - val_eval_dice: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4277 - eval_dice: 0.0803\n",
      "Epoch 41: val_loss did not improve from 10.47340\n",
      "74/74 [==============================] - 92s 786ms/step - loss: 10.4277 - eval_dice: 0.0803 - val_loss: 10.7338 - val_eval_dice: 0.0667 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4439 - eval_dice: 0.0815\n",
      "Epoch 42: val_loss improved from 10.47340 to 10.46397, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 100s 826ms/step - loss: 10.4439 - eval_dice: 0.0815 - val_loss: 10.4640 - val_eval_dice: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4103 - eval_dice: 0.0756\n",
      "Epoch 43: val_loss did not improve from 10.46397\n",
      "74/74 [==============================] - 97s 807ms/step - loss: 10.4103 - eval_dice: 0.0756 - val_loss: 10.4684 - val_eval_dice: 0.0164 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4184 - eval_dice: 0.0799\n",
      "Epoch 44: val_loss did not improve from 10.46397\n",
      "74/74 [==============================] - 94s 783ms/step - loss: 10.4184 - eval_dice: 0.0799 - val_loss: 10.4821 - val_eval_dice: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3880 - eval_dice: 0.0751\n",
      "Epoch 45: val_loss did not improve from 10.46397\n",
      "74/74 [==============================] - 95s 794ms/step - loss: 10.3880 - eval_dice: 0.0751 - val_loss: 10.4975 - val_eval_dice: 0.0447 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4032 - eval_dice: 0.0728\n",
      "Epoch 46: val_loss did not improve from 10.46397\n",
      "74/74 [==============================] - 94s 779ms/step - loss: 10.4032 - eval_dice: 0.0728 - val_loss: 10.4760 - val_eval_dice: 0.0259 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3913 - eval_dice: 0.0763\n",
      "Epoch 47: val_loss improved from 10.46397 to 10.44625, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 94s 787ms/step - loss: 10.3913 - eval_dice: 0.0763 - val_loss: 10.4463 - val_eval_dice: 0.0149 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3774 - eval_dice: 0.0721\n",
      "Epoch 48: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 95s 776ms/step - loss: 10.3774 - eval_dice: 0.0721 - val_loss: 10.4758 - val_eval_dice: 0.0431 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4487 - eval_dice: 0.0809\n",
      "Epoch 49: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 96s 783ms/step - loss: 10.4487 - eval_dice: 0.0809 - val_loss: 10.4738 - val_eval_dice: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4478 - eval_dice: 0.0779\n",
      "Epoch 50: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 94s 784ms/step - loss: 10.4478 - eval_dice: 0.0779 - val_loss: 10.5253 - val_eval_dice: 0.0381 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3845 - eval_dice: 0.0711\n",
      "Epoch 51: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 94s 778ms/step - loss: 10.3845 - eval_dice: 0.0711 - val_loss: 10.4801 - val_eval_dice: 0.0322 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3804 - eval_dice: 0.0739\n",
      "Epoch 52: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 95s 778ms/step - loss: 10.3804 - eval_dice: 0.0739 - val_loss: 10.4606 - val_eval_dice: 0.0361 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3804 - eval_dice: 0.0747\n",
      "Epoch 53: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 94s 782ms/step - loss: 10.3804 - eval_dice: 0.0747 - val_loss: 10.4735 - val_eval_dice: 0.0361 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3960 - eval_dice: 0.0720\n",
      "Epoch 54: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 95s 779ms/step - loss: 10.3960 - eval_dice: 0.0720 - val_loss: 10.5073 - val_eval_dice: 0.0371 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3622 - eval_dice: 0.0698\n",
      "Epoch 55: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 101s 865ms/step - loss: 10.3622 - eval_dice: 0.0698 - val_loss: 10.4699 - val_eval_dice: 0.0326 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3571 - eval_dice: 0.0739\n",
      "Epoch 56: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 104s 896ms/step - loss: 10.3571 - eval_dice: 0.0739 - val_loss: 10.4661 - val_eval_dice: 0.0364 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3530 - eval_dice: 0.0735\n",
      "Epoch 57: val_loss did not improve from 10.44625\n",
      "74/74 [==============================] - 105s 882ms/step - loss: 10.3530 - eval_dice: 0.0735 - val_loss: 10.4778 - val_eval_dice: 0.0415 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3608 - eval_dice: 0.0755\n",
      "Epoch 58: val_loss improved from 10.44625 to 10.43357, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 99s 810ms/step - loss: 10.3608 - eval_dice: 0.0755 - val_loss: 10.4336 - val_eval_dice: 0.0281 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3395 - eval_dice: 0.0691\n",
      "Epoch 59: val_loss did not improve from 10.43357\n",
      "74/74 [==============================] - 95s 806ms/step - loss: 10.3395 - eval_dice: 0.0691 - val_loss: 10.4434 - val_eval_dice: 0.0345 - lr: 5.0000e-05\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3477 - eval_dice: 0.0690\n",
      "Epoch 60: val_loss improved from 10.43357 to 10.43259, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 97s 809ms/step - loss: 10.3477 - eval_dice: 0.0690 - val_loss: 10.4326 - val_eval_dice: 0.0254 - lr: 5.0000e-05\n",
      "Epoch 61/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3570 - eval_dice: 0.0732\n",
      "Epoch 61: val_loss improved from 10.43259 to 10.40478, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 97s 805ms/step - loss: 10.3570 - eval_dice: 0.0732 - val_loss: 10.4048 - val_eval_dice: 0.0181 - lr: 5.0000e-05\n",
      "Epoch 62/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3373 - eval_dice: 0.0692\n",
      "Epoch 62: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 96s 803ms/step - loss: 10.3373 - eval_dice: 0.0692 - val_loss: 10.4697 - val_eval_dice: 0.0428 - lr: 5.0000e-05\n",
      "Epoch 63/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3503 - eval_dice: 0.0721\n",
      "Epoch 63: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 97s 803ms/step - loss: 10.3503 - eval_dice: 0.0721 - val_loss: 10.4243 - val_eval_dice: 0.0309 - lr: 5.0000e-05\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3393 - eval_dice: 0.0691\n",
      "Epoch 64: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 97s 802ms/step - loss: 10.3393 - eval_dice: 0.0691 - val_loss: 10.4258 - val_eval_dice: 0.0314 - lr: 5.0000e-05\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3449 - eval_dice: 0.0750\n",
      "Epoch 65: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 101s 856ms/step - loss: 10.3449 - eval_dice: 0.0750 - val_loss: 10.4233 - val_eval_dice: 0.0348 - lr: 5.0000e-05\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3457 - eval_dice: 0.0738\n",
      "Epoch 66: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 103s 851ms/step - loss: 10.3457 - eval_dice: 0.0738 - val_loss: 10.4371 - val_eval_dice: 0.0342 - lr: 5.0000e-05\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3512 - eval_dice: 0.0755\n",
      "Epoch 67: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 102s 850ms/step - loss: 10.3512 - eval_dice: 0.0755 - val_loss: 10.4305 - val_eval_dice: 0.0399 - lr: 5.0000e-05\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3416 - eval_dice: 0.0740\n",
      "Epoch 68: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 102s 870ms/step - loss: 10.3416 - eval_dice: 0.0740 - val_loss: 10.4444 - val_eval_dice: 0.0376 - lr: 5.0000e-05\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3305 - eval_dice: 0.0676\n",
      "Epoch 69: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 102s 858ms/step - loss: 10.3305 - eval_dice: 0.0676 - val_loss: 10.4288 - val_eval_dice: 0.0290 - lr: 5.0000e-05\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3310 - eval_dice: 0.0718\n",
      "Epoch 70: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 101s 832ms/step - loss: 10.3310 - eval_dice: 0.0718 - val_loss: 10.4180 - val_eval_dice: 0.0334 - lr: 2.5000e-05\n",
      "Epoch 71/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3381 - eval_dice: 0.0736\n",
      "Epoch 71: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 96s 801ms/step - loss: 10.3381 - eval_dice: 0.0736 - val_loss: 10.4382 - val_eval_dice: 0.0342 - lr: 2.5000e-05\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3280 - eval_dice: 0.0734\n",
      "Epoch 72: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 98s 817ms/step - loss: 10.3280 - eval_dice: 0.0734 - val_loss: 10.4211 - val_eval_dice: 0.0356 - lr: 2.5000e-05\n",
      "Epoch 73/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3343 - eval_dice: 0.0735\n",
      "Epoch 73: val_loss did not improve from 10.40478\n",
      "74/74 [==============================] - 101s 839ms/step - loss: 10.3343 - eval_dice: 0.0735 - val_loss: 10.4318 - val_eval_dice: 0.0377 - lr: 2.5000e-05\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3234 - eval_dice: 0.0682\n",
      "Epoch 74: val_loss improved from 10.40478 to 10.39766, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 103s 884ms/step - loss: 10.3234 - eval_dice: 0.0682 - val_loss: 10.3977 - val_eval_dice: 0.0291 - lr: 2.5000e-05\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3215 - eval_dice: 0.0704\n",
      "Epoch 75: val_loss improved from 10.39766 to 10.39246, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 103s 864ms/step - loss: 10.3215 - eval_dice: 0.0704 - val_loss: 10.3925 - val_eval_dice: 0.0224 - lr: 2.5000e-05\n",
      "Epoch 76/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3226 - eval_dice: 0.0703\n",
      "Epoch 76: val_loss did not improve from 10.39246\n",
      "74/74 [==============================] - 102s 860ms/step - loss: 10.3226 - eval_dice: 0.0703 - val_loss: 10.4175 - val_eval_dice: 0.0296 - lr: 2.5000e-05\n",
      "Epoch 77/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3421 - eval_dice: 0.0762\n",
      "Epoch 77: val_loss did not improve from 10.39246\n",
      "74/74 [==============================] - 102s 873ms/step - loss: 10.3421 - eval_dice: 0.0762 - val_loss: 10.4202 - val_eval_dice: 0.0306 - lr: 2.5000e-05\n",
      "Epoch 78/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3312 - eval_dice: 0.0721\n",
      "Epoch 78: val_loss did not improve from 10.39246\n",
      "74/74 [==============================] - 102s 843ms/step - loss: 10.3312 - eval_dice: 0.0721 - val_loss: 10.4217 - val_eval_dice: 0.0348 - lr: 2.5000e-05\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3128 - eval_dice: 0.0662\n",
      "Epoch 79: val_loss did not improve from 10.39246\n",
      "74/74 [==============================] - 101s 849ms/step - loss: 10.3128 - eval_dice: 0.0662 - val_loss: 10.4116 - val_eval_dice: 0.0295 - lr: 2.5000e-05\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3132 - eval_dice: 0.0650\n",
      "Epoch 80: val_loss improved from 10.39246 to 10.38079, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/attunet3d(2024-07-16)/15.23.55\\cp.ckpt\n",
      "74/74 [==============================] - 101s 857ms/step - loss: 10.3132 - eval_dice: 0.0650 - val_loss: 10.3808 - val_eval_dice: 0.0236 - lr: 2.5000e-05\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3187 - eval_dice: 0.0693\n",
      "Epoch 81: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 102s 853ms/step - loss: 10.3187 - eval_dice: 0.0693 - val_loss: 10.3927 - val_eval_dice: 0.0277 - lr: 2.5000e-05\n",
      "Epoch 82/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3159 - eval_dice: 0.0702\n",
      "Epoch 82: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 103s 856ms/step - loss: 10.3159 - eval_dice: 0.0702 - val_loss: 10.3991 - val_eval_dice: 0.0364 - lr: 2.5000e-05\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3152 - eval_dice: 0.0682\n",
      "Epoch 83: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 101s 868ms/step - loss: 10.3152 - eval_dice: 0.0682 - val_loss: 10.3871 - val_eval_dice: 0.0311 - lr: 2.5000e-05\n",
      "Epoch 84/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3152 - eval_dice: 0.0688\n",
      "Epoch 84: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 103s 851ms/step - loss: 10.3152 - eval_dice: 0.0688 - val_loss: 10.4138 - val_eval_dice: 0.0321 - lr: 2.5000e-05\n",
      "Epoch 85/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3283 - eval_dice: 0.0696\n",
      "Epoch 85: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 104s 865ms/step - loss: 10.3283 - eval_dice: 0.0696 - val_loss: 10.4043 - val_eval_dice: 0.0279 - lr: 2.5000e-05\n",
      "Epoch 86/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3237 - eval_dice: 0.0696\n",
      "Epoch 86: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 103s 865ms/step - loss: 10.3237 - eval_dice: 0.0696 - val_loss: 10.3872 - val_eval_dice: 0.0237 - lr: 2.5000e-05\n",
      "Epoch 87/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3270 - eval_dice: 0.0729\n",
      "Epoch 87: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 105s 848ms/step - loss: 10.3270 - eval_dice: 0.0729 - val_loss: 10.4174 - val_eval_dice: 0.0391 - lr: 2.5000e-05\n",
      "Epoch 88/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3059 - eval_dice: 0.0664\n",
      "Epoch 88: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 101s 845ms/step - loss: 10.3059 - eval_dice: 0.0664 - val_loss: 10.4181 - val_eval_dice: 0.0317 - lr: 2.5000e-05\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3240 - eval_dice: 0.0707\n",
      "Epoch 89: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 102s 869ms/step - loss: 10.3240 - eval_dice: 0.0707 - val_loss: 10.3863 - val_eval_dice: 0.0239 - lr: 1.2500e-05\n",
      "Epoch 90/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2965 - eval_dice: 0.0652\n",
      "Epoch 90: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 102s 858ms/step - loss: 10.2965 - eval_dice: 0.0652 - val_loss: 10.3835 - val_eval_dice: 0.0281 - lr: 1.2500e-05\n",
      "Epoch 91/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3280 - eval_dice: 0.0747\n",
      "Epoch 91: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 101s 824ms/step - loss: 10.3280 - eval_dice: 0.0747 - val_loss: 10.3980 - val_eval_dice: 0.0285 - lr: 1.2500e-05\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2986 - eval_dice: 0.0654\n",
      "Epoch 92: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 95s 801ms/step - loss: 10.2986 - eval_dice: 0.0654 - val_loss: 10.3929 - val_eval_dice: 0.0308 - lr: 1.2500e-05\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3096 - eval_dice: 0.0691\n",
      "Epoch 93: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 96s 799ms/step - loss: 10.3096 - eval_dice: 0.0691 - val_loss: 10.3931 - val_eval_dice: 0.0288 - lr: 1.2500e-05\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3075 - eval_dice: 0.0658\n",
      "Epoch 94: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 97s 796ms/step - loss: 10.3075 - eval_dice: 0.0658 - val_loss: 10.3827 - val_eval_dice: 0.0281 - lr: 1.2500e-05\n",
      "Epoch 95/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3026 - eval_dice: 0.0652\n",
      "Epoch 95: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 95s 790ms/step - loss: 10.3026 - eval_dice: 0.0652 - val_loss: 10.3988 - val_eval_dice: 0.0286 - lr: 1.2500e-05\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3142 - eval_dice: 0.0696\n",
      "Epoch 96: val_loss did not improve from 10.38079\n",
      "74/74 [==============================] - 96s 789ms/step - loss: 10.3142 - eval_dice: 0.0696 - val_loss: 10.3991 - val_eval_dice: 0.0236 - lr: 1.2500e-05\n",
      "Epoch 96: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "print('Training session id:', training_session_path, params['normalization'])\n",
    "history1 = attunet_model.fit(\n",
    "                train_axial,\n",
    "                epochs=100,\n",
    "                validation_data=val_axial,\n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - Residual Attention U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL\n",
      "Training session id: Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\n"
     ]
    }
   ],
   "source": [
    "logs_axial = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "training_session_path = 'Sigma3/BatchNorm/resattunet3d_{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_axial)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_axial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttResUnet3d input: 12 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_8'), name='input_8', description=\"created by layer 'input_8'\") True\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_245 (Conv3D)            (None, 32, 256, 256  432         ['input_8[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_182 (Batch  (None, 32, 256, 256  64         ['conv3d_245[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_182 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_182[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_246 (Conv3D)            (None, 32, 256, 256  6912        ['re_lu_182[0][0]']              \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_183 (Batch  (None, 32, 256, 256  64         ['conv3d_246[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_183 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_183[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_247 (Conv3D)            (None, 16, 128, 128  13824       ['re_lu_183[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_184 (Batch  (None, 16, 128, 128  128        ['conv3d_247[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_184 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_184[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_248 (Conv3D)            (None, 16, 128, 128  27648       ['re_lu_184[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_185 (Batch  (None, 16, 128, 128  128        ['conv3d_248[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_249 (Conv3D)            (None, 16, 128, 128  512         ['re_lu_183[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_185 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_185[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_186 (Batch  (None, 16, 128, 128  128        ['conv3d_249[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " add_84 (Add)                   (None, 16, 128, 128  0           ['re_lu_185[0][0]',              \n",
      "                                , 32)                             'batch_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_186 (ReLU)               (None, 16, 128, 128  0           ['add_84[0][0]']                 \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_250 (Conv3D)            (None, 8, 64, 64, 6  55296       ['re_lu_186[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_187 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_250[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_187 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_187[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_251 (Conv3D)            (None, 8, 64, 64, 6  110592      ['re_lu_187[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_251[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_252 (Conv3D)            (None, 8, 64, 64, 6  2048        ['re_lu_186[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_188 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_188[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_252[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " add_85 (Add)                   (None, 8, 64, 64, 6  0           ['re_lu_188[0][0]',              \n",
      "                                4)                                'batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_189 (ReLU)               (None, 8, 64, 64, 6  0           ['add_85[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_253 (Conv3D)            (None, 4, 32, 32, 1  221184      ['re_lu_189[0][0]']              \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_253[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_190 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_190[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_254 (Conv3D)            (None, 4, 32, 32, 1  442368      ['re_lu_190[0][0]']              \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_254[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_255 (Conv3D)            (None, 4, 32, 32, 1  8192        ['re_lu_189[0][0]']              \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_191 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_191[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_255[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " add_86 (Add)                   (None, 4, 32, 32, 1  0           ['re_lu_191[0][0]',              \n",
      "                                28)                               'batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_192 (ReLU)               (None, 4, 32, 32, 1  0           ['add_86[0][0]']                 \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_256 (Conv3D)            (None, 2, 16, 16, 3  1105920     ['re_lu_192[0][0]']              \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 2, 16, 16, 3  1280       ['conv3d_256[0][0]']             \n",
      " Normalization)                 20)                                                               \n",
      "                                                                                                  \n",
      " re_lu_193 (ReLU)               (None, 2, 16, 16, 3  0           ['batch_normalization_193[0][0]']\n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " conv3d_257 (Conv3D)            (None, 2, 16, 16, 3  2764800     ['re_lu_193[0][0]']              \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 2, 16, 16, 3  1280       ['conv3d_257[0][0]']             \n",
      " Normalization)                 20)                                                               \n",
      "                                                                                                  \n",
      " conv3d_258 (Conv3D)            (None, 2, 16, 16, 3  40960       ['re_lu_192[0][0]']              \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " re_lu_194 (ReLU)               (None, 2, 16, 16, 3  0           ['batch_normalization_194[0][0]']\n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 2, 16, 16, 3  1280       ['conv3d_258[0][0]']             \n",
      " Normalization)                 20)                                                               \n",
      "                                                                                                  \n",
      " add_87 (Add)                   (None, 2, 16, 16, 3  0           ['re_lu_194[0][0]',              \n",
      "                                20)                               'batch_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_195 (ReLU)               (None, 2, 16, 16, 3  0           ['add_87[0][0]']                 \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 2, 16, 16, 3  0           ['re_lu_195[0][0]']              \n",
      "                                20)                                                               \n",
      "                                                                                                  \n",
      " conv3d_259 (Conv3D)            (None, 2, 16, 16, 6  65600       ['re_lu_192[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_260 (Conv3D)            (None, 2, 16, 16, 6  20544       ['dropout_7[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " add_88 (Add)                   (None, 2, 16, 16, 6  0           ['conv3d_259[0][0]',             \n",
      "                                4)                                'conv3d_260[0][0]']             \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 2, 16, 16, 6  0           ['add_88[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_261 (Conv3D)            (None, 2, 16, 16, 1  65          ['activation_63[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 2, 16, 16, 1  0           ['conv3d_261[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_28 (UpSampling3D  (None, 4, 32, 32, 1  0          ['activation_64[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_56 (Conv3DTra  (None, 4, 32, 32, 1  1106048    ['dropout_7[0][0]']              \n",
      " nspose)                        28)                                                               \n",
      "                                                                                                  \n",
      " multiply_28 (Multiply)         (None, 4, 32, 32, 1  0           ['up_sampling3d_28[0][0]',       \n",
      "                                28)                               're_lu_192[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 4, 32, 32, 2  0           ['conv3d_transpose_56[0][0]',    \n",
      "                                56)                               'multiply_28[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_262 (Conv3D)            (None, 4, 32, 32, 1  884736      ['concatenate_28[0][0]']         \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_262[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_196 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_196[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_263 (Conv3D)            (None, 4, 32, 32, 1  442368      ['re_lu_196[0][0]']              \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_263[0][0]']             \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_57 (Conv3DTra  (None, 4, 32, 32, 1  40960      ['dropout_7[0][0]']              \n",
      " nspose)                        28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_197 (ReLU)               (None, 4, 32, 32, 1  0           ['batch_normalization_197[0][0]']\n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 4, 32, 32, 1  512        ['conv3d_transpose_57[0][0]']    \n",
      " Normalization)                 28)                                                               \n",
      "                                                                                                  \n",
      " add_89 (Add)                   (None, 4, 32, 32, 1  0           ['re_lu_197[0][0]',              \n",
      "                                28)                               'batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_198 (ReLU)               (None, 4, 32, 32, 1  0           ['add_89[0][0]']                 \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_264 (Conv3D)            (None, 4, 32, 32, 3  16416       ['re_lu_189[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_265 (Conv3D)            (None, 4, 32, 32, 3  4128        ['re_lu_198[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " add_90 (Add)                   (None, 4, 32, 32, 3  0           ['conv3d_264[0][0]',             \n",
      "                                2)                                'conv3d_265[0][0]']             \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 4, 32, 32, 3  0           ['add_90[0][0]']                 \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_266 (Conv3D)            (None, 4, 32, 32, 1  33          ['activation_65[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 4, 32, 32, 1  0           ['conv3d_266[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_29 (UpSampling3D  (None, 8, 64, 64, 1  0          ['activation_66[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_58 (Conv3DTra  (None, 8, 64, 64, 6  221248     ['re_lu_198[0][0]']              \n",
      " nspose)                        4)                                                                \n",
      "                                                                                                  \n",
      " multiply_29 (Multiply)         (None, 8, 64, 64, 6  0           ['up_sampling3d_29[0][0]',       \n",
      "                                4)                                're_lu_189[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 8, 64, 64, 1  0           ['conv3d_transpose_58[0][0]',    \n",
      "                                28)                               'multiply_29[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_267 (Conv3D)            (None, 8, 64, 64, 6  221184      ['concatenate_29[0][0]']         \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_267[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_199 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_199[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_268 (Conv3D)            (None, 8, 64, 64, 6  110592      ['re_lu_199[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_268[0][0]']             \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_59 (Conv3DTra  (None, 8, 64, 64, 6  8192       ['re_lu_198[0][0]']              \n",
      " nspose)                        4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_200 (ReLU)               (None, 8, 64, 64, 6  0           ['batch_normalization_200[0][0]']\n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 8, 64, 64, 6  256        ['conv3d_transpose_59[0][0]']    \n",
      " Normalization)                 4)                                                                \n",
      "                                                                                                  \n",
      " add_91 (Add)                   (None, 8, 64, 64, 6  0           ['re_lu_200[0][0]',              \n",
      "                                4)                                'batch_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_201 (ReLU)               (None, 8, 64, 64, 6  0           ['add_91[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_269 (Conv3D)            (None, 8, 64, 64, 1  4112        ['re_lu_186[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_270 (Conv3D)            (None, 8, 64, 64, 1  1040        ['re_lu_201[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_92 (Add)                   (None, 8, 64, 64, 1  0           ['conv3d_269[0][0]',             \n",
      "                                6)                                'conv3d_270[0][0]']             \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 8, 64, 64, 1  0           ['add_92[0][0]']                 \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_271 (Conv3D)            (None, 8, 64, 64, 1  17          ['activation_67[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 8, 64, 64, 1  0           ['conv3d_271[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_30 (UpSampling3D  (None, 16, 128, 128  0          ['activation_68[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_60 (Conv3DTra  (None, 16, 128, 128  55328      ['re_lu_201[0][0]']              \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " multiply_30 (Multiply)         (None, 16, 128, 128  0           ['up_sampling3d_30[0][0]',       \n",
      "                                , 32)                             're_lu_186[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 16, 128, 128  0           ['conv3d_transpose_60[0][0]',    \n",
      "                                , 64)                             'multiply_30[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_272 (Conv3D)            (None, 16, 128, 128  55296       ['concatenate_30[0][0]']         \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 16, 128, 128  128        ['conv3d_272[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_202 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_202[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_273 (Conv3D)            (None, 16, 128, 128  27648       ['re_lu_202[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 16, 128, 128  128        ['conv3d_273[0][0]']             \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_61 (Conv3DTra  (None, 16, 128, 128  2048       ['re_lu_201[0][0]']              \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_203 (ReLU)               (None, 16, 128, 128  0           ['batch_normalization_203[0][0]']\n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 16, 128, 128  128        ['conv3d_transpose_61[0][0]']    \n",
      " Normalization)                 , 32)                                                             \n",
      "                                                                                                  \n",
      " add_93 (Add)                   (None, 16, 128, 128  0           ['re_lu_203[0][0]',              \n",
      "                                , 32)                             'batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_204 (ReLU)               (None, 16, 128, 128  0           ['add_93[0][0]']                 \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_274 (Conv3D)            (None, 16, 128, 128  1032        ['re_lu_183[0][0]']              \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_275 (Conv3D)            (None, 16, 128, 128  264         ['re_lu_204[0][0]']              \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " add_94 (Add)                   (None, 16, 128, 128  0           ['conv3d_274[0][0]',             \n",
      "                                , 8)                              'conv3d_275[0][0]']             \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 16, 128, 128  0           ['add_94[0][0]']                 \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_276 (Conv3D)            (None, 16, 128, 128  9           ['activation_69[0][0]']          \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 16, 128, 128  0           ['conv3d_276[0][0]']             \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " up_sampling3d_31 (UpSampling3D  (None, 32, 256, 256  0          ['activation_70[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_62 (Conv3DTra  (None, 32, 256, 256  13840      ['re_lu_204[0][0]']              \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " multiply_31 (Multiply)         (None, 32, 256, 256  0           ['up_sampling3d_31[0][0]',       \n",
      "                                , 16)                             're_lu_183[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 32, 256, 256  0           ['conv3d_transpose_62[0][0]',    \n",
      "                                , 32)                             'multiply_31[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_277 (Conv3D)            (None, 32, 256, 256  13824       ['concatenate_31[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 32, 256, 256  64         ['conv3d_277[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_205 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_205[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_278 (Conv3D)            (None, 32, 256, 256  6912        ['re_lu_205[0][0]']              \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 32, 256, 256  64         ['conv3d_278[0][0]']             \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_63 (Conv3DTra  (None, 32, 256, 256  512        ['re_lu_204[0][0]']              \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_206 (ReLU)               (None, 32, 256, 256  0           ['batch_normalization_206[0][0]']\n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 32, 256, 256  64         ['conv3d_transpose_63[0][0]']    \n",
      " Normalization)                 , 16)                                                             \n",
      "                                                                                                  \n",
      " add_95 (Add)                   (None, 32, 256, 256  0           ['re_lu_206[0][0]',              \n",
      "                                , 16)                             'batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_207 (ReLU)               (None, 32, 256, 256  0           ['add_95[0][0]']                 \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_279 (Conv3D)            (None, 32, 256, 256  5196        ['re_lu_207[0][0]']              \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 32, 256, 256  0           ['conv3d_279[0][0]']             \n",
      "                                , 12)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,139,416\n",
      "Trainable params: 8,134,648\n",
      "Non-trainable params: 4,768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('AttResUnet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'])\n",
    "output = resAtt_unet3d(yshape[params['subset']][-1],params['mode'],features,params['normalization'])\n",
    "attres_unet_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "attres_unet_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])\n",
    "attres_unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SESSION ID: Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30 batchnorm 4\n",
      "Epoch 1/100\n",
      "      6/Unknown - 53s 1s/step - loss: 14.6480 - eval_dice: 0.9328WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4435s vs `on_train_batch_end` time: 0.8625s). Check your callbacks.\n",
      "     37/Unknown - 95s 1s/step - loss: 13.9282 - eval_dice: 0.8818\n",
      "Epoch 1: val_loss improved from inf to 13.37894, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 104s 2s/step - loss: 13.9282 - eval_dice: 0.8818 - val_loss: 13.3789 - val_eval_dice: 0.7883 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 12.4251 - eval_dice: 0.6105\n",
      "Epoch 2: val_loss improved from 13.37894 to 11.78835, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 94s 2s/step - loss: 12.4251 - eval_dice: 0.6105 - val_loss: 11.7884 - val_eval_dice: 0.3794 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.4216 - eval_dice: 0.2603\n",
      "Epoch 3: val_loss improved from 11.78835 to 11.26140, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 93s 2s/step - loss: 11.4216 - eval_dice: 0.2603 - val_loss: 11.2614 - val_eval_dice: 0.1407 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.2016 - eval_dice: 0.1508\n",
      "Epoch 4: val_loss improved from 11.26140 to 11.18895, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 101s 2s/step - loss: 11.2016 - eval_dice: 0.1508 - val_loss: 11.1890 - val_eval_dice: 0.0982 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1487 - eval_dice: 0.1220\n",
      "Epoch 5: val_loss improved from 11.18895 to 11.18036, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 11.1487 - eval_dice: 0.1220 - val_loss: 11.1804 - val_eval_dice: 0.0901 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1357 - eval_dice: 0.1094\n",
      "Epoch 6: val_loss improved from 11.18036 to 11.14834, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 93s 1s/step - loss: 11.1357 - eval_dice: 0.1094 - val_loss: 11.1483 - val_eval_dice: 0.0758 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1268 - eval_dice: 0.1013\n",
      "Epoch 7: val_loss did not improve from 11.14834\n",
      "37/37 [==============================] - 92s 1s/step - loss: 11.1268 - eval_dice: 0.1013 - val_loss: 11.1525 - val_eval_dice: 0.0763 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1265 - eval_dice: 0.1013\n",
      "Epoch 8: val_loss did not improve from 11.14834\n",
      "37/37 [==============================] - 93s 2s/step - loss: 11.1265 - eval_dice: 0.1013 - val_loss: 11.1526 - val_eval_dice: 0.0754 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1159 - eval_dice: 0.0996\n",
      "Epoch 9: val_loss did not improve from 11.14834\n",
      "37/37 [==============================] - 93s 1s/step - loss: 11.1159 - eval_dice: 0.0996 - val_loss: 11.1485 - val_eval_dice: 0.0731 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1119 - eval_dice: 0.0964\n",
      "Epoch 10: val_loss improved from 11.14834 to 11.14294, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 94s 2s/step - loss: 11.1119 - eval_dice: 0.0964 - val_loss: 11.1429 - val_eval_dice: 0.0702 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1088 - eval_dice: 0.0967\n",
      "Epoch 11: val_loss did not improve from 11.14294\n",
      "37/37 [==============================] - 99s 2s/step - loss: 11.1088 - eval_dice: 0.0967 - val_loss: 11.1524 - val_eval_dice: 0.0737 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1052 - eval_dice: 0.0914\n",
      "Epoch 12: val_loss did not improve from 11.14294\n",
      "37/37 [==============================] - 98s 2s/step - loss: 11.1052 - eval_dice: 0.0914 - val_loss: 11.1700 - val_eval_dice: 0.0826 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1058 - eval_dice: 0.0914\n",
      "Epoch 13: val_loss did not improve from 11.14294\n",
      "37/37 [==============================] - 99s 2s/step - loss: 11.1058 - eval_dice: 0.0914 - val_loss: 11.1552 - val_eval_dice: 0.0742 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1055 - eval_dice: 0.0943\n",
      "Epoch 14: val_loss did not improve from 11.14294\n",
      "37/37 [==============================] - 102s 2s/step - loss: 11.1055 - eval_dice: 0.0943 - val_loss: 11.1560 - val_eval_dice: 0.0737 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1027 - eval_dice: 0.0878\n",
      "Epoch 15: val_loss improved from 11.14294 to 11.13662, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 99s 2s/step - loss: 11.1027 - eval_dice: 0.0878 - val_loss: 11.1366 - val_eval_dice: 0.0665 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1007 - eval_dice: 0.0886\n",
      "Epoch 16: val_loss improved from 11.13662 to 11.13321, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 93s 1s/step - loss: 11.1007 - eval_dice: 0.0886 - val_loss: 11.1332 - val_eval_dice: 0.0660 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1017 - eval_dice: 0.0922\n",
      "Epoch 17: val_loss did not improve from 11.13321\n",
      "37/37 [==============================] - 94s 1s/step - loss: 11.1017 - eval_dice: 0.0922 - val_loss: 11.1655 - val_eval_dice: 0.0773 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1019 - eval_dice: 0.0910\n",
      "Epoch 18: val_loss did not improve from 11.13321\n",
      "37/37 [==============================] - 92s 1s/step - loss: 11.1019 - eval_dice: 0.0910 - val_loss: 11.1439 - val_eval_dice: 0.0710 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.1014 - eval_dice: 0.0926\n",
      "Epoch 19: val_loss did not improve from 11.13321\n",
      "37/37 [==============================] - 94s 2s/step - loss: 11.1014 - eval_dice: 0.0926 - val_loss: 11.1518 - val_eval_dice: 0.0757 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0966 - eval_dice: 0.0881\n",
      "Epoch 20: val_loss did not improve from 11.13321\n",
      "37/37 [==============================] - 93s 2s/step - loss: 11.0966 - eval_dice: 0.0881 - val_loss: 11.1356 - val_eval_dice: 0.0685 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0983 - eval_dice: 0.0929\n",
      "Epoch 21: val_loss did not improve from 11.13321\n",
      "37/37 [==============================] - 94s 2s/step - loss: 11.0983 - eval_dice: 0.0929 - val_loss: 11.1524 - val_eval_dice: 0.0801 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0851 - eval_dice: 0.0909\n",
      "Epoch 22: val_loss improved from 11.13321 to 11.09624, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 100s 2s/step - loss: 11.0851 - eval_dice: 0.0909 - val_loss: 11.0962 - val_eval_dice: 0.0625 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0717 - eval_dice: 0.0902\n",
      "Epoch 23: val_loss did not improve from 11.09624\n",
      "37/37 [==============================] - 100s 2s/step - loss: 11.0717 - eval_dice: 0.0902 - val_loss: 11.1102 - val_eval_dice: 0.0721 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0484 - eval_dice: 0.0882\n",
      "Epoch 24: val_loss improved from 11.09624 to 11.06006, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 101s 2s/step - loss: 11.0484 - eval_dice: 0.0882 - val_loss: 11.0601 - val_eval_dice: 0.0552 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0281 - eval_dice: 0.0871\n",
      "Epoch 25: val_loss did not improve from 11.06006\n",
      "37/37 [==============================] - 95s 2s/step - loss: 11.0281 - eval_dice: 0.0871 - val_loss: 11.0878 - val_eval_dice: 0.0698 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 11.0090 - eval_dice: 0.0855\n",
      "Epoch 26: val_loss improved from 11.06006 to 11.05299, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 93s 2s/step - loss: 11.0090 - eval_dice: 0.0855 - val_loss: 11.0530 - val_eval_dice: 0.0596 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.9817 - eval_dice: 0.0833\n",
      "Epoch 27: val_loss improved from 11.05299 to 11.02499, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 93s 2s/step - loss: 10.9817 - eval_dice: 0.0833 - val_loss: 11.0250 - val_eval_dice: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.9645 - eval_dice: 0.0864\n",
      "Epoch 28: val_loss did not improve from 11.02499\n",
      "37/37 [==============================] - 100s 2s/step - loss: 10.9645 - eval_dice: 0.0864 - val_loss: 11.0335 - val_eval_dice: 0.0660 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.9323 - eval_dice: 0.0824\n",
      "Epoch 29: val_loss improved from 11.02499 to 10.98643, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.9323 - eval_dice: 0.0824 - val_loss: 10.9864 - val_eval_dice: 0.0529 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8805 - eval_dice: 0.0733\n",
      "Epoch 30: val_loss improved from 10.98643 to 10.95351, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 93s 2s/step - loss: 10.8805 - eval_dice: 0.0733 - val_loss: 10.9535 - val_eval_dice: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8625 - eval_dice: 0.0746\n",
      "Epoch 31: val_loss improved from 10.95351 to 10.92077, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.8625 - eval_dice: 0.0746 - val_loss: 10.9208 - val_eval_dice: 0.0470 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8337 - eval_dice: 0.0738\n",
      "Epoch 32: val_loss improved from 10.92077 to 10.89411, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 101s 2s/step - loss: 10.8337 - eval_dice: 0.0738 - val_loss: 10.8941 - val_eval_dice: 0.0455 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.8022 - eval_dice: 0.0788\n",
      "Epoch 33: val_loss did not improve from 10.89411\n",
      "37/37 [==============================] - 102s 2s/step - loss: 10.8022 - eval_dice: 0.0788 - val_loss: 10.8962 - val_eval_dice: 0.0485 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.7800 - eval_dice: 0.0743\n",
      "Epoch 34: val_loss improved from 10.89411 to 10.85115, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 97s 2s/step - loss: 10.7800 - eval_dice: 0.0743 - val_loss: 10.8511 - val_eval_dice: 0.0449 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.7499 - eval_dice: 0.0745\n",
      "Epoch 35: val_loss did not improve from 10.85115\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.7499 - eval_dice: 0.0745 - val_loss: 10.8512 - val_eval_dice: 0.0422 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.7229 - eval_dice: 0.0759\n",
      "Epoch 36: val_loss improved from 10.85115 to 10.83883, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 97s 2s/step - loss: 10.7229 - eval_dice: 0.0759 - val_loss: 10.8388 - val_eval_dice: 0.0463 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.6938 - eval_dice: 0.0738\n",
      "Epoch 37: val_loss improved from 10.83883 to 10.81269, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 98s 2s/step - loss: 10.6938 - eval_dice: 0.0738 - val_loss: 10.8127 - val_eval_dice: 0.0412 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.6777 - eval_dice: 0.0745\n",
      "Epoch 38: val_loss improved from 10.81269 to 10.78619, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.6777 - eval_dice: 0.0745 - val_loss: 10.7862 - val_eval_dice: 0.0463 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.6358 - eval_dice: 0.0749\n",
      "Epoch 39: val_loss improved from 10.78619 to 10.76884, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 97s 2s/step - loss: 10.6358 - eval_dice: 0.0749 - val_loss: 10.7688 - val_eval_dice: 0.0485 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.5847 - eval_dice: 0.0765\n",
      "Epoch 40: val_loss improved from 10.76884 to 10.75186, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 102s 2s/step - loss: 10.5847 - eval_dice: 0.0765 - val_loss: 10.7519 - val_eval_dice: 0.0520 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.5392 - eval_dice: 0.0740\n",
      "Epoch 41: val_loss improved from 10.75186 to 10.73198, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 99s 2s/step - loss: 10.5392 - eval_dice: 0.0740 - val_loss: 10.7320 - val_eval_dice: 0.0629 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.5010 - eval_dice: 0.0727\n",
      "Epoch 42: val_loss improved from 10.73198 to 10.68635, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 100s 2s/step - loss: 10.5010 - eval_dice: 0.0727 - val_loss: 10.6863 - val_eval_dice: 0.0561 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.4568 - eval_dice: 0.0738\n",
      "Epoch 43: val_loss improved from 10.68635 to 10.62352, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 97s 2s/step - loss: 10.4568 - eval_dice: 0.0738 - val_loss: 10.6235 - val_eval_dice: 0.0406 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.4246 - eval_dice: 0.0757\n",
      "Epoch 44: val_loss did not improve from 10.62352\n",
      "37/37 [==============================] - 94s 2s/step - loss: 10.4246 - eval_dice: 0.0757 - val_loss: 10.6272 - val_eval_dice: 0.0449 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.3836 - eval_dice: 0.0732\n",
      "Epoch 45: val_loss improved from 10.62352 to 10.58252, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.3836 - eval_dice: 0.0732 - val_loss: 10.5825 - val_eval_dice: 0.0452 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.3457 - eval_dice: 0.0703\n",
      "Epoch 46: val_loss improved from 10.58252 to 10.57169, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.3457 - eval_dice: 0.0703 - val_loss: 10.5717 - val_eval_dice: 0.0486 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.3228 - eval_dice: 0.0760\n",
      "Epoch 47: val_loss improved from 10.57169 to 10.55989, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 94s 2s/step - loss: 10.3228 - eval_dice: 0.0760 - val_loss: 10.5599 - val_eval_dice: 0.0543 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.3063 - eval_dice: 0.0793\n",
      "Epoch 48: val_loss improved from 10.55989 to 10.55025, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.3063 - eval_dice: 0.0793 - val_loss: 10.5503 - val_eval_dice: 0.0554 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.2824 - eval_dice: 0.0782\n",
      "Epoch 49: val_loss improved from 10.55025 to 10.54204, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.2824 - eval_dice: 0.0782 - val_loss: 10.5420 - val_eval_dice: 0.0496 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.2678 - eval_dice: 0.0722\n",
      "Epoch 50: val_loss improved from 10.54204 to 10.53347, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 93s 2s/step - loss: 10.2678 - eval_dice: 0.0722 - val_loss: 10.5335 - val_eval_dice: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.2751 - eval_dice: 0.0741\n",
      "Epoch 51: val_loss did not improve from 10.53347\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.2751 - eval_dice: 0.0741 - val_loss: 10.5659 - val_eval_dice: 0.0450 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.2533 - eval_dice: 0.0712\n",
      "Epoch 52: val_loss did not improve from 10.53347\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.2533 - eval_dice: 0.0712 - val_loss: 10.5400 - val_eval_dice: 0.0536 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.2187 - eval_dice: 0.0740\n",
      "Epoch 53: val_loss improved from 10.53347 to 10.49458, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.2187 - eval_dice: 0.0740 - val_loss: 10.4946 - val_eval_dice: 0.0499 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.2235 - eval_dice: 0.0715\n",
      "Epoch 54: val_loss improved from 10.49458 to 10.48689, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.2235 - eval_dice: 0.0715 - val_loss: 10.4869 - val_eval_dice: 0.0487 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.1846 - eval_dice: 0.0700\n",
      "Epoch 55: val_loss improved from 10.48689 to 10.41721, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.1846 - eval_dice: 0.0700 - val_loss: 10.4172 - val_eval_dice: 0.0443 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.1583 - eval_dice: 0.0742\n",
      "Epoch 56: val_loss improved from 10.41721 to 10.40216, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.1583 - eval_dice: 0.0742 - val_loss: 10.4022 - val_eval_dice: 0.0443 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.1715 - eval_dice: 0.0741\n",
      "Epoch 57: val_loss did not improve from 10.40216\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.1715 - eval_dice: 0.0741 - val_loss: 10.4450 - val_eval_dice: 0.0559 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.1414 - eval_dice: 0.0673\n",
      "Epoch 58: val_loss improved from 10.40216 to 10.36740, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 10.1414 - eval_dice: 0.0673 - val_loss: 10.3674 - val_eval_dice: 0.0396 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.1305 - eval_dice: 0.0732\n",
      "Epoch 59: val_loss did not improve from 10.36740\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.1305 - eval_dice: 0.0732 - val_loss: 10.3702 - val_eval_dice: 0.0408 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.1062 - eval_dice: 0.0667\n",
      "Epoch 60: val_loss did not improve from 10.36740\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.1062 - eval_dice: 0.0667 - val_loss: 10.3824 - val_eval_dice: 0.0511 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0985 - eval_dice: 0.0692\n",
      "Epoch 61: val_loss improved from 10.36740 to 10.34061, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.0985 - eval_dice: 0.0692 - val_loss: 10.3406 - val_eval_dice: 0.0444 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0741 - eval_dice: 0.0692\n",
      "Epoch 62: val_loss did not improve from 10.34061\n",
      "37/37 [==============================] - 94s 2s/step - loss: 10.0741 - eval_dice: 0.0692 - val_loss: 10.3460 - val_eval_dice: 0.0429 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0811 - eval_dice: 0.0694\n",
      "Epoch 63: val_loss did not improve from 10.34061\n",
      "37/37 [==============================] - 94s 2s/step - loss: 10.0811 - eval_dice: 0.0694 - val_loss: 10.3452 - val_eval_dice: 0.0491 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0621 - eval_dice: 0.0702\n",
      "Epoch 64: val_loss did not improve from 10.34061\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.0621 - eval_dice: 0.0702 - val_loss: 10.3466 - val_eval_dice: 0.0385 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0251 - eval_dice: 0.0665\n",
      "Epoch 65: val_loss improved from 10.34061 to 10.29506, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 94s 2s/step - loss: 10.0251 - eval_dice: 0.0665 - val_loss: 10.2951 - val_eval_dice: 0.0424 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0359 - eval_dice: 0.0659\n",
      "Epoch 66: val_loss did not improve from 10.29506\n",
      "37/37 [==============================] - 94s 2s/step - loss: 10.0359 - eval_dice: 0.0659 - val_loss: 10.3237 - val_eval_dice: 0.0386 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 10.0300 - eval_dice: 0.0698\n",
      "Epoch 67: val_loss did not improve from 10.29506\n",
      "37/37 [==============================] - 95s 2s/step - loss: 10.0300 - eval_dice: 0.0698 - val_loss: 10.3042 - val_eval_dice: 0.0450 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9971 - eval_dice: 0.0686\n",
      "Epoch 68: val_loss did not improve from 10.29506\n",
      "37/37 [==============================] - 93s 2s/step - loss: 9.9971 - eval_dice: 0.0686 - val_loss: 10.3162 - val_eval_dice: 0.0484 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9825 - eval_dice: 0.0668\n",
      "Epoch 69: val_loss improved from 10.29506 to 10.26101, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.9825 - eval_dice: 0.0668 - val_loss: 10.2610 - val_eval_dice: 0.0352 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9768 - eval_dice: 0.0670\n",
      "Epoch 70: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.9768 - eval_dice: 0.0670 - val_loss: 10.3234 - val_eval_dice: 0.0370 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9810 - eval_dice: 0.0689\n",
      "Epoch 71: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.9810 - eval_dice: 0.0689 - val_loss: 10.3144 - val_eval_dice: 0.0553 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9851 - eval_dice: 0.0718\n",
      "Epoch 72: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.9851 - eval_dice: 0.0718 - val_loss: 10.2903 - val_eval_dice: 0.0457 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9841 - eval_dice: 0.0736\n",
      "Epoch 73: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.9841 - eval_dice: 0.0736 - val_loss: 10.2919 - val_eval_dice: 0.0467 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9622 - eval_dice: 0.0722\n",
      "Epoch 74: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 94s 2s/step - loss: 9.9622 - eval_dice: 0.0722 - val_loss: 10.2772 - val_eval_dice: 0.0457 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9814 - eval_dice: 0.0797\n",
      "Epoch 75: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 96s 2s/step - loss: 9.9814 - eval_dice: 0.0797 - val_loss: 10.3046 - val_eval_dice: 0.0582 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9551 - eval_dice: 0.0733\n",
      "Epoch 76: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.9551 - eval_dice: 0.0733 - val_loss: 10.2798 - val_eval_dice: 0.0472 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9601 - eval_dice: 0.0705\n",
      "Epoch 77: val_loss did not improve from 10.26101\n",
      "37/37 [==============================] - 93s 2s/step - loss: 9.9601 - eval_dice: 0.0705 - val_loss: 10.3065 - val_eval_dice: 0.0435 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9448 - eval_dice: 0.0699\n",
      "Epoch 78: val_loss improved from 10.26101 to 10.25729, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 98s 2s/step - loss: 9.9448 - eval_dice: 0.0699 - val_loss: 10.2573 - val_eval_dice: 0.0449 - lr: 2.0000e-05\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9331 - eval_dice: 0.0762\n",
      "Epoch 79: val_loss improved from 10.25729 to 10.24193, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 100s 2s/step - loss: 9.9331 - eval_dice: 0.0762 - val_loss: 10.2419 - val_eval_dice: 0.0470 - lr: 2.0000e-05\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9242 - eval_dice: 0.0764\n",
      "Epoch 80: val_loss did not improve from 10.24193\n",
      "37/37 [==============================] - 98s 2s/step - loss: 9.9242 - eval_dice: 0.0764 - val_loss: 10.2488 - val_eval_dice: 0.0468 - lr: 2.0000e-05\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9224 - eval_dice: 0.0734\n",
      "Epoch 81: val_loss did not improve from 10.24193\n",
      "37/37 [==============================] - 96s 2s/step - loss: 9.9224 - eval_dice: 0.0734 - val_loss: 10.2463 - val_eval_dice: 0.0449 - lr: 2.0000e-05\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9031 - eval_dice: 0.0669\n",
      "Epoch 82: val_loss improved from 10.24193 to 10.23200, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 94s 2s/step - loss: 9.9031 - eval_dice: 0.0669 - val_loss: 10.2320 - val_eval_dice: 0.0424 - lr: 2.0000e-05\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9161 - eval_dice: 0.0740\n",
      "Epoch 83: val_loss did not improve from 10.23200\n",
      "37/37 [==============================] - 94s 2s/step - loss: 9.9161 - eval_dice: 0.0740 - val_loss: 10.2408 - val_eval_dice: 0.0460 - lr: 2.0000e-05\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9068 - eval_dice: 0.0706\n",
      "Epoch 84: val_loss did not improve from 10.23200\n",
      "37/37 [==============================] - 94s 2s/step - loss: 9.9068 - eval_dice: 0.0706 - val_loss: 10.2334 - val_eval_dice: 0.0449 - lr: 2.0000e-05\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9018 - eval_dice: 0.0709\n",
      "Epoch 85: val_loss improved from 10.23200 to 10.23142, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 9.9018 - eval_dice: 0.0709 - val_loss: 10.2314 - val_eval_dice: 0.0446 - lr: 2.0000e-05\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9029 - eval_dice: 0.0751\n",
      "Epoch 86: val_loss did not improve from 10.23142\n",
      "37/37 [==============================] - 94s 2s/step - loss: 9.9029 - eval_dice: 0.0751 - val_loss: 10.2423 - val_eval_dice: 0.0460 - lr: 2.0000e-05\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8989 - eval_dice: 0.0720\n",
      "Epoch 87: val_loss improved from 10.23142 to 10.22509, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 9.8989 - eval_dice: 0.0720 - val_loss: 10.2251 - val_eval_dice: 0.0432 - lr: 2.0000e-05\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9014 - eval_dice: 0.0720\n",
      "Epoch 88: val_loss did not improve from 10.22509\n",
      "37/37 [==============================] - 96s 2s/step - loss: 9.9014 - eval_dice: 0.0720 - val_loss: 10.2252 - val_eval_dice: 0.0462 - lr: 2.0000e-05\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8950 - eval_dice: 0.0730\n",
      "Epoch 89: val_loss did not improve from 10.22509\n",
      "37/37 [==============================] - 93s 1s/step - loss: 9.8950 - eval_dice: 0.0730 - val_loss: 10.2412 - val_eval_dice: 0.0452 - lr: 2.0000e-05\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8964 - eval_dice: 0.0729\n",
      "Epoch 90: val_loss improved from 10.22509 to 10.22003, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 103s 2s/step - loss: 9.8964 - eval_dice: 0.0729 - val_loss: 10.2200 - val_eval_dice: 0.0450 - lr: 2.0000e-05\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8816 - eval_dice: 0.0694\n",
      "Epoch 91: val_loss improved from 10.22003 to 10.21883, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 105s 2s/step - loss: 9.8816 - eval_dice: 0.0694 - val_loss: 10.2188 - val_eval_dice: 0.0438 - lr: 2.0000e-05\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8848 - eval_dice: 0.0718\n",
      "Epoch 92: val_loss improved from 10.21883 to 10.21423, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 106s 2s/step - loss: 9.8848 - eval_dice: 0.0718 - val_loss: 10.2142 - val_eval_dice: 0.0439 - lr: 2.0000e-05\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.9015 - eval_dice: 0.0778\n",
      "Epoch 93: val_loss did not improve from 10.21423\n",
      "37/37 [==============================] - 101s 2s/step - loss: 9.9015 - eval_dice: 0.0778 - val_loss: 10.2235 - val_eval_dice: 0.0464 - lr: 2.0000e-05\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8690 - eval_dice: 0.0653\n",
      "Epoch 94: val_loss did not improve from 10.21423\n",
      "37/37 [==============================] - 99s 2s/step - loss: 9.8690 - eval_dice: 0.0653 - val_loss: 10.2145 - val_eval_dice: 0.0429 - lr: 2.0000e-05\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8865 - eval_dice: 0.0711\n",
      "Epoch 95: val_loss did not improve from 10.21423\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.8865 - eval_dice: 0.0711 - val_loss: 10.2205 - val_eval_dice: 0.0431 - lr: 2.0000e-05\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8776 - eval_dice: 0.0723\n",
      "Epoch 96: val_loss did not improve from 10.21423\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.8776 - eval_dice: 0.0723 - val_loss: 10.2182 - val_eval_dice: 0.0441 - lr: 2.0000e-05\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8714 - eval_dice: 0.0729\n",
      "Epoch 97: val_loss did not improve from 10.21423\n",
      "37/37 [==============================] - 95s 2s/step - loss: 9.8714 - eval_dice: 0.0729 - val_loss: 10.2302 - val_eval_dice: 0.0439 - lr: 2.0000e-05\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8700 - eval_dice: 0.0721\n",
      "Epoch 98: val_loss improved from 10.21423 to 10.21215, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 96s 2s/step - loss: 9.8700 - eval_dice: 0.0721 - val_loss: 10.2121 - val_eval_dice: 0.0441 - lr: 2.0000e-05\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8578 - eval_dice: 0.0718\n",
      "Epoch 99: val_loss improved from 10.21215 to 10.19552, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/resattunet3d_(2024-07-17)/15.51.30\\cp.ckpt\n",
      "37/37 [==============================] - 99s 2s/step - loss: 9.8578 - eval_dice: 0.0718 - val_loss: 10.1955 - val_eval_dice: 0.0442 - lr: 2.0000e-05\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - ETA: 0s - loss: 9.8525 - eval_dice: 0.0687\n",
      "Epoch 100: val_loss did not improve from 10.19552\n",
      "37/37 [==============================] - 105s 2s/step - loss: 9.8525 - eval_dice: 0.0687 - val_loss: 10.2124 - val_eval_dice: 0.0435 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING SESSION ID:', training_session_path, params['normalization'], batch_size)\n",
    "\n",
    "history1 = attres_unet_model.fit(\n",
    "                train_axial,\n",
    "                epochs=100,\n",
    "                validation_data=val_axial,\n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was saved during training, reconstruction must be made with the weights. Reusing the model of training (same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/residualUnet3d(2024-07-27)/15.51.55/cp.ckpt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/Eduardo/Desktop/dataortho_edu/ubuntu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/unet3d_GN(2023-12-20)/12_53_15/cp.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Eduardo/Desktop/dataortho_edu/ubuntu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/GroupNorm/unet3d_GN(2023-12-20)/12_53_15/cp.ckpt'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current_model = res_unet_model \n",
    "#current_model = attres_unet_model\n",
    "current_model = unet3d_model\n",
    "#current_model = attunet_model\n",
    "current_file_path = file_path\n",
    "current_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves (Current fitted model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history1.history\n",
    "#history_dict = history1_unet.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "visualize_learning_curves(epochs,train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold cross validation - Axial Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'augment': True,\n",
       " 'mode': 'train',\n",
       " 'seed': 42,\n",
       " 'subset': 'DATASET_AXIAL',\n",
       " 'interpolation': 'Linear Interpolation',\n",
       " 'normalization': 'batchnorm',\n",
       " 'total_train_samples': 0,\n",
       " 'total_val_samples': 0,\n",
       " 'lr': 0.0001,\n",
       " 'loss': 'dice+ce',\n",
       " 'dropout': 0.2,\n",
       " 'batch_size': 2,\n",
       " 'norm_params_minmax': None,\n",
       " 'norm_params_meanstd': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['normalization'] =  'batchnorm'\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_cross_validation(subset_dir, test_subjects,fold_idx, n_folds):\n",
    "    tfrecords_paths = create_subject_tfrpaths(subset_dir,test_subjects)\n",
    "    #subject_paths_array = np.array(subject_paths)\n",
    "\n",
    "    # perform cross-validation\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    folds = list(kf.split(tfrecords_paths))\n",
    "\n",
    "    # get the current fold data\n",
    "    train_indices, val_indices = folds[fold_idx]\n",
    "    train_paths = [tfrecords_paths[i] for i in train_indices]\n",
    "    val_paths = [tfrecords_paths[i] for i in val_indices]\n",
    "\n",
    "    return train_paths, val_paths\n",
    "\n",
    "def train_fold(fold_idx, n_folds, params, tfrecords_dir, test_subjects, batch_size, seed):\n",
    "    data_dir = data_dir = os.path.join(tfrecords_dir,params['subset'])\n",
    "    logs_and_model_path = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "    test_paths = parse_test_tfrecords(data_dir, test_subjects[params['subset']])\n",
    "    \n",
    "    train_paths, val_paths = subset_cross_validation(data_dir, test_subjects[params['subset']], fold_idx, n_folds)\n",
    "    \n",
    "    normalization_params_train = get_norm_params(train_paths,0)\n",
    "\n",
    "    #norm_params_path = os.path.join(logs_and_model_path, f'fold_{fold_idx + 1}_norm_params.json')\n",
    "    #with open(norm_params_path, 'w') as f:\n",
    "    #    json.dump(normalization_params_train, f)\n",
    "\n",
    "    print(f\"Fold {fold_idx + 1}/{n_folds}\")\n",
    "    print(\"Number of training tuple paths:\", len(train_paths))\n",
    "    print(\"Number of validation tuple paths:\", len(val_paths))\n",
    "    print(\"Number of test tuple paths:\", len(test_paths))\n",
    "    print(\"Normalization parameters training:\", normalization_params_train)\n",
    "    print(\"Layer Normalization: \", params['normalization'])\n",
    "    \n",
    "    params['total_train_samples'] = len(train_paths)\n",
    "    params['total_val_samples'] = len(val_paths)\n",
    "    \n",
    "    train_d = train_tfr_fn(train_paths, normalization_params_train, 0, batch_size, seed, params)\n",
    "    val_ds = val_tfr_fn(val_paths, normalization_params_train, batch_size)\n",
    "    \n",
    "    if params['normalization'] == 'batchnorm':\n",
    "        training_session_path = f'Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_{fold_idx + 1}_{datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\")}'\n",
    "        #norm_params_path = os.path.join(f'Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_{fold_idx + 1}_{datetime.datetime.now().strftime(\"(%Y-%m-%d)\")}', f'fold_{fold_idx + 1}_norm_params.json')\n",
    "\n",
    "    else:\n",
    "        training_session_path = f'Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_{fold_idx + 1}_{datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\")}'\n",
    "        #norm_params_path = os.path.join(f'Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_{fold_idx + 1}_{datetime.datetime.now().strftime(\"(%Y-%m-%d)\")}', f'fold_{fold_idx + 1}_norm_params.json')\n",
    "    file_path, callbacks_list = prepareCallbacks(training_session_path, logs_and_model_path)\n",
    "\n",
    "\n",
    "    features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "    output = unet3d_mod(yshape[params['subset']][-1], params['mode'], features, params['normalization'])\n",
    "    unet3d_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "    unet3d_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                         loss=make_loss, \n",
    "                         metrics=['accuracy', eval_dice])\n",
    "    \n",
    "    history = unet3d_model.fit(\n",
    "        train_d,\n",
    "        epochs=60,\n",
    "        validation_data=val_ds, \n",
    "        callbacks=callbacks_list\n",
    "    )    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_cross_val(n_folds, params, resampled_dir, test_subjects,batch_size,seed):\n",
    "    history_reg = []\n",
    "    for fold_id in range(n_folds):\n",
    "        # fold_idx, n_folds, params, log_and_model_path, resampled_dir, test_subjects, batch_size, seed\n",
    "        history = train_fold(fold_id,n_folds, params, resampled_dir, test_subjects, batch_size, seed)\n",
    "        history_reg.append(history)\n",
    "    return history_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Number of training tuple paths: 148\n",
      "Number of validation tuple paths: 38\n",
      "Number of test tuple paths: 48\n",
      "Normalization parameters training: (0.0, 2701.6875)\n",
      "Layer Normalization:  batchnorm\n",
      "WARNING:tensorflow:From c:\\Users\\Eduardo\\miniconda3\\envs\\dataortho_env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Input shape after downsample: (None, 16, 128, 128, 32)\n",
      "Input shape after downsample: (None, 8, 64, 64, 64)\n",
      "Input shape after downsample: (None, 4, 32, 32, 128)\n",
      "Input shape after downsample: (None, 2, 16, 16, 512)\n",
      "Epoch 1/60\n",
      "      6/Unknown - 51s 720ms/step - loss: 14.2842 - accuracy: 0.0872 - eval_dice: 0.9200WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1281s vs `on_train_batch_end` time: 0.5025s). Check your callbacks.\n",
      "     74/Unknown - 94s 631ms/step - loss: 13.0359 - accuracy: 0.4814 - eval_dice: 0.7244\n",
      "Epoch 1: val_loss improved from inf to 12.11227, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 102s 749ms/step - loss: 13.0359 - accuracy: 0.4814 - eval_dice: 0.7244 - val_loss: 12.1123 - val_accuracy: 0.9675 - val_eval_dice: 0.4900 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.5159 - accuracy: 0.8874 - eval_dice: 0.3136\n",
      "Epoch 2: val_loss improved from 12.11227 to 11.32011, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 87s 704ms/step - loss: 11.5159 - accuracy: 0.8874 - eval_dice: 0.3136 - val_loss: 11.3201 - val_accuracy: 0.9927 - val_eval_dice: 0.1753 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.2195 - accuracy: 0.8957 - eval_dice: 0.1626\n",
      "Epoch 3: val_loss improved from 11.32011 to 11.22371, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 86s 705ms/step - loss: 11.2195 - accuracy: 0.8957 - eval_dice: 0.1626 - val_loss: 11.2237 - val_accuracy: 0.9948 - val_eval_dice: 0.1197 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1642 - accuracy: 0.9030 - eval_dice: 0.1245\n",
      "Epoch 4: val_loss improved from 11.22371 to 11.17964, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 87s 702ms/step - loss: 11.1642 - accuracy: 0.9030 - eval_dice: 0.1245 - val_loss: 11.1796 - val_accuracy: 0.9952 - val_eval_dice: 0.0964 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1415 - accuracy: 0.8939 - eval_dice: 0.1134\n",
      "Epoch 5: val_loss did not improve from 11.17964\n",
      "74/74 [==============================] - 88s 698ms/step - loss: 11.1415 - accuracy: 0.8939 - eval_dice: 0.1134 - val_loss: 11.1900 - val_accuracy: 0.9948 - val_eval_dice: 0.0982 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1310 - accuracy: 0.8980 - eval_dice: 0.1062\n",
      "Epoch 6: val_loss improved from 11.17964 to 11.17117, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 89s 715ms/step - loss: 11.1310 - accuracy: 0.8980 - eval_dice: 0.1062 - val_loss: 11.1712 - val_accuracy: 0.9948 - val_eval_dice: 0.0903 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1283 - accuracy: 0.8902 - eval_dice: 0.1089\n",
      "Epoch 7: val_loss improved from 11.17117 to 11.14090, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 89s 715ms/step - loss: 11.1283 - accuracy: 0.8902 - eval_dice: 0.1089 - val_loss: 11.1409 - val_accuracy: 0.9951 - val_eval_dice: 0.0773 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1188 - accuracy: 0.8932 - eval_dice: 0.1031\n",
      "Epoch 8: val_loss did not improve from 11.14090\n",
      "74/74 [==============================] - 87s 703ms/step - loss: 11.1188 - accuracy: 0.8932 - eval_dice: 0.1031 - val_loss: 11.1537 - val_accuracy: 0.9944 - val_eval_dice: 0.0826 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0982 - accuracy: 0.8872 - eval_dice: 0.1009\n",
      "Epoch 9: val_loss improved from 11.14090 to 11.09845, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 87s 703ms/step - loss: 11.0982 - accuracy: 0.8872 - eval_dice: 0.1009 - val_loss: 11.0984 - val_accuracy: 0.9947 - val_eval_dice: 0.0708 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0712 - accuracy: 0.8973 - eval_dice: 0.0930\n",
      "Epoch 10: val_loss improved from 11.09845 to 11.05974, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 92s 711ms/step - loss: 11.0712 - accuracy: 0.8973 - eval_dice: 0.0930 - val_loss: 11.0597 - val_accuracy: 0.9956 - val_eval_dice: 0.0624 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0525 - accuracy: 0.8952 - eval_dice: 0.0917\n",
      "Epoch 11: val_loss did not improve from 11.05974\n",
      "74/74 [==============================] - 91s 713ms/step - loss: 11.0525 - accuracy: 0.8952 - eval_dice: 0.0917 - val_loss: 11.0676 - val_accuracy: 0.9952 - val_eval_dice: 0.0686 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0146 - accuracy: 0.8871 - eval_dice: 0.0908\n",
      "Epoch 12: val_loss improved from 11.05974 to 10.99839, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 90s 709ms/step - loss: 11.0146 - accuracy: 0.8871 - eval_dice: 0.0908 - val_loss: 10.9984 - val_accuracy: 0.9926 - val_eval_dice: 0.0611 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9730 - accuracy: 0.8870 - eval_dice: 0.0866\n",
      "Epoch 13: val_loss did not improve from 10.99839\n",
      "74/74 [==============================] - 89s 714ms/step - loss: 10.9730 - accuracy: 0.8870 - eval_dice: 0.0866 - val_loss: 11.0038 - val_accuracy: 0.9922 - val_eval_dice: 0.0752 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9179 - accuracy: 0.8917 - eval_dice: 0.0821\n",
      "Epoch 14: val_loss improved from 10.99839 to 10.93998, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 89s 715ms/step - loss: 10.9179 - accuracy: 0.8917 - eval_dice: 0.0821 - val_loss: 10.9400 - val_accuracy: 0.9937 - val_eval_dice: 0.0606 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8857 - accuracy: 0.8945 - eval_dice: 0.0789\n",
      "Epoch 15: val_loss improved from 10.93998 to 10.90365, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 89s 722ms/step - loss: 10.8857 - accuracy: 0.8945 - eval_dice: 0.0789 - val_loss: 10.9037 - val_accuracy: 0.9941 - val_eval_dice: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8133 - accuracy: 0.8920 - eval_dice: 0.0804\n",
      "Epoch 16: val_loss improved from 10.90365 to 10.77026, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 99s 790ms/step - loss: 10.8133 - accuracy: 0.8920 - eval_dice: 0.0804 - val_loss: 10.7703 - val_accuracy: 0.9925 - val_eval_dice: 0.0583 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7319 - accuracy: 0.8958 - eval_dice: 0.0764\n",
      "Epoch 17: val_loss improved from 10.77026 to 10.69018, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 98s 794ms/step - loss: 10.7319 - accuracy: 0.8958 - eval_dice: 0.0764 - val_loss: 10.6902 - val_accuracy: 0.9920 - val_eval_dice: 0.0363 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6894 - accuracy: 0.8782 - eval_dice: 0.0834\n",
      "Epoch 18: val_loss improved from 10.69018 to 10.63749, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 97s 781ms/step - loss: 10.6894 - accuracy: 0.8782 - eval_dice: 0.0834 - val_loss: 10.6375 - val_accuracy: 0.9936 - val_eval_dice: 0.0447 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6368 - accuracy: 0.8950 - eval_dice: 0.0726\n",
      "Epoch 19: val_loss improved from 10.63749 to 10.52941, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 94s 738ms/step - loss: 10.6368 - accuracy: 0.8950 - eval_dice: 0.0726 - val_loss: 10.5294 - val_accuracy: 0.9933 - val_eval_dice: 0.0383 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5989 - accuracy: 0.8965 - eval_dice: 0.0720\n",
      "Epoch 20: val_loss did not improve from 10.52941\n",
      "74/74 [==============================] - 91s 730ms/step - loss: 10.5989 - accuracy: 0.8965 - eval_dice: 0.0720 - val_loss: 10.5416 - val_accuracy: 0.9932 - val_eval_dice: 0.0436 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5674 - accuracy: 0.8925 - eval_dice: 0.0728\n",
      "Epoch 21: val_loss improved from 10.52941 to 10.47605, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 92s 732ms/step - loss: 10.5674 - accuracy: 0.8925 - eval_dice: 0.0728 - val_loss: 10.4761 - val_accuracy: 0.9924 - val_eval_dice: 0.0416 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5254 - accuracy: 0.8912 - eval_dice: 0.0733\n",
      "Epoch 22: val_loss improved from 10.47605 to 10.45797, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 92s 740ms/step - loss: 10.5254 - accuracy: 0.8912 - eval_dice: 0.0733 - val_loss: 10.4580 - val_accuracy: 0.9942 - val_eval_dice: 0.0472 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4925 - accuracy: 0.8881 - eval_dice: 0.0743\n",
      "Epoch 23: val_loss did not improve from 10.45797\n",
      "74/74 [==============================] - 93s 731ms/step - loss: 10.4925 - accuracy: 0.8881 - eval_dice: 0.0743 - val_loss: 10.5632 - val_accuracy: 0.9928 - val_eval_dice: 0.0560 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4481 - accuracy: 0.8950 - eval_dice: 0.0713\n",
      "Epoch 24: val_loss improved from 10.45797 to 10.37353, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 90s 732ms/step - loss: 10.4481 - accuracy: 0.8950 - eval_dice: 0.0713 - val_loss: 10.3735 - val_accuracy: 0.9937 - val_eval_dice: 0.0363 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3993 - accuracy: 0.8928 - eval_dice: 0.0726\n",
      "Epoch 25: val_loss did not improve from 10.37353\n",
      "74/74 [==============================] - 94s 760ms/step - loss: 10.3993 - accuracy: 0.8928 - eval_dice: 0.0726 - val_loss: 10.3873 - val_accuracy: 0.9920 - val_eval_dice: 0.0388 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4057 - accuracy: 0.9007 - eval_dice: 0.0695\n",
      "Epoch 26: val_loss did not improve from 10.37353\n",
      "74/74 [==============================] - 95s 759ms/step - loss: 10.4057 - accuracy: 0.9007 - eval_dice: 0.0695 - val_loss: 10.4243 - val_accuracy: 0.9947 - val_eval_dice: 0.0452 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3850 - accuracy: 0.9029 - eval_dice: 0.0694\n",
      "Epoch 27: val_loss did not improve from 10.37353\n",
      "74/74 [==============================] - 95s 767ms/step - loss: 10.3850 - accuracy: 0.9029 - eval_dice: 0.0694 - val_loss: 10.3925 - val_accuracy: 0.9950 - val_eval_dice: 0.0417 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3728 - accuracy: 0.8961 - eval_dice: 0.0712\n",
      "Epoch 28: val_loss improved from 10.37353 to 10.34890, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 97s 776ms/step - loss: 10.3728 - accuracy: 0.8961 - eval_dice: 0.0712 - val_loss: 10.3489 - val_accuracy: 0.9940 - val_eval_dice: 0.0372 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3377 - accuracy: 0.8863 - eval_dice: 0.0760\n",
      "Epoch 29: val_loss improved from 10.34890 to 10.33850, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 92s 733ms/step - loss: 10.3377 - accuracy: 0.8863 - eval_dice: 0.0760 - val_loss: 10.3385 - val_accuracy: 0.9944 - val_eval_dice: 0.0344 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3204 - accuracy: 0.8866 - eval_dice: 0.0746\n",
      "Epoch 30: val_loss improved from 10.33850 to 10.31759, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 91s 721ms/step - loss: 10.3204 - accuracy: 0.8866 - eval_dice: 0.0746 - val_loss: 10.3176 - val_accuracy: 0.9960 - val_eval_dice: 0.0357 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3163 - accuracy: 0.8861 - eval_dice: 0.0748\n",
      "Epoch 31: val_loss did not improve from 10.31759\n",
      "74/74 [==============================] - 92s 731ms/step - loss: 10.3163 - accuracy: 0.8861 - eval_dice: 0.0748 - val_loss: 10.3366 - val_accuracy: 0.9948 - val_eval_dice: 0.0470 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2771 - accuracy: 0.9019 - eval_dice: 0.0663\n",
      "Epoch 32: val_loss improved from 10.31759 to 10.27690, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 92s 733ms/step - loss: 10.2771 - accuracy: 0.9019 - eval_dice: 0.0663 - val_loss: 10.2769 - val_accuracy: 0.9952 - val_eval_dice: 0.0312 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2727 - accuracy: 0.8880 - eval_dice: 0.0732\n",
      "Epoch 33: val_loss did not improve from 10.27690\n",
      "74/74 [==============================] - 92s 728ms/step - loss: 10.2727 - accuracy: 0.8880 - eval_dice: 0.0732 - val_loss: 10.3139 - val_accuracy: 0.9961 - val_eval_dice: 0.0481 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2332 - accuracy: 0.8929 - eval_dice: 0.0706\n",
      "Epoch 34: val_loss improved from 10.27690 to 10.19063, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 96s 780ms/step - loss: 10.2332 - accuracy: 0.8929 - eval_dice: 0.0706 - val_loss: 10.1906 - val_accuracy: 0.9949 - val_eval_dice: 0.0315 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2164 - accuracy: 0.8944 - eval_dice: 0.0690\n",
      "Epoch 35: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 94s 761ms/step - loss: 10.2164 - accuracy: 0.8944 - eval_dice: 0.0690 - val_loss: 10.2090 - val_accuracy: 0.9945 - val_eval_dice: 0.0382 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2862 - accuracy: 0.8909 - eval_dice: 0.0714\n",
      "Epoch 36: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 94s 764ms/step - loss: 10.2862 - accuracy: 0.8909 - eval_dice: 0.0714 - val_loss: 10.3104 - val_accuracy: 0.9956 - val_eval_dice: 0.0442 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2940 - accuracy: 0.8885 - eval_dice: 0.0736\n",
      "Epoch 37: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 92s 726ms/step - loss: 10.2940 - accuracy: 0.8885 - eval_dice: 0.0736 - val_loss: 10.2895 - val_accuracy: 0.9936 - val_eval_dice: 0.0455 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2080 - accuracy: 0.8921 - eval_dice: 0.0728\n",
      "Epoch 38: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 92s 726ms/step - loss: 10.2080 - accuracy: 0.8921 - eval_dice: 0.0728 - val_loss: 10.2026 - val_accuracy: 0.9955 - val_eval_dice: 0.0402 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1745 - accuracy: 0.8841 - eval_dice: 0.0795\n",
      "Epoch 39: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 91s 721ms/step - loss: 10.1745 - accuracy: 0.8841 - eval_dice: 0.0795 - val_loss: 10.2401 - val_accuracy: 0.9930 - val_eval_dice: 0.0355 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2100 - accuracy: 0.8867 - eval_dice: 0.0791\n",
      "Epoch 40: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 92s 730ms/step - loss: 10.2100 - accuracy: 0.8867 - eval_dice: 0.0791 - val_loss: 10.1929 - val_accuracy: 0.9953 - val_eval_dice: 0.0355 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1903 - accuracy: 0.8879 - eval_dice: 0.0766\n",
      "Epoch 41: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 93s 736ms/step - loss: 10.1903 - accuracy: 0.8879 - eval_dice: 0.0766 - val_loss: 10.2125 - val_accuracy: 0.9958 - val_eval_dice: 0.0436 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1627 - accuracy: 0.8908 - eval_dice: 0.0734\n",
      "Epoch 42: val_loss did not improve from 10.19063\n",
      "74/74 [==============================] - 92s 740ms/step - loss: 10.1627 - accuracy: 0.8908 - eval_dice: 0.0734 - val_loss: 10.2006 - val_accuracy: 0.9959 - val_eval_dice: 0.0334 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1369 - accuracy: 0.8936 - eval_dice: 0.0712\n",
      "Epoch 43: val_loss improved from 10.19063 to 10.14521, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 98s 789ms/step - loss: 10.1369 - accuracy: 0.8936 - eval_dice: 0.0712 - val_loss: 10.1452 - val_accuracy: 0.9959 - val_eval_dice: 0.0304 - lr: 2.0000e-05\n",
      "Epoch 44/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1123 - accuracy: 0.8907 - eval_dice: 0.0720\n",
      "Epoch 44: val_loss improved from 10.14521 to 10.14106, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 98s 788ms/step - loss: 10.1123 - accuracy: 0.8907 - eval_dice: 0.0720 - val_loss: 10.1411 - val_accuracy: 0.9966 - val_eval_dice: 0.0306 - lr: 2.0000e-05\n",
      "Epoch 45/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1168 - accuracy: 0.8878 - eval_dice: 0.0729\n",
      "Epoch 45: val_loss improved from 10.14106 to 10.13707, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 97s 771ms/step - loss: 10.1168 - accuracy: 0.8878 - eval_dice: 0.0729 - val_loss: 10.1371 - val_accuracy: 0.9965 - val_eval_dice: 0.0280 - lr: 2.0000e-05\n",
      "Epoch 46/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1077 - accuracy: 0.8925 - eval_dice: 0.0700\n",
      "Epoch 46: val_loss did not improve from 10.13707\n",
      "74/74 [==============================] - 93s 730ms/step - loss: 10.1077 - accuracy: 0.8925 - eval_dice: 0.0700 - val_loss: 10.1429 - val_accuracy: 0.9959 - val_eval_dice: 0.0305 - lr: 2.0000e-05\n",
      "Epoch 47/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1083 - accuracy: 0.8943 - eval_dice: 0.0688\n",
      "Epoch 47: val_loss improved from 10.13707 to 10.13541, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_1_(2024-07-19)/22.15.16\\cp.ckpt\n",
      "74/74 [==============================] - 94s 763ms/step - loss: 10.1083 - accuracy: 0.8943 - eval_dice: 0.0688 - val_loss: 10.1354 - val_accuracy: 0.9953 - val_eval_dice: 0.0292 - lr: 2.0000e-05\n",
      "Epoch 48/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0984 - accuracy: 0.8935 - eval_dice: 0.0696\n",
      "Epoch 48: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 97s 781ms/step - loss: 10.0984 - accuracy: 0.8935 - eval_dice: 0.0696 - val_loss: 10.1501 - val_accuracy: 0.9935 - val_eval_dice: 0.0308 - lr: 2.0000e-05\n",
      "Epoch 49/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1024 - accuracy: 0.8924 - eval_dice: 0.0696\n",
      "Epoch 49: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 97s 781ms/step - loss: 10.1024 - accuracy: 0.8924 - eval_dice: 0.0696 - val_loss: 10.1502 - val_accuracy: 0.9942 - val_eval_dice: 0.0313 - lr: 2.0000e-05\n",
      "Epoch 50/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0975 - accuracy: 0.8932 - eval_dice: 0.0696\n",
      "Epoch 50: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 99s 782ms/step - loss: 10.0975 - accuracy: 0.8932 - eval_dice: 0.0696 - val_loss: 10.1506 - val_accuracy: 0.9929 - val_eval_dice: 0.0323 - lr: 2.0000e-05\n",
      "Epoch 51/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0975 - accuracy: 0.8902 - eval_dice: 0.0713\n",
      "Epoch 51: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 92s 727ms/step - loss: 10.0975 - accuracy: 0.8902 - eval_dice: 0.0713 - val_loss: 10.1696 - val_accuracy: 0.9931 - val_eval_dice: 0.0375 - lr: 2.0000e-05\n",
      "Epoch 52/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1175 - accuracy: 0.8865 - eval_dice: 0.0738\n",
      "Epoch 52: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 92s 735ms/step - loss: 10.1175 - accuracy: 0.8865 - eval_dice: 0.0738 - val_loss: 10.1469 - val_accuracy: 0.9943 - val_eval_dice: 0.0329 - lr: 2.0000e-05\n",
      "Epoch 53/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1095 - accuracy: 0.8998 - eval_dice: 0.0674\n",
      "Epoch 53: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 91s 710ms/step - loss: 10.1095 - accuracy: 0.8998 - eval_dice: 0.0674 - val_loss: 10.1514 - val_accuracy: 0.9934 - val_eval_dice: 0.0292 - lr: 2.0000e-05\n",
      "Epoch 54/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1021 - accuracy: 0.8906 - eval_dice: 0.0716\n",
      "Epoch 54: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 91s 727ms/step - loss: 10.1021 - accuracy: 0.8906 - eval_dice: 0.0716 - val_loss: 10.1508 - val_accuracy: 0.9930 - val_eval_dice: 0.0328 - lr: 2.0000e-05\n",
      "Epoch 55/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1018 - accuracy: 0.8922 - eval_dice: 0.0706\n",
      "Epoch 55: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 92s 726ms/step - loss: 10.1018 - accuracy: 0.8922 - eval_dice: 0.0706 - val_loss: 10.1536 - val_accuracy: 0.9931 - val_eval_dice: 0.0330 - lr: 2.0000e-05\n",
      "Epoch 56/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0913 - accuracy: 0.8887 - eval_dice: 0.0721\n",
      "Epoch 56: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 92s 735ms/step - loss: 10.0913 - accuracy: 0.8887 - eval_dice: 0.0721 - val_loss: 10.1465 - val_accuracy: 0.9930 - val_eval_dice: 0.0328 - lr: 4.0000e-06\n",
      "Epoch 57/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0936 - accuracy: 0.8945 - eval_dice: 0.0691\n",
      "Epoch 57: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 91s 734ms/step - loss: 10.0936 - accuracy: 0.8945 - eval_dice: 0.0691 - val_loss: 10.1448 - val_accuracy: 0.9931 - val_eval_dice: 0.0325 - lr: 4.0000e-06\n",
      "Epoch 58/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0949 - accuracy: 0.8928 - eval_dice: 0.0703\n",
      "Epoch 58: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 92s 741ms/step - loss: 10.0949 - accuracy: 0.8928 - eval_dice: 0.0703 - val_loss: 10.1435 - val_accuracy: 0.9930 - val_eval_dice: 0.0323 - lr: 4.0000e-06\n",
      "Epoch 59/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0981 - accuracy: 0.8883 - eval_dice: 0.0728\n",
      "Epoch 59: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 92s 735ms/step - loss: 10.0981 - accuracy: 0.8883 - eval_dice: 0.0728 - val_loss: 10.1423 - val_accuracy: 0.9930 - val_eval_dice: 0.0324 - lr: 4.0000e-06\n",
      "Epoch 60/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1140 - accuracy: 0.8845 - eval_dice: 0.0748\n",
      "Epoch 60: val_loss did not improve from 10.13541\n",
      "74/74 [==============================] - 91s 729ms/step - loss: 10.1140 - accuracy: 0.8845 - eval_dice: 0.0748 - val_loss: 10.1433 - val_accuracy: 0.9931 - val_eval_dice: 0.0332 - lr: 4.0000e-06\n",
      "Fold 2/5\n",
      "Number of training tuple paths: 149\n",
      "Number of validation tuple paths: 37\n",
      "Number of test tuple paths: 48\n",
      "Normalization parameters training: (0.0, 2609.4062)\n",
      "Layer Normalization:  batchnorm\n",
      "Input shape after downsample: (None, 16, 128, 128, 32)\n",
      "Input shape after downsample: (None, 8, 64, 64, 64)\n",
      "Input shape after downsample: (None, 4, 32, 32, 128)\n",
      "Input shape after downsample: (None, 2, 16, 16, 512)\n",
      "Epoch 1/60\n",
      "      6/Unknown - 38s 731ms/step - loss: 14.1218 - accuracy: 0.0525 - eval_dice: 0.9157WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1705s vs `on_train_batch_end` time: 0.5769s). Check your callbacks.\n",
      "     74/Unknown - 83s 667ms/step - loss: 12.9341 - accuracy: 0.5640 - eval_dice: 0.7328\n",
      "Epoch 1: val_loss improved from inf to 11.89259, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 92s 796ms/step - loss: 12.9341 - accuracy: 0.5640 - eval_dice: 0.7328 - val_loss: 11.8926 - val_accuracy: 0.9907 - val_eval_dice: 0.4348 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.4486 - accuracy: 0.8917 - eval_dice: 0.2854\n",
      "Epoch 2: val_loss improved from 11.89259 to 11.27112, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 737ms/step - loss: 11.4486 - accuracy: 0.8917 - eval_dice: 0.2854 - val_loss: 11.2711 - val_accuracy: 0.9981 - val_eval_dice: 0.1581 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.2036 - accuracy: 0.8851 - eval_dice: 0.1622\n",
      "Epoch 3: val_loss improved from 11.27112 to 11.17589, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 739ms/step - loss: 11.2036 - accuracy: 0.8851 - eval_dice: 0.1622 - val_loss: 11.1759 - val_accuracy: 0.9981 - val_eval_dice: 0.1109 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1366 - accuracy: 0.8896 - eval_dice: 0.1328\n",
      "Epoch 4: val_loss improved from 11.17589 to 11.12471, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 741ms/step - loss: 11.1366 - accuracy: 0.8896 - eval_dice: 0.1328 - val_loss: 11.1247 - val_accuracy: 0.9966 - val_eval_dice: 0.0874 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0857 - accuracy: 0.9039 - eval_dice: 0.1094\n",
      "Epoch 5: val_loss improved from 11.12471 to 11.07610, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 92s 732ms/step - loss: 11.0857 - accuracy: 0.9039 - eval_dice: 0.1094 - val_loss: 11.0761 - val_accuracy: 0.9957 - val_eval_dice: 0.0729 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0547 - accuracy: 0.8866 - eval_dice: 0.1077\n",
      "Epoch 6: val_loss improved from 11.07610 to 11.05944, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 92s 733ms/step - loss: 11.0547 - accuracy: 0.8866 - eval_dice: 0.1077 - val_loss: 11.0594 - val_accuracy: 0.9947 - val_eval_dice: 0.0684 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0202 - accuracy: 0.8886 - eval_dice: 0.0998\n",
      "Epoch 7: val_loss improved from 11.05944 to 11.04797, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 744ms/step - loss: 11.0202 - accuracy: 0.8886 - eval_dice: 0.0998 - val_loss: 11.0480 - val_accuracy: 0.9966 - val_eval_dice: 0.0698 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9812 - accuracy: 0.8944 - eval_dice: 0.0911\n",
      "Epoch 8: val_loss improved from 11.04797 to 10.99289, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 751ms/step - loss: 10.9812 - accuracy: 0.8944 - eval_dice: 0.0911 - val_loss: 10.9929 - val_accuracy: 0.9965 - val_eval_dice: 0.0577 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8791 - accuracy: 0.8986 - eval_dice: 0.0810\n",
      "Epoch 9: val_loss improved from 10.99289 to 10.86893, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 92s 740ms/step - loss: 10.8791 - accuracy: 0.8986 - eval_dice: 0.0810 - val_loss: 10.8689 - val_accuracy: 0.9962 - val_eval_dice: 0.0534 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7411 - accuracy: 0.8946 - eval_dice: 0.0798\n",
      "Epoch 10: val_loss improved from 10.86893 to 10.83103, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 739ms/step - loss: 10.7411 - accuracy: 0.8946 - eval_dice: 0.0798 - val_loss: 10.8310 - val_accuracy: 0.9961 - val_eval_dice: 0.0522 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5935 - accuracy: 0.8962 - eval_dice: 0.0749\n",
      "Epoch 11: val_loss improved from 10.83103 to 10.70089, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 739ms/step - loss: 10.5935 - accuracy: 0.8962 - eval_dice: 0.0749 - val_loss: 10.7009 - val_accuracy: 0.9969 - val_eval_dice: 0.0363 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4119 - accuracy: 0.8922 - eval_dice: 0.0745\n",
      "Epoch 12: val_loss improved from 10.70089 to 10.56663, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 749ms/step - loss: 10.4119 - accuracy: 0.8922 - eval_dice: 0.0745 - val_loss: 10.5666 - val_accuracy: 0.9946 - val_eval_dice: 0.0337 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2843 - accuracy: 0.8952 - eval_dice: 0.0719\n",
      "Epoch 13: val_loss improved from 10.56663 to 10.48399, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 97s 796ms/step - loss: 10.2843 - accuracy: 0.8952 - eval_dice: 0.0719 - val_loss: 10.4840 - val_accuracy: 0.9959 - val_eval_dice: 0.0559 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1752 - accuracy: 0.8907 - eval_dice: 0.0752\n",
      "Epoch 14: val_loss improved from 10.48399 to 10.41510, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 98s 774ms/step - loss: 10.1752 - accuracy: 0.8907 - eval_dice: 0.0752 - val_loss: 10.4151 - val_accuracy: 0.9947 - val_eval_dice: 0.0481 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0679 - accuracy: 0.8928 - eval_dice: 0.0751\n",
      "Epoch 15: val_loss improved from 10.41510 to 10.32052, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 96s 784ms/step - loss: 10.0679 - accuracy: 0.8928 - eval_dice: 0.0751 - val_loss: 10.3205 - val_accuracy: 0.9948 - val_eval_dice: 0.0427 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.9357 - accuracy: 0.8871 - eval_dice: 0.0760\n",
      "Epoch 16: val_loss improved from 10.32052 to 10.26820, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 101s 819ms/step - loss: 9.9357 - accuracy: 0.8871 - eval_dice: 0.0760 - val_loss: 10.2682 - val_accuracy: 0.9949 - val_eval_dice: 0.0477 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8455 - accuracy: 0.8924 - eval_dice: 0.0736\n",
      "Epoch 17: val_loss improved from 10.26820 to 10.22890, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 99s 806ms/step - loss: 9.8455 - accuracy: 0.8924 - eval_dice: 0.0736 - val_loss: 10.2289 - val_accuracy: 0.9946 - val_eval_dice: 0.0466 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7955 - accuracy: 0.8874 - eval_dice: 0.0758\n",
      "Epoch 18: val_loss did not improve from 10.22890\n",
      "74/74 [==============================] - 97s 782ms/step - loss: 9.7955 - accuracy: 0.8874 - eval_dice: 0.0758 - val_loss: 10.2436 - val_accuracy: 0.9937 - val_eval_dice: 0.0551 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7739 - accuracy: 0.8955 - eval_dice: 0.0744\n",
      "Epoch 19: val_loss did not improve from 10.22890\n",
      "74/74 [==============================] - 95s 747ms/step - loss: 9.7739 - accuracy: 0.8955 - eval_dice: 0.0744 - val_loss: 10.2372 - val_accuracy: 0.9953 - val_eval_dice: 0.0677 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7467 - accuracy: 0.8892 - eval_dice: 0.0755\n",
      "Epoch 20: val_loss improved from 10.22890 to 10.14917, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 742ms/step - loss: 9.7467 - accuracy: 0.8892 - eval_dice: 0.0755 - val_loss: 10.1492 - val_accuracy: 0.9945 - val_eval_dice: 0.0577 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7243 - accuracy: 0.8937 - eval_dice: 0.0735\n",
      "Epoch 21: val_loss improved from 10.14917 to 10.12085, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 92s 731ms/step - loss: 9.7243 - accuracy: 0.8937 - eval_dice: 0.0735 - val_loss: 10.1209 - val_accuracy: 0.9952 - val_eval_dice: 0.0547 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6775 - accuracy: 0.8874 - eval_dice: 0.0747\n",
      "Epoch 22: val_loss did not improve from 10.12085\n",
      "74/74 [==============================] - 96s 773ms/step - loss: 9.6775 - accuracy: 0.8874 - eval_dice: 0.0747 - val_loss: 10.1698 - val_accuracy: 0.9962 - val_eval_dice: 0.0629 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6584 - accuracy: 0.8879 - eval_dice: 0.0747\n",
      "Epoch 23: val_loss improved from 10.12085 to 10.08247, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 98s 784ms/step - loss: 9.6584 - accuracy: 0.8879 - eval_dice: 0.0747 - val_loss: 10.0825 - val_accuracy: 0.9950 - val_eval_dice: 0.0438 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6480 - accuracy: 0.9021 - eval_dice: 0.0673\n",
      "Epoch 24: val_loss did not improve from 10.08247\n",
      "74/74 [==============================] - 97s 765ms/step - loss: 9.6480 - accuracy: 0.9021 - eval_dice: 0.0673 - val_loss: 10.1171 - val_accuracy: 0.9932 - val_eval_dice: 0.0361 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6335 - accuracy: 0.8959 - eval_dice: 0.0697\n",
      "Epoch 25: val_loss did not improve from 10.08247\n",
      "74/74 [==============================] - 96s 769ms/step - loss: 9.6335 - accuracy: 0.8959 - eval_dice: 0.0697 - val_loss: 10.1170 - val_accuracy: 0.9951 - val_eval_dice: 0.0499 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6167 - accuracy: 0.8900 - eval_dice: 0.0724\n",
      "Epoch 26: val_loss improved from 10.08247 to 10.05612, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 742ms/step - loss: 9.6167 - accuracy: 0.8900 - eval_dice: 0.0724 - val_loss: 10.0561 - val_accuracy: 0.9943 - val_eval_dice: 0.0462 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5720 - accuracy: 0.8938 - eval_dice: 0.0698\n",
      "Epoch 27: val_loss did not improve from 10.05612\n",
      "74/74 [==============================] - 92s 738ms/step - loss: 9.5720 - accuracy: 0.8938 - eval_dice: 0.0698 - val_loss: 10.1004 - val_accuracy: 0.9959 - val_eval_dice: 0.0467 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5763 - accuracy: 0.8872 - eval_dice: 0.0741\n",
      "Epoch 28: val_loss did not improve from 10.05612\n",
      "74/74 [==============================] - 93s 726ms/step - loss: 9.5763 - accuracy: 0.8872 - eval_dice: 0.0741 - val_loss: 10.1013 - val_accuracy: 0.9935 - val_eval_dice: 0.0468 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5740 - accuracy: 0.8872 - eval_dice: 0.0753\n",
      "Epoch 29: val_loss improved from 10.05612 to 10.04866, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 747ms/step - loss: 9.5740 - accuracy: 0.8872 - eval_dice: 0.0753 - val_loss: 10.0487 - val_accuracy: 0.9935 - val_eval_dice: 0.0420 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5681 - accuracy: 0.8918 - eval_dice: 0.0747\n",
      "Epoch 30: val_loss did not improve from 10.04866\n",
      "74/74 [==============================] - 93s 727ms/step - loss: 9.5681 - accuracy: 0.8918 - eval_dice: 0.0747 - val_loss: 10.0833 - val_accuracy: 0.9942 - val_eval_dice: 0.0570 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5746 - accuracy: 0.8863 - eval_dice: 0.0792\n",
      "Epoch 31: val_loss did not improve from 10.04866\n",
      "74/74 [==============================] - 94s 752ms/step - loss: 9.5746 - accuracy: 0.8863 - eval_dice: 0.0792 - val_loss: 10.0914 - val_accuracy: 0.9938 - val_eval_dice: 0.0562 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5674 - accuracy: 0.8815 - eval_dice: 0.0811\n",
      "Epoch 32: val_loss improved from 10.04866 to 10.01407, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 746ms/step - loss: 9.5674 - accuracy: 0.8815 - eval_dice: 0.0811 - val_loss: 10.0141 - val_accuracy: 0.9934 - val_eval_dice: 0.0430 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5192 - accuracy: 0.8956 - eval_dice: 0.0723\n",
      "Epoch 33: val_loss improved from 10.01407 to 10.00707, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 92s 737ms/step - loss: 9.5192 - accuracy: 0.8956 - eval_dice: 0.0723 - val_loss: 10.0071 - val_accuracy: 0.9923 - val_eval_dice: 0.0384 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5194 - accuracy: 0.8901 - eval_dice: 0.0737\n",
      "Epoch 34: val_loss did not improve from 10.00707\n",
      "74/74 [==============================] - 93s 740ms/step - loss: 9.5194 - accuracy: 0.8901 - eval_dice: 0.0737 - val_loss: 10.0249 - val_accuracy: 0.9929 - val_eval_dice: 0.0480 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5739 - accuracy: 0.8892 - eval_dice: 0.0759\n",
      "Epoch 35: val_loss did not improve from 10.00707\n",
      "74/74 [==============================] - 94s 733ms/step - loss: 9.5739 - accuracy: 0.8892 - eval_dice: 0.0759 - val_loss: 10.0506 - val_accuracy: 0.9953 - val_eval_dice: 0.0347 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5467 - accuracy: 0.8922 - eval_dice: 0.0722\n",
      "Epoch 36: val_loss did not improve from 10.00707\n",
      "74/74 [==============================] - 91s 731ms/step - loss: 9.5467 - accuracy: 0.8922 - eval_dice: 0.0722 - val_loss: 10.0657 - val_accuracy: 0.9939 - val_eval_dice: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5158 - accuracy: 0.8912 - eval_dice: 0.0714\n",
      "Epoch 37: val_loss did not improve from 10.00707\n",
      "74/74 [==============================] - 94s 739ms/step - loss: 9.5158 - accuracy: 0.8912 - eval_dice: 0.0714 - val_loss: 10.0082 - val_accuracy: 0.9934 - val_eval_dice: 0.0372 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5022 - accuracy: 0.8882 - eval_dice: 0.0726\n",
      "Epoch 38: val_loss did not improve from 10.00707\n",
      "74/74 [==============================] - 94s 732ms/step - loss: 9.5022 - accuracy: 0.8882 - eval_dice: 0.0726 - val_loss: 10.0159 - val_accuracy: 0.9918 - val_eval_dice: 0.0518 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4515 - accuracy: 0.8923 - eval_dice: 0.0701\n",
      "Epoch 39: val_loss improved from 10.00707 to 9.97853, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 736ms/step - loss: 9.4515 - accuracy: 0.8923 - eval_dice: 0.0701 - val_loss: 9.9785 - val_accuracy: 0.9958 - val_eval_dice: 0.0376 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4128 - accuracy: 0.8884 - eval_dice: 0.0709\n",
      "Epoch 40: val_loss improved from 9.97853 to 9.96840, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 752ms/step - loss: 9.4128 - accuracy: 0.8884 - eval_dice: 0.0709 - val_loss: 9.9684 - val_accuracy: 0.9946 - val_eval_dice: 0.0456 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2801 - accuracy: 0.8948 - eval_dice: 0.0675\n",
      "Epoch 41: val_loss improved from 9.96840 to 9.87095, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 741ms/step - loss: 9.2801 - accuracy: 0.8948 - eval_dice: 0.0675 - val_loss: 9.8710 - val_accuracy: 0.9937 - val_eval_dice: 0.0428 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2222 - accuracy: 0.8797 - eval_dice: 0.0739\n",
      "Epoch 42: val_loss improved from 9.87095 to 9.81265, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 98s 780ms/step - loss: 9.2222 - accuracy: 0.8797 - eval_dice: 0.0739 - val_loss: 9.8126 - val_accuracy: 0.9935 - val_eval_dice: 0.0439 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1488 - accuracy: 0.8988 - eval_dice: 0.0638\n",
      "Epoch 43: val_loss did not improve from 9.81265\n",
      "74/74 [==============================] - 98s 777ms/step - loss: 9.1488 - accuracy: 0.8988 - eval_dice: 0.0638 - val_loss: 9.8299 - val_accuracy: 0.9947 - val_eval_dice: 0.0455 - lr: 1.0000e-04\n",
      "Epoch 44/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1292 - accuracy: 0.8913 - eval_dice: 0.0675\n",
      "Epoch 44: val_loss improved from 9.81265 to 9.78096, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 99s 775ms/step - loss: 9.1292 - accuracy: 0.8913 - eval_dice: 0.0675 - val_loss: 9.7810 - val_accuracy: 0.9940 - val_eval_dice: 0.0303 - lr: 1.0000e-04\n",
      "Epoch 45/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1421 - accuracy: 0.8898 - eval_dice: 0.0695\n",
      "Epoch 45: val_loss improved from 9.78096 to 9.75569, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 734ms/step - loss: 9.1421 - accuracy: 0.8898 - eval_dice: 0.0695 - val_loss: 9.7557 - val_accuracy: 0.9954 - val_eval_dice: 0.0340 - lr: 1.0000e-04\n",
      "Epoch 46/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1166 - accuracy: 0.8875 - eval_dice: 0.0695\n",
      "Epoch 46: val_loss did not improve from 9.75569\n",
      "74/74 [==============================] - 93s 738ms/step - loss: 9.1166 - accuracy: 0.8875 - eval_dice: 0.0695 - val_loss: 9.7847 - val_accuracy: 0.9943 - val_eval_dice: 0.0420 - lr: 1.0000e-04\n",
      "Epoch 47/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1191 - accuracy: 0.8922 - eval_dice: 0.0675\n",
      "Epoch 47: val_loss did not improve from 9.75569\n",
      "74/74 [==============================] - 93s 737ms/step - loss: 9.1191 - accuracy: 0.8922 - eval_dice: 0.0675 - val_loss: 9.7870 - val_accuracy: 0.9940 - val_eval_dice: 0.0373 - lr: 1.0000e-04\n",
      "Epoch 48/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0996 - accuracy: 0.8852 - eval_dice: 0.0717\n",
      "Epoch 48: val_loss did not improve from 9.75569\n",
      "74/74 [==============================] - 93s 739ms/step - loss: 9.0996 - accuracy: 0.8852 - eval_dice: 0.0717 - val_loss: 9.8157 - val_accuracy: 0.9933 - val_eval_dice: 0.0417 - lr: 1.0000e-04\n",
      "Epoch 49/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0679 - accuracy: 0.8969 - eval_dice: 0.0658\n",
      "Epoch 49: val_loss did not improve from 9.75569\n",
      "74/74 [==============================] - 93s 741ms/step - loss: 9.0679 - accuracy: 0.8969 - eval_dice: 0.0658 - val_loss: 9.7681 - val_accuracy: 0.9901 - val_eval_dice: 0.0416 - lr: 1.0000e-04\n",
      "Epoch 50/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.9582 - accuracy: 0.8947 - eval_dice: 0.0661\n",
      "Epoch 50: val_loss improved from 9.75569 to 9.69275, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 744ms/step - loss: 8.9582 - accuracy: 0.8947 - eval_dice: 0.0661 - val_loss: 9.6928 - val_accuracy: 0.9926 - val_eval_dice: 0.0345 - lr: 1.0000e-04\n",
      "Epoch 51/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8706 - accuracy: 0.8931 - eval_dice: 0.0663\n",
      "Epoch 51: val_loss improved from 9.69275 to 9.58150, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 92s 733ms/step - loss: 8.8706 - accuracy: 0.8931 - eval_dice: 0.0663 - val_loss: 9.5815 - val_accuracy: 0.9811 - val_eval_dice: 0.0422 - lr: 1.0000e-04\n",
      "Epoch 52/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7766 - accuracy: 0.8971 - eval_dice: 0.0641\n",
      "Epoch 52: val_loss improved from 9.58150 to 9.56025, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 744ms/step - loss: 8.7766 - accuracy: 0.8971 - eval_dice: 0.0641 - val_loss: 9.5602 - val_accuracy: 0.9868 - val_eval_dice: 0.0363 - lr: 1.0000e-04\n",
      "Epoch 53/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7546 - accuracy: 0.8928 - eval_dice: 0.0681\n",
      "Epoch 53: val_loss improved from 9.56025 to 9.51515, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 736ms/step - loss: 8.7546 - accuracy: 0.8928 - eval_dice: 0.0681 - val_loss: 9.5151 - val_accuracy: 0.9911 - val_eval_dice: 0.0301 - lr: 1.0000e-04\n",
      "Epoch 54/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7403 - accuracy: 0.8908 - eval_dice: 0.0676\n",
      "Epoch 54: val_loss did not improve from 9.51515\n",
      "74/74 [==============================] - 92s 732ms/step - loss: 8.7403 - accuracy: 0.8908 - eval_dice: 0.0676 - val_loss: 9.5800 - val_accuracy: 0.9934 - val_eval_dice: 0.0437 - lr: 1.0000e-04\n",
      "Epoch 55/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7720 - accuracy: 0.8956 - eval_dice: 0.0669\n",
      "Epoch 55: val_loss did not improve from 9.51515\n",
      "74/74 [==============================] - 93s 729ms/step - loss: 8.7720 - accuracy: 0.8956 - eval_dice: 0.0669 - val_loss: 9.5311 - val_accuracy: 0.9919 - val_eval_dice: 0.0376 - lr: 1.0000e-04\n",
      "Epoch 56/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7530 - accuracy: 0.8856 - eval_dice: 0.0721\n",
      "Epoch 56: val_loss did not improve from 9.51515\n",
      "74/74 [==============================] - 94s 744ms/step - loss: 8.7530 - accuracy: 0.8856 - eval_dice: 0.0721 - val_loss: 9.5167 - val_accuracy: 0.9929 - val_eval_dice: 0.0419 - lr: 1.0000e-04\n",
      "Epoch 57/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7278 - accuracy: 0.8903 - eval_dice: 0.0702\n",
      "Epoch 57: val_loss improved from 9.51515 to 9.45611, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 93s 745ms/step - loss: 8.7278 - accuracy: 0.8903 - eval_dice: 0.0702 - val_loss: 9.4561 - val_accuracy: 0.9897 - val_eval_dice: 0.0376 - lr: 1.0000e-04\n",
      "Epoch 58/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.6702 - accuracy: 0.8931 - eval_dice: 0.0675\n",
      "Epoch 58: val_loss improved from 9.45611 to 9.44589, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 748ms/step - loss: 8.6702 - accuracy: 0.8931 - eval_dice: 0.0675 - val_loss: 9.4459 - val_accuracy: 0.9867 - val_eval_dice: 0.0409 - lr: 1.0000e-04\n",
      "Epoch 59/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5352 - accuracy: 0.8853 - eval_dice: 0.0700\n",
      "Epoch 59: val_loss improved from 9.44589 to 9.34297, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 736ms/step - loss: 8.5352 - accuracy: 0.8853 - eval_dice: 0.0700 - val_loss: 9.3430 - val_accuracy: 0.9880 - val_eval_dice: 0.0405 - lr: 1.0000e-04\n",
      "Epoch 60/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.4570 - accuracy: 0.8912 - eval_dice: 0.0668\n",
      "Epoch 60: val_loss improved from 9.34297 to 9.29713, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_2_(2024-07-19)/23.48.19\\cp.ckpt\n",
      "74/74 [==============================] - 94s 747ms/step - loss: 8.4570 - accuracy: 0.8912 - eval_dice: 0.0668 - val_loss: 9.2971 - val_accuracy: 0.9920 - val_eval_dice: 0.0361 - lr: 1.0000e-04\n",
      "Fold 3/5\n",
      "Number of training tuple paths: 149\n",
      "Number of validation tuple paths: 37\n",
      "Number of test tuple paths: 48\n",
      "Normalization parameters training: (0.0, 2701.6875)\n",
      "Layer Normalization:  batchnorm\n",
      "Input shape after downsample: (None, 16, 128, 128, 32)\n",
      "Input shape after downsample: (None, 8, 64, 64, 64)\n",
      "Input shape after downsample: (None, 4, 32, 32, 128)\n",
      "Input shape after downsample: (None, 2, 16, 16, 512)\n",
      "Epoch 1/60\n",
      "      6/Unknown - 39s 818ms/step - loss: 14.2904 - accuracy: 0.0566 - eval_dice: 0.9250WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2504s vs `on_train_batch_end` time: 0.5945s). Check your callbacks.\n",
      "     74/Unknown - 87s 721ms/step - loss: 13.0589 - accuracy: 0.6042 - eval_dice: 0.7494\n",
      "Epoch 1: val_loss improved from inf to 11.97494, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 97s 851ms/step - loss: 13.0589 - accuracy: 0.6042 - eval_dice: 0.7494 - val_loss: 11.9749 - val_accuracy: 0.9858 - val_eval_dice: 0.4589 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.4760 - accuracy: 0.8957 - eval_dice: 0.2981\n",
      "Epoch 2: val_loss improved from 11.97494 to 11.31296, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 98s 777ms/step - loss: 11.4760 - accuracy: 0.8957 - eval_dice: 0.2981 - val_loss: 11.3130 - val_accuracy: 0.9959 - val_eval_dice: 0.1746 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.2137 - accuracy: 0.8931 - eval_dice: 0.1619\n",
      "Epoch 3: val_loss improved from 11.31296 to 11.22170, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 97s 773ms/step - loss: 11.2137 - accuracy: 0.8931 - eval_dice: 0.1619 - val_loss: 11.2217 - val_accuracy: 0.9917 - val_eval_dice: 0.1162 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1590 - accuracy: 0.8941 - eval_dice: 0.1258\n",
      "Epoch 4: val_loss improved from 11.22170 to 11.19166, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 96s 741ms/step - loss: 11.1590 - accuracy: 0.8941 - eval_dice: 0.1258 - val_loss: 11.1917 - val_accuracy: 0.9949 - val_eval_dice: 0.0989 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1380 - accuracy: 0.8932 - eval_dice: 0.1116\n",
      "Epoch 5: val_loss improved from 11.19166 to 11.18207, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 94s 747ms/step - loss: 11.1380 - accuracy: 0.8932 - eval_dice: 0.1116 - val_loss: 11.1821 - val_accuracy: 0.9945 - val_eval_dice: 0.0918 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1246 - accuracy: 0.8907 - eval_dice: 0.1024\n",
      "Epoch 6: val_loss improved from 11.18207 to 11.15303, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 93s 742ms/step - loss: 11.1246 - accuracy: 0.8907 - eval_dice: 0.1024 - val_loss: 11.1530 - val_accuracy: 0.9936 - val_eval_dice: 0.0751 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1200 - accuracy: 0.8987 - eval_dice: 0.0946\n",
      "Epoch 7: val_loss improved from 11.15303 to 11.13383, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 94s 741ms/step - loss: 11.1200 - accuracy: 0.8987 - eval_dice: 0.0946 - val_loss: 11.1338 - val_accuracy: 0.9964 - val_eval_dice: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1131 - accuracy: 0.8963 - eval_dice: 0.0921\n",
      "Epoch 8: val_loss improved from 11.13383 to 11.12710, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 94s 744ms/step - loss: 11.1131 - accuracy: 0.8963 - eval_dice: 0.0921 - val_loss: 11.1271 - val_accuracy: 0.9960 - val_eval_dice: 0.0653 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1088 - accuracy: 0.8894 - eval_dice: 0.0923\n",
      "Epoch 9: val_loss did not improve from 11.12710\n",
      "74/74 [==============================] - 93s 727ms/step - loss: 11.1088 - accuracy: 0.8894 - eval_dice: 0.0923 - val_loss: 11.1537 - val_accuracy: 0.9943 - val_eval_dice: 0.0740 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1072 - accuracy: 0.8843 - eval_dice: 0.0927\n",
      "Epoch 10: val_loss did not improve from 11.12710\n",
      "74/74 [==============================] - 93s 738ms/step - loss: 11.1072 - accuracy: 0.8843 - eval_dice: 0.0927 - val_loss: 11.1676 - val_accuracy: 0.9958 - val_eval_dice: 0.0790 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1033 - accuracy: 0.8905 - eval_dice: 0.0876\n",
      "Epoch 11: val_loss did not improve from 11.12710\n",
      "74/74 [==============================] - 92s 736ms/step - loss: 11.1033 - accuracy: 0.8905 - eval_dice: 0.0876 - val_loss: 11.1324 - val_accuracy: 0.9965 - val_eval_dice: 0.0635 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1019 - accuracy: 0.8901 - eval_dice: 0.0862\n",
      "Epoch 12: val_loss did not improve from 11.12710\n",
      "74/74 [==============================] - 91s 727ms/step - loss: 11.1019 - accuracy: 0.8901 - eval_dice: 0.0862 - val_loss: 11.1380 - val_accuracy: 0.9966 - val_eval_dice: 0.0667 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1037 - accuracy: 0.8913 - eval_dice: 0.0876\n",
      "Epoch 13: val_loss did not improve from 11.12710\n",
      "74/74 [==============================] - 94s 743ms/step - loss: 11.1037 - accuracy: 0.8913 - eval_dice: 0.0876 - val_loss: 11.1289 - val_accuracy: 0.9968 - val_eval_dice: 0.0652 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0979 - accuracy: 0.8913 - eval_dice: 0.0865\n",
      "Epoch 14: val_loss did not improve from 11.12710\n",
      "74/74 [==============================] - 93s 734ms/step - loss: 11.0979 - accuracy: 0.8913 - eval_dice: 0.0865 - val_loss: 11.1290 - val_accuracy: 0.9947 - val_eval_dice: 0.0636 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0903 - accuracy: 0.9034 - eval_dice: 0.0786\n",
      "Epoch 15: val_loss improved from 11.12710 to 11.12276, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 94s 751ms/step - loss: 11.0903 - accuracy: 0.9034 - eval_dice: 0.0786 - val_loss: 11.1228 - val_accuracy: 0.9952 - val_eval_dice: 0.0607 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0906 - accuracy: 0.8915 - eval_dice: 0.0843\n",
      "Epoch 16: val_loss did not improve from 11.12276\n",
      "74/74 [==============================] - 93s 737ms/step - loss: 11.0906 - accuracy: 0.8915 - eval_dice: 0.0843 - val_loss: 11.1656 - val_accuracy: 0.9966 - val_eval_dice: 0.0794 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0852 - accuracy: 0.8998 - eval_dice: 0.0812\n",
      "Epoch 17: val_loss improved from 11.12276 to 11.08350, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 93s 743ms/step - loss: 11.0852 - accuracy: 0.8998 - eval_dice: 0.0812 - val_loss: 11.0835 - val_accuracy: 0.9968 - val_eval_dice: 0.0539 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0788 - accuracy: 0.8893 - eval_dice: 0.0843\n",
      "Epoch 18: val_loss did not improve from 11.08350\n",
      "74/74 [==============================] - 93s 747ms/step - loss: 11.0788 - accuracy: 0.8893 - eval_dice: 0.0843 - val_loss: 11.0934 - val_accuracy: 0.9966 - val_eval_dice: 0.0592 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0738 - accuracy: 0.8887 - eval_dice: 0.0850\n",
      "Epoch 19: val_loss did not improve from 11.08350\n",
      "74/74 [==============================] - 95s 743ms/step - loss: 11.0738 - accuracy: 0.8887 - eval_dice: 0.0850 - val_loss: 11.0869 - val_accuracy: 0.9970 - val_eval_dice: 0.0584 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0656 - accuracy: 0.8977 - eval_dice: 0.0793\n",
      "Epoch 20: val_loss improved from 11.08350 to 11.08322, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 95s 751ms/step - loss: 11.0656 - accuracy: 0.8977 - eval_dice: 0.0793 - val_loss: 11.0832 - val_accuracy: 0.9963 - val_eval_dice: 0.0601 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0603 - accuracy: 0.8881 - eval_dice: 0.0836\n",
      "Epoch 21: val_loss improved from 11.08322 to 11.07517, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 95s 745ms/step - loss: 11.0603 - accuracy: 0.8881 - eval_dice: 0.0836 - val_loss: 11.0752 - val_accuracy: 0.9971 - val_eval_dice: 0.0607 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0596 - accuracy: 0.8888 - eval_dice: 0.0847\n",
      "Epoch 22: val_loss improved from 11.07517 to 11.05417, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 101s 798ms/step - loss: 11.0596 - accuracy: 0.8888 - eval_dice: 0.0847 - val_loss: 11.0542 - val_accuracy: 0.9969 - val_eval_dice: 0.0539 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0509 - accuracy: 0.8944 - eval_dice: 0.0842\n",
      "Epoch 23: val_loss improved from 11.05417 to 11.05060, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 99s 790ms/step - loss: 11.0509 - accuracy: 0.8944 - eval_dice: 0.0842 - val_loss: 11.0506 - val_accuracy: 0.9965 - val_eval_dice: 0.0586 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0420 - accuracy: 0.8929 - eval_dice: 0.0808\n",
      "Epoch 24: val_loss improved from 11.05060 to 11.03306, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 99s 795ms/step - loss: 11.0420 - accuracy: 0.8929 - eval_dice: 0.0808 - val_loss: 11.0331 - val_accuracy: 0.9975 - val_eval_dice: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0339 - accuracy: 0.8972 - eval_dice: 0.0783\n",
      "Epoch 25: val_loss improved from 11.03306 to 11.01960, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 99s 808ms/step - loss: 11.0339 - accuracy: 0.8972 - eval_dice: 0.0783 - val_loss: 11.0196 - val_accuracy: 0.9973 - val_eval_dice: 0.0483 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0214 - accuracy: 0.8902 - eval_dice: 0.0789\n",
      "Epoch 26: val_loss improved from 11.01960 to 11.01305, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 100s 803ms/step - loss: 11.0214 - accuracy: 0.8902 - eval_dice: 0.0789 - val_loss: 11.0131 - val_accuracy: 0.9967 - val_eval_dice: 0.0499 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0039 - accuracy: 0.8975 - eval_dice: 0.0753\n",
      "Epoch 27: val_loss improved from 11.01305 to 10.99350, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 95s 732ms/step - loss: 11.0039 - accuracy: 0.8975 - eval_dice: 0.0753 - val_loss: 10.9935 - val_accuracy: 0.9972 - val_eval_dice: 0.0425 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0098 - accuracy: 0.9005 - eval_dice: 0.0760\n",
      "Epoch 28: val_loss improved from 10.99350 to 10.98937, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 94s 749ms/step - loss: 11.0098 - accuracy: 0.9005 - eval_dice: 0.0760 - val_loss: 10.9894 - val_accuracy: 0.9954 - val_eval_dice: 0.0437 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9941 - accuracy: 0.8886 - eval_dice: 0.0786\n",
      "Epoch 29: val_loss improved from 10.98937 to 10.93596, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 95s 749ms/step - loss: 10.9941 - accuracy: 0.8886 - eval_dice: 0.0786 - val_loss: 10.9360 - val_accuracy: 0.9961 - val_eval_dice: 0.0362 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9453 - accuracy: 0.8894 - eval_dice: 0.0771\n",
      "Epoch 30: val_loss improved from 10.93596 to 10.92185, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 98s 799ms/step - loss: 10.9453 - accuracy: 0.8894 - eval_dice: 0.0771 - val_loss: 10.9219 - val_accuracy: 0.9969 - val_eval_dice: 0.0424 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9177 - accuracy: 0.8838 - eval_dice: 0.0790\n",
      "Epoch 31: val_loss improved from 10.92185 to 10.82637, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 100s 790ms/step - loss: 10.9177 - accuracy: 0.8838 - eval_dice: 0.0790 - val_loss: 10.8264 - val_accuracy: 0.9965 - val_eval_dice: 0.0367 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8754 - accuracy: 0.8855 - eval_dice: 0.0774\n",
      "Epoch 32: val_loss improved from 10.82637 to 10.81644, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 99s 790ms/step - loss: 10.8754 - accuracy: 0.8855 - eval_dice: 0.0774 - val_loss: 10.8164 - val_accuracy: 0.9952 - val_eval_dice: 0.0324 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8602 - accuracy: 0.8918 - eval_dice: 0.0764\n",
      "Epoch 33: val_loss did not improve from 10.81644\n",
      "74/74 [==============================] - 92s 730ms/step - loss: 10.8602 - accuracy: 0.8918 - eval_dice: 0.0764 - val_loss: 10.9145 - val_accuracy: 0.9968 - val_eval_dice: 0.0324 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8137 - accuracy: 0.8877 - eval_dice: 0.0756\n",
      "Epoch 34: val_loss improved from 10.81644 to 10.73912, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 94s 750ms/step - loss: 10.8137 - accuracy: 0.8877 - eval_dice: 0.0756 - val_loss: 10.7391 - val_accuracy: 0.9942 - val_eval_dice: 0.0464 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7954 - accuracy: 0.8953 - eval_dice: 0.0714\n",
      "Epoch 35: val_loss improved from 10.73912 to 10.68778, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 94s 752ms/step - loss: 10.7954 - accuracy: 0.8953 - eval_dice: 0.0714 - val_loss: 10.6878 - val_accuracy: 0.9949 - val_eval_dice: 0.0371 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7039 - accuracy: 0.8943 - eval_dice: 0.0712\n",
      "Epoch 36: val_loss did not improve from 10.68778\n",
      "74/74 [==============================] - 93s 742ms/step - loss: 10.7039 - accuracy: 0.8943 - eval_dice: 0.0712 - val_loss: 10.6879 - val_accuracy: 0.9946 - val_eval_dice: 0.0385 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6809 - accuracy: 0.8974 - eval_dice: 0.0687\n",
      "Epoch 37: val_loss improved from 10.68778 to 10.61801, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 98s 808ms/step - loss: 10.6809 - accuracy: 0.8974 - eval_dice: 0.0687 - val_loss: 10.6180 - val_accuracy: 0.9952 - val_eval_dice: 0.0393 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6589 - accuracy: 0.8925 - eval_dice: 0.0719\n",
      "Epoch 38: val_loss improved from 10.61801 to 10.54271, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 101s 807ms/step - loss: 10.6589 - accuracy: 0.8925 - eval_dice: 0.0719 - val_loss: 10.5427 - val_accuracy: 0.9951 - val_eval_dice: 0.0345 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6474 - accuracy: 0.8897 - eval_dice: 0.0744\n",
      "Epoch 39: val_loss did not improve from 10.54271\n",
      "74/74 [==============================] - 95s 770ms/step - loss: 10.6474 - accuracy: 0.8897 - eval_dice: 0.0744 - val_loss: 10.6131 - val_accuracy: 0.9941 - val_eval_dice: 0.0356 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6322 - accuracy: 0.8946 - eval_dice: 0.0755\n",
      "Epoch 40: val_loss did not improve from 10.54271\n",
      "74/74 [==============================] - 101s 786ms/step - loss: 10.6322 - accuracy: 0.8946 - eval_dice: 0.0755 - val_loss: 10.5870 - val_accuracy: 0.9925 - val_eval_dice: 0.0404 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6099 - accuracy: 0.8890 - eval_dice: 0.0767\n",
      "Epoch 41: val_loss improved from 10.54271 to 10.51285, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 93s 729ms/step - loss: 10.6099 - accuracy: 0.8890 - eval_dice: 0.0767 - val_loss: 10.5128 - val_accuracy: 0.9926 - val_eval_dice: 0.0383 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5472 - accuracy: 0.8916 - eval_dice: 0.0729\n",
      "Epoch 42: val_loss did not improve from 10.51285\n",
      "74/74 [==============================] - 97s 768ms/step - loss: 10.5472 - accuracy: 0.8916 - eval_dice: 0.0729 - val_loss: 10.5349 - val_accuracy: 0.9933 - val_eval_dice: 0.0373 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5461 - accuracy: 0.8879 - eval_dice: 0.0742\n",
      "Epoch 43: val_loss did not improve from 10.51285\n",
      "74/74 [==============================] - 99s 779ms/step - loss: 10.5461 - accuracy: 0.8879 - eval_dice: 0.0742 - val_loss: 10.5738 - val_accuracy: 0.9885 - val_eval_dice: 0.0563 - lr: 1.0000e-04\n",
      "Epoch 44/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5691 - accuracy: 0.8946 - eval_dice: 0.0728\n",
      "Epoch 44: val_loss did not improve from 10.51285\n",
      "74/74 [==============================] - 91s 715ms/step - loss: 10.5691 - accuracy: 0.8946 - eval_dice: 0.0728 - val_loss: 10.5406 - val_accuracy: 0.9870 - val_eval_dice: 0.0467 - lr: 1.0000e-04\n",
      "Epoch 45/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5451 - accuracy: 0.8906 - eval_dice: 0.0794\n",
      "Epoch 45: val_loss did not improve from 10.51285\n",
      "74/74 [==============================] - 92s 721ms/step - loss: 10.5451 - accuracy: 0.8906 - eval_dice: 0.0794 - val_loss: 10.5239 - val_accuracy: 0.9883 - val_eval_dice: 0.0522 - lr: 1.0000e-04\n",
      "Epoch 46/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5361 - accuracy: 0.8931 - eval_dice: 0.0772\n",
      "Epoch 46: val_loss did not improve from 10.51285\n",
      "74/74 [==============================] - 94s 744ms/step - loss: 10.5361 - accuracy: 0.8931 - eval_dice: 0.0772 - val_loss: 10.5567 - val_accuracy: 0.9912 - val_eval_dice: 0.0608 - lr: 1.0000e-04\n",
      "Epoch 47/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5397 - accuracy: 0.9003 - eval_dice: 0.0711\n",
      "Epoch 47: val_loss improved from 10.51285 to 10.46265, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 97s 768ms/step - loss: 10.5397 - accuracy: 0.9003 - eval_dice: 0.0711 - val_loss: 10.4626 - val_accuracy: 0.9941 - val_eval_dice: 0.0355 - lr: 1.0000e-04\n",
      "Epoch 48/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5036 - accuracy: 0.8928 - eval_dice: 0.0726\n",
      "Epoch 48: val_loss did not improve from 10.46265\n",
      "74/74 [==============================] - 98s 768ms/step - loss: 10.5036 - accuracy: 0.8928 - eval_dice: 0.0726 - val_loss: 10.4789 - val_accuracy: 0.9934 - val_eval_dice: 0.0360 - lr: 1.0000e-04\n",
      "Epoch 49/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5031 - accuracy: 0.8913 - eval_dice: 0.0728\n",
      "Epoch 49: val_loss did not improve from 10.46265\n",
      "74/74 [==============================] - 96s 760ms/step - loss: 10.5031 - accuracy: 0.8913 - eval_dice: 0.0728 - val_loss: 10.4657 - val_accuracy: 0.9937 - val_eval_dice: 0.0367 - lr: 1.0000e-04\n",
      "Epoch 50/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5041 - accuracy: 0.8848 - eval_dice: 0.0758\n",
      "Epoch 50: val_loss improved from 10.46265 to 10.44995, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 102s 773ms/step - loss: 10.5041 - accuracy: 0.8848 - eval_dice: 0.0758 - val_loss: 10.4500 - val_accuracy: 0.9937 - val_eval_dice: 0.0343 - lr: 1.0000e-04\n",
      "Epoch 51/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4762 - accuracy: 0.8967 - eval_dice: 0.0695\n",
      "Epoch 51: val_loss improved from 10.44995 to 10.44227, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 97s 776ms/step - loss: 10.4762 - accuracy: 0.8967 - eval_dice: 0.0695 - val_loss: 10.4423 - val_accuracy: 0.9936 - val_eval_dice: 0.0326 - lr: 1.0000e-04\n",
      "Epoch 52/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4726 - accuracy: 0.8922 - eval_dice: 0.0710\n",
      "Epoch 52: val_loss did not improve from 10.44227\n",
      "74/74 [==============================] - 99s 779ms/step - loss: 10.4726 - accuracy: 0.8922 - eval_dice: 0.0710 - val_loss: 10.4452 - val_accuracy: 0.9936 - val_eval_dice: 0.0321 - lr: 1.0000e-04\n",
      "Epoch 53/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4720 - accuracy: 0.8979 - eval_dice: 0.0679\n",
      "Epoch 53: val_loss did not improve from 10.44227\n",
      "74/74 [==============================] - 97s 767ms/step - loss: 10.4720 - accuracy: 0.8979 - eval_dice: 0.0679 - val_loss: 10.4525 - val_accuracy: 0.9936 - val_eval_dice: 0.0354 - lr: 1.0000e-04\n",
      "Epoch 54/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4963 - accuracy: 0.8951 - eval_dice: 0.0692\n",
      "Epoch 54: val_loss did not improve from 10.44227\n",
      "74/74 [==============================] - 96s 743ms/step - loss: 10.4963 - accuracy: 0.8951 - eval_dice: 0.0692 - val_loss: 10.4588 - val_accuracy: 0.9945 - val_eval_dice: 0.0265 - lr: 1.0000e-04\n",
      "Epoch 55/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4760 - accuracy: 0.8937 - eval_dice: 0.0697\n",
      "Epoch 55: val_loss improved from 10.44227 to 10.43482, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 99s 789ms/step - loss: 10.4760 - accuracy: 0.8937 - eval_dice: 0.0697 - val_loss: 10.4348 - val_accuracy: 0.9941 - val_eval_dice: 0.0341 - lr: 1.0000e-04\n",
      "Epoch 56/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4417 - accuracy: 0.8905 - eval_dice: 0.0710\n",
      "Epoch 56: val_loss improved from 10.43482 to 10.43101, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 101s 800ms/step - loss: 10.4417 - accuracy: 0.8905 - eval_dice: 0.0710 - val_loss: 10.4310 - val_accuracy: 0.9939 - val_eval_dice: 0.0302 - lr: 1.0000e-04\n",
      "Epoch 57/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4539 - accuracy: 0.8910 - eval_dice: 0.0713\n",
      "Epoch 57: val_loss did not improve from 10.43101\n",
      "74/74 [==============================] - 98s 774ms/step - loss: 10.4539 - accuracy: 0.8910 - eval_dice: 0.0713 - val_loss: 10.4682 - val_accuracy: 0.9941 - val_eval_dice: 0.0339 - lr: 1.0000e-04\n",
      "Epoch 58/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4797 - accuracy: 0.8926 - eval_dice: 0.0703\n",
      "Epoch 58: val_loss improved from 10.43101 to 10.42918, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 98s 766ms/step - loss: 10.4797 - accuracy: 0.8926 - eval_dice: 0.0703 - val_loss: 10.4292 - val_accuracy: 0.9942 - val_eval_dice: 0.0241 - lr: 1.0000e-04\n",
      "Epoch 59/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4430 - accuracy: 0.8910 - eval_dice: 0.0709\n",
      "Epoch 59: val_loss improved from 10.42918 to 10.41728, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_3_(2024-07-20)/01.23.07\\cp.ckpt\n",
      "74/74 [==============================] - 93s 730ms/step - loss: 10.4430 - accuracy: 0.8910 - eval_dice: 0.0709 - val_loss: 10.4173 - val_accuracy: 0.9943 - val_eval_dice: 0.0268 - lr: 1.0000e-04\n",
      "Epoch 60/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4499 - accuracy: 0.8875 - eval_dice: 0.0728\n",
      "Epoch 60: val_loss did not improve from 10.41728\n",
      "74/74 [==============================] - 92s 730ms/step - loss: 10.4499 - accuracy: 0.8875 - eval_dice: 0.0728 - val_loss: 10.4540 - val_accuracy: 0.9931 - val_eval_dice: 0.0372 - lr: 1.0000e-04\n",
      "Fold 4/5\n",
      "Number of training tuple paths: 149\n",
      "Number of validation tuple paths: 37\n",
      "Number of test tuple paths: 48\n",
      "Normalization parameters training: (0.0, 2701.6875)\n",
      "Layer Normalization:  batchnorm\n",
      "Input shape after downsample: (None, 16, 128, 128, 32)\n",
      "Input shape after downsample: (None, 8, 64, 64, 64)\n",
      "Input shape after downsample: (None, 4, 32, 32, 128)\n",
      "Input shape after downsample: (None, 2, 16, 16, 512)\n",
      "Epoch 1/60\n",
      "      6/Unknown - 44s 730ms/step - loss: 14.4992 - accuracy: 0.0407 - eval_dice: 0.9342WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1101s vs `on_train_batch_end` time: 0.6642s). Check your callbacks.\n",
      "     74/Unknown - 92s 714ms/step - loss: 13.3466 - accuracy: 0.4315 - eval_dice: 0.8026\n",
      "Epoch 1: val_loss improved from inf to 12.21193, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 102s 848ms/step - loss: 13.3466 - accuracy: 0.4315 - eval_dice: 0.8026 - val_loss: 12.2119 - val_accuracy: 0.9798 - val_eval_dice: 0.5478 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.5489 - accuracy: 0.8917 - eval_dice: 0.3298\n",
      "Epoch 2: val_loss improved from 12.21193 to 11.28412, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 98s 773ms/step - loss: 11.5489 - accuracy: 0.8917 - eval_dice: 0.3298 - val_loss: 11.2841 - val_accuracy: 0.9978 - val_eval_dice: 0.1615 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1974 - accuracy: 0.8850 - eval_dice: 0.1553\n",
      "Epoch 3: val_loss improved from 11.28412 to 11.21871, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 97s 758ms/step - loss: 11.1974 - accuracy: 0.8850 - eval_dice: 0.1553 - val_loss: 11.2187 - val_accuracy: 0.9958 - val_eval_dice: 0.1153 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1459 - accuracy: 0.8908 - eval_dice: 0.1194\n",
      "Epoch 4: val_loss improved from 11.21871 to 11.20654, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 95s 747ms/step - loss: 11.1459 - accuracy: 0.8908 - eval_dice: 0.1194 - val_loss: 11.2065 - val_accuracy: 0.9951 - val_eval_dice: 0.1052 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1267 - accuracy: 0.9026 - eval_dice: 0.1028\n",
      "Epoch 5: val_loss improved from 11.20654 to 11.16553, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 93s 748ms/step - loss: 11.1267 - accuracy: 0.9026 - eval_dice: 0.1028 - val_loss: 11.1655 - val_accuracy: 0.9961 - val_eval_dice: 0.0886 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1126 - accuracy: 0.8952 - eval_dice: 0.1017\n",
      "Epoch 6: val_loss improved from 11.16553 to 11.13498, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 755ms/step - loss: 11.1126 - accuracy: 0.8952 - eval_dice: 0.1017 - val_loss: 11.1350 - val_accuracy: 0.9949 - val_eval_dice: 0.0813 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0960 - accuracy: 0.8980 - eval_dice: 0.0985\n",
      "Epoch 7: val_loss improved from 11.13498 to 11.10613, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 95s 753ms/step - loss: 11.0960 - accuracy: 0.8980 - eval_dice: 0.0985 - val_loss: 11.1061 - val_accuracy: 0.9943 - val_eval_dice: 0.0746 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0746 - accuracy: 0.8885 - eval_dice: 0.0989\n",
      "Epoch 8: val_loss improved from 11.10613 to 11.05568, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 747ms/step - loss: 11.0746 - accuracy: 0.8885 - eval_dice: 0.0989 - val_loss: 11.0557 - val_accuracy: 0.9942 - val_eval_dice: 0.0588 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0437 - accuracy: 0.8973 - eval_dice: 0.0885\n",
      "Epoch 9: val_loss improved from 11.05568 to 11.02803, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 97s 779ms/step - loss: 11.0437 - accuracy: 0.8973 - eval_dice: 0.0885 - val_loss: 11.0280 - val_accuracy: 0.9938 - val_eval_dice: 0.0591 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0170 - accuracy: 0.8887 - eval_dice: 0.0874\n",
      "Epoch 10: val_loss improved from 11.02803 to 11.00171, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 100s 802ms/step - loss: 11.0170 - accuracy: 0.8887 - eval_dice: 0.0874 - val_loss: 11.0017 - val_accuracy: 0.9939 - val_eval_dice: 0.0570 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9667 - accuracy: 0.8954 - eval_dice: 0.0817\n",
      "Epoch 11: val_loss improved from 11.00171 to 10.91607, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 99s 784ms/step - loss: 10.9667 - accuracy: 0.8954 - eval_dice: 0.0817 - val_loss: 10.9161 - val_accuracy: 0.9903 - val_eval_dice: 0.0601 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9042 - accuracy: 0.8876 - eval_dice: 0.0847\n",
      "Epoch 12: val_loss improved from 10.91607 to 10.87534, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 100s 800ms/step - loss: 10.9042 - accuracy: 0.8876 - eval_dice: 0.0847 - val_loss: 10.8753 - val_accuracy: 0.9914 - val_eval_dice: 0.0685 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8733 - accuracy: 0.8911 - eval_dice: 0.0819\n",
      "Epoch 13: val_loss improved from 10.87534 to 10.83942, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 101s 809ms/step - loss: 10.8733 - accuracy: 0.8911 - eval_dice: 0.0819 - val_loss: 10.8394 - val_accuracy: 0.9903 - val_eval_dice: 0.0617 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8271 - accuracy: 0.8932 - eval_dice: 0.0808\n",
      "Epoch 14: val_loss improved from 10.83942 to 10.80010, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 100s 792ms/step - loss: 10.8271 - accuracy: 0.8932 - eval_dice: 0.0808 - val_loss: 10.8001 - val_accuracy: 0.9907 - val_eval_dice: 0.0590 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7959 - accuracy: 0.8969 - eval_dice: 0.0777\n",
      "Epoch 15: val_loss improved from 10.80010 to 10.74426, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 98s 800ms/step - loss: 10.7959 - accuracy: 0.8969 - eval_dice: 0.0777 - val_loss: 10.7443 - val_accuracy: 0.9931 - val_eval_dice: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7778 - accuracy: 0.8934 - eval_dice: 0.0773\n",
      "Epoch 16: val_loss did not improve from 10.74426\n",
      "74/74 [==============================] - 100s 791ms/step - loss: 10.7778 - accuracy: 0.8934 - eval_dice: 0.0773 - val_loss: 10.7670 - val_accuracy: 0.9934 - val_eval_dice: 0.0598 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7669 - accuracy: 0.8918 - eval_dice: 0.0771\n",
      "Epoch 17: val_loss improved from 10.74426 to 10.71439, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 101s 806ms/step - loss: 10.7669 - accuracy: 0.8918 - eval_dice: 0.0771 - val_loss: 10.7144 - val_accuracy: 0.9931 - val_eval_dice: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7572 - accuracy: 0.8835 - eval_dice: 0.0822\n",
      "Epoch 18: val_loss improved from 10.71439 to 10.67670, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 97s 756ms/step - loss: 10.7572 - accuracy: 0.8835 - eval_dice: 0.0822 - val_loss: 10.6767 - val_accuracy: 0.9933 - val_eval_dice: 0.0575 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7351 - accuracy: 0.8852 - eval_dice: 0.0801\n",
      "Epoch 19: val_loss improved from 10.67670 to 10.64086, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 756ms/step - loss: 10.7351 - accuracy: 0.8852 - eval_dice: 0.0801 - val_loss: 10.6409 - val_accuracy: 0.9954 - val_eval_dice: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6916 - accuracy: 0.8888 - eval_dice: 0.0801\n",
      "Epoch 20: val_loss did not improve from 10.64086\n",
      "74/74 [==============================] - 94s 743ms/step - loss: 10.6916 - accuracy: 0.8888 - eval_dice: 0.0801 - val_loss: 10.6669 - val_accuracy: 0.9940 - val_eval_dice: 0.0583 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6680 - accuracy: 0.8942 - eval_dice: 0.0789\n",
      "Epoch 21: val_loss improved from 10.64086 to 10.58230, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 95s 751ms/step - loss: 10.6680 - accuracy: 0.8942 - eval_dice: 0.0789 - val_loss: 10.5823 - val_accuracy: 0.9945 - val_eval_dice: 0.0467 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6618 - accuracy: 0.8916 - eval_dice: 0.0792\n",
      "Epoch 22: val_loss improved from 10.58230 to 10.56730, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 95s 755ms/step - loss: 10.6618 - accuracy: 0.8916 - eval_dice: 0.0792 - val_loss: 10.5673 - val_accuracy: 0.9940 - val_eval_dice: 0.0480 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5786 - accuracy: 0.8958 - eval_dice: 0.0752\n",
      "Epoch 23: val_loss improved from 10.56730 to 10.40097, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 97s 771ms/step - loss: 10.5786 - accuracy: 0.8958 - eval_dice: 0.0752 - val_loss: 10.4010 - val_accuracy: 0.9937 - val_eval_dice: 0.0415 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3861 - accuracy: 0.8941 - eval_dice: 0.0728\n",
      "Epoch 24: val_loss improved from 10.40097 to 10.22797, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 98s 785ms/step - loss: 10.3861 - accuracy: 0.8941 - eval_dice: 0.0728 - val_loss: 10.2280 - val_accuracy: 0.9916 - val_eval_dice: 0.0429 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2095 - accuracy: 0.8960 - eval_dice: 0.0691\n",
      "Epoch 25: val_loss improved from 10.22797 to 10.22225, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 99s 784ms/step - loss: 10.2095 - accuracy: 0.8960 - eval_dice: 0.0691 - val_loss: 10.2222 - val_accuracy: 0.9916 - val_eval_dice: 0.0369 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0931 - accuracy: 0.8856 - eval_dice: 0.0741\n",
      "Epoch 26: val_loss improved from 10.22225 to 9.96239, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 99s 787ms/step - loss: 10.0931 - accuracy: 0.8856 - eval_dice: 0.0741 - val_loss: 9.9624 - val_accuracy: 0.9920 - val_eval_dice: 0.0381 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.9934 - accuracy: 0.8907 - eval_dice: 0.0713\n",
      "Epoch 27: val_loss improved from 9.96239 to 9.80239, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 746ms/step - loss: 9.9934 - accuracy: 0.8907 - eval_dice: 0.0713 - val_loss: 9.8024 - val_accuracy: 0.9924 - val_eval_dice: 0.0444 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.9195 - accuracy: 0.8892 - eval_dice: 0.0712\n",
      "Epoch 28: val_loss improved from 9.80239 to 9.78383, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 752ms/step - loss: 9.9195 - accuracy: 0.8892 - eval_dice: 0.0712 - val_loss: 9.7838 - val_accuracy: 0.9932 - val_eval_dice: 0.0425 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8676 - accuracy: 0.8971 - eval_dice: 0.0672\n",
      "Epoch 29: val_loss improved from 9.78383 to 9.69260, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 95s 763ms/step - loss: 9.8676 - accuracy: 0.8971 - eval_dice: 0.0672 - val_loss: 9.6926 - val_accuracy: 0.9939 - val_eval_dice: 0.0403 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8024 - accuracy: 0.8939 - eval_dice: 0.0686\n",
      "Epoch 30: val_loss did not improve from 9.69260\n",
      "74/74 [==============================] - 94s 751ms/step - loss: 9.8024 - accuracy: 0.8939 - eval_dice: 0.0686 - val_loss: 9.7133 - val_accuracy: 0.9934 - val_eval_dice: 0.0356 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8062 - accuracy: 0.8934 - eval_dice: 0.0684\n",
      "Epoch 31: val_loss improved from 9.69260 to 9.63970, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 760ms/step - loss: 9.8062 - accuracy: 0.8934 - eval_dice: 0.0684 - val_loss: 9.6397 - val_accuracy: 0.9943 - val_eval_dice: 0.0377 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7371 - accuracy: 0.8902 - eval_dice: 0.0706\n",
      "Epoch 32: val_loss did not improve from 9.63970\n",
      "74/74 [==============================] - 94s 743ms/step - loss: 9.7371 - accuracy: 0.8902 - eval_dice: 0.0706 - val_loss: 9.6530 - val_accuracy: 0.9941 - val_eval_dice: 0.0342 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7284 - accuracy: 0.8885 - eval_dice: 0.0716\n",
      "Epoch 33: val_loss improved from 9.63970 to 9.59442, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 739ms/step - loss: 9.7284 - accuracy: 0.8885 - eval_dice: 0.0716 - val_loss: 9.5944 - val_accuracy: 0.9934 - val_eval_dice: 0.0454 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7018 - accuracy: 0.8975 - eval_dice: 0.0660\n",
      "Epoch 34: val_loss improved from 9.59442 to 9.56111, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 96s 780ms/step - loss: 9.7018 - accuracy: 0.8975 - eval_dice: 0.0660 - val_loss: 9.5611 - val_accuracy: 0.9937 - val_eval_dice: 0.0334 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6628 - accuracy: 0.8945 - eval_dice: 0.0679\n",
      "Epoch 35: val_loss did not improve from 9.56111\n",
      "74/74 [==============================] - 100s 796ms/step - loss: 9.6628 - accuracy: 0.8945 - eval_dice: 0.0679 - val_loss: 9.5997 - val_accuracy: 0.9930 - val_eval_dice: 0.0365 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6320 - accuracy: 0.8867 - eval_dice: 0.0718\n",
      "Epoch 36: val_loss did not improve from 9.56111\n",
      "74/74 [==============================] - 101s 814ms/step - loss: 9.6320 - accuracy: 0.8867 - eval_dice: 0.0718 - val_loss: 9.5911 - val_accuracy: 0.9891 - val_eval_dice: 0.0386 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6113 - accuracy: 0.8956 - eval_dice: 0.0676\n",
      "Epoch 37: val_loss improved from 9.56111 to 9.56082, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 99s 777ms/step - loss: 9.6113 - accuracy: 0.8956 - eval_dice: 0.0676 - val_loss: 9.5608 - val_accuracy: 0.9951 - val_eval_dice: 0.0347 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6107 - accuracy: 0.8908 - eval_dice: 0.0708\n",
      "Epoch 38: val_loss improved from 9.56082 to 9.54120, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 96s 762ms/step - loss: 9.6107 - accuracy: 0.8908 - eval_dice: 0.0708 - val_loss: 9.5412 - val_accuracy: 0.9928 - val_eval_dice: 0.0360 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6276 - accuracy: 0.8903 - eval_dice: 0.0721\n",
      "Epoch 39: val_loss improved from 9.54120 to 9.51870, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 95s 748ms/step - loss: 9.6276 - accuracy: 0.8903 - eval_dice: 0.0721 - val_loss: 9.5187 - val_accuracy: 0.9947 - val_eval_dice: 0.0304 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5973 - accuracy: 0.8975 - eval_dice: 0.0675\n",
      "Epoch 40: val_loss did not improve from 9.51870\n",
      "74/74 [==============================] - 94s 751ms/step - loss: 9.5973 - accuracy: 0.8975 - eval_dice: 0.0675 - val_loss: 9.5640 - val_accuracy: 0.9949 - val_eval_dice: 0.0348 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5896 - accuracy: 0.8955 - eval_dice: 0.0675\n",
      "Epoch 41: val_loss did not improve from 9.51870\n",
      "74/74 [==============================] - 94s 747ms/step - loss: 9.5896 - accuracy: 0.8955 - eval_dice: 0.0675 - val_loss: 9.5447 - val_accuracy: 0.9934 - val_eval_dice: 0.0347 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5674 - accuracy: 0.8931 - eval_dice: 0.0682\n",
      "Epoch 42: val_loss improved from 9.51870 to 9.49217, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 94s 757ms/step - loss: 9.5674 - accuracy: 0.8931 - eval_dice: 0.0682 - val_loss: 9.4922 - val_accuracy: 0.9931 - val_eval_dice: 0.0307 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5764 - accuracy: 0.8864 - eval_dice: 0.0720\n",
      "Epoch 43: val_loss improved from 9.49217 to 9.42738, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_4_(2024-07-20)/02.59.33\\cp.ckpt\n",
      "74/74 [==============================] - 96s 755ms/step - loss: 9.5764 - accuracy: 0.8864 - eval_dice: 0.0720 - val_loss: 9.4274 - val_accuracy: 0.9946 - val_eval_dice: 0.0299 - lr: 1.0000e-04\n",
      "Epoch 44/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5357 - accuracy: 0.9042 - eval_dice: 0.0630\n",
      "Epoch 44: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 95s 771ms/step - loss: 9.5357 - accuracy: 0.9042 - eval_dice: 0.0630 - val_loss: 9.4474 - val_accuracy: 0.9944 - val_eval_dice: 0.0223 - lr: 1.0000e-04\n",
      "Epoch 45/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5760 - accuracy: 0.8900 - eval_dice: 0.0698\n",
      "Epoch 45: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 99s 780ms/step - loss: 9.5760 - accuracy: 0.8900 - eval_dice: 0.0698 - val_loss: 9.5116 - val_accuracy: 0.9947 - val_eval_dice: 0.0354 - lr: 1.0000e-04\n",
      "Epoch 46/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5305 - accuracy: 0.8946 - eval_dice: 0.0677\n",
      "Epoch 46: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 100s 808ms/step - loss: 9.5305 - accuracy: 0.8946 - eval_dice: 0.0677 - val_loss: 9.5938 - val_accuracy: 0.9948 - val_eval_dice: 0.0284 - lr: 1.0000e-04\n",
      "Epoch 47/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5752 - accuracy: 0.8861 - eval_dice: 0.0722\n",
      "Epoch 47: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 99s 763ms/step - loss: 9.5752 - accuracy: 0.8861 - eval_dice: 0.0722 - val_loss: 9.5141 - val_accuracy: 0.9930 - val_eval_dice: 0.0383 - lr: 1.0000e-04\n",
      "Epoch 48/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4908 - accuracy: 0.8941 - eval_dice: 0.0677\n",
      "Epoch 48: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 94s 747ms/step - loss: 9.4908 - accuracy: 0.8941 - eval_dice: 0.0677 - val_loss: 9.4928 - val_accuracy: 0.9933 - val_eval_dice: 0.0317 - lr: 1.0000e-04\n",
      "Epoch 49/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4960 - accuracy: 0.8952 - eval_dice: 0.0672\n",
      "Epoch 49: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 94s 746ms/step - loss: 9.4960 - accuracy: 0.8952 - eval_dice: 0.0672 - val_loss: 9.4658 - val_accuracy: 0.9903 - val_eval_dice: 0.0321 - lr: 1.0000e-04\n",
      "Epoch 50/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4953 - accuracy: 0.8906 - eval_dice: 0.0692\n",
      "Epoch 50: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 95s 740ms/step - loss: 9.4953 - accuracy: 0.8906 - eval_dice: 0.0692 - val_loss: 9.4442 - val_accuracy: 0.9941 - val_eval_dice: 0.0334 - lr: 1.0000e-04\n",
      "Epoch 51/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4923 - accuracy: 0.8881 - eval_dice: 0.0714\n",
      "Epoch 51: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 95s 753ms/step - loss: 9.4923 - accuracy: 0.8881 - eval_dice: 0.0714 - val_loss: 9.5293 - val_accuracy: 0.9918 - val_eval_dice: 0.0408 - lr: 1.0000e-04\n",
      "Epoch 52/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4682 - accuracy: 0.8960 - eval_dice: 0.0680\n",
      "Epoch 52: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 94s 749ms/step - loss: 9.4682 - accuracy: 0.8960 - eval_dice: 0.0680 - val_loss: 9.4544 - val_accuracy: 0.9927 - val_eval_dice: 0.0330 - lr: 2.0000e-05\n",
      "Epoch 53/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4582 - accuracy: 0.8918 - eval_dice: 0.0702\n",
      "Epoch 53: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 95s 748ms/step - loss: 9.4582 - accuracy: 0.8918 - eval_dice: 0.0702 - val_loss: 9.4619 - val_accuracy: 0.9920 - val_eval_dice: 0.0355 - lr: 2.0000e-05\n",
      "Epoch 54/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4307 - accuracy: 0.8885 - eval_dice: 0.0717\n",
      "Epoch 54: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 94s 746ms/step - loss: 9.4307 - accuracy: 0.8885 - eval_dice: 0.0717 - val_loss: 9.4413 - val_accuracy: 0.9922 - val_eval_dice: 0.0361 - lr: 2.0000e-05\n",
      "Epoch 55/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4271 - accuracy: 0.8962 - eval_dice: 0.0679\n",
      "Epoch 55: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 94s 748ms/step - loss: 9.4271 - accuracy: 0.8962 - eval_dice: 0.0679 - val_loss: 9.4502 - val_accuracy: 0.9887 - val_eval_dice: 0.0389 - lr: 2.0000e-05\n",
      "Epoch 56/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4306 - accuracy: 0.8914 - eval_dice: 0.0705\n",
      "Epoch 56: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 95s 744ms/step - loss: 9.4306 - accuracy: 0.8914 - eval_dice: 0.0705 - val_loss: 9.4293 - val_accuracy: 0.9923 - val_eval_dice: 0.0371 - lr: 2.0000e-05\n",
      "Epoch 57/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4218 - accuracy: 0.8931 - eval_dice: 0.0704\n",
      "Epoch 57: val_loss did not improve from 9.42738\n",
      "74/74 [==============================] - 92s 733ms/step - loss: 9.4218 - accuracy: 0.8931 - eval_dice: 0.0704 - val_loss: 9.4410 - val_accuracy: 0.9901 - val_eval_dice: 0.0398 - lr: 2.0000e-05\n",
      "Epoch 57: early stopping\n",
      "Fold 5/5\n",
      "Number of training tuple paths: 149\n",
      "Number of validation tuple paths: 37\n",
      "Number of test tuple paths: 48\n",
      "Normalization parameters training: (0.0, 2701.6875)\n",
      "Layer Normalization:  batchnorm\n",
      "Input shape after downsample: (None, 16, 128, 128, 32)\n",
      "Input shape after downsample: (None, 8, 64, 64, 64)\n",
      "Input shape after downsample: (None, 4, 32, 32, 128)\n",
      "Input shape after downsample: (None, 2, 16, 16, 512)\n",
      "Epoch 1/60\n",
      "      6/Unknown - 39s 705ms/step - loss: 13.8915 - accuracy: 0.1953 - eval_dice: 0.8876WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1472s vs `on_train_batch_end` time: 0.5772s). Check your callbacks.\n",
      "     74/Unknown - 86s 685ms/step - loss: 12.6040 - accuracy: 0.6568 - eval_dice: 0.6522\n",
      "Epoch 1: val_loss improved from inf to 11.70701, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 95s 813ms/step - loss: 12.6040 - accuracy: 0.6568 - eval_dice: 0.6522 - val_loss: 11.7070 - val_accuracy: 0.9919 - val_eval_dice: 0.3575 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.3544 - accuracy: 0.8862 - eval_dice: 0.2447\n",
      "Epoch 2: val_loss improved from 11.70701 to 11.30800, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 92s 716ms/step - loss: 11.3544 - accuracy: 0.8862 - eval_dice: 0.2447 - val_loss: 11.3080 - val_accuracy: 0.9969 - val_eval_dice: 0.1675 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.2119 - accuracy: 0.8878 - eval_dice: 0.1622\n",
      "Epoch 3: val_loss improved from 11.30800 to 11.19936, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 95s 769ms/step - loss: 11.2119 - accuracy: 0.8878 - eval_dice: 0.1622 - val_loss: 11.1994 - val_accuracy: 0.9943 - val_eval_dice: 0.1146 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1659 - accuracy: 0.8823 - eval_dice: 0.1358\n",
      "Epoch 4: val_loss improved from 11.19936 to 11.18558, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 98s 762ms/step - loss: 11.1659 - accuracy: 0.8823 - eval_dice: 0.1358 - val_loss: 11.1856 - val_accuracy: 0.9935 - val_eval_dice: 0.1034 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1288 - accuracy: 0.8929 - eval_dice: 0.1161\n",
      "Epoch 5: val_loss improved from 11.18558 to 11.13595, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 99s 777ms/step - loss: 11.1288 - accuracy: 0.8929 - eval_dice: 0.1161 - val_loss: 11.1359 - val_accuracy: 0.9931 - val_eval_dice: 0.0891 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1033 - accuracy: 0.8910 - eval_dice: 0.1087\n",
      "Epoch 6: val_loss did not improve from 11.13595\n",
      "74/74 [==============================] - 94s 725ms/step - loss: 11.1033 - accuracy: 0.8910 - eval_dice: 0.1087 - val_loss: 11.1507 - val_accuracy: 0.9962 - val_eval_dice: 0.0956 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0832 - accuracy: 0.8919 - eval_dice: 0.1035\n",
      "Epoch 7: val_loss improved from 11.13595 to 11.11854, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 718ms/step - loss: 11.0832 - accuracy: 0.8919 - eval_dice: 0.1035 - val_loss: 11.1185 - val_accuracy: 0.9953 - val_eval_dice: 0.0875 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0556 - accuracy: 0.8940 - eval_dice: 0.0958\n",
      "Epoch 8: val_loss improved from 11.11854 to 11.05878, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 721ms/step - loss: 11.0556 - accuracy: 0.8940 - eval_dice: 0.0958 - val_loss: 11.0588 - val_accuracy: 0.9963 - val_eval_dice: 0.0686 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0302 - accuracy: 0.8972 - eval_dice: 0.0894\n",
      "Epoch 9: val_loss improved from 11.05878 to 11.03334, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 91s 714ms/step - loss: 11.0302 - accuracy: 0.8972 - eval_dice: 0.0894 - val_loss: 11.0333 - val_accuracy: 0.9963 - val_eval_dice: 0.0614 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0155 - accuracy: 0.8894 - eval_dice: 0.0909\n",
      "Epoch 10: val_loss improved from 11.03334 to 11.01442, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 726ms/step - loss: 11.0155 - accuracy: 0.8894 - eval_dice: 0.0909 - val_loss: 11.0144 - val_accuracy: 0.9962 - val_eval_dice: 0.0639 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0103 - accuracy: 0.8824 - eval_dice: 0.0938\n",
      "Epoch 11: val_loss improved from 11.01442 to 11.00648, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 725ms/step - loss: 11.0103 - accuracy: 0.8824 - eval_dice: 0.0938 - val_loss: 11.0065 - val_accuracy: 0.9956 - val_eval_dice: 0.0629 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9751 - accuracy: 0.8906 - eval_dice: 0.0861\n",
      "Epoch 12: val_loss improved from 11.00648 to 10.95612, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 92s 719ms/step - loss: 10.9751 - accuracy: 0.8906 - eval_dice: 0.0861 - val_loss: 10.9561 - val_accuracy: 0.9951 - val_eval_dice: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9458 - accuracy: 0.9067 - eval_dice: 0.0757\n",
      "Epoch 13: val_loss improved from 10.95612 to 10.93058, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 95s 749ms/step - loss: 10.9458 - accuracy: 0.9067 - eval_dice: 0.0757 - val_loss: 10.9306 - val_accuracy: 0.9952 - val_eval_dice: 0.0465 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9363 - accuracy: 0.8911 - eval_dice: 0.0820\n",
      "Epoch 14: val_loss did not improve from 10.93058\n",
      "74/74 [==============================] - 97s 755ms/step - loss: 10.9363 - accuracy: 0.8911 - eval_dice: 0.0820 - val_loss: 10.9404 - val_accuracy: 0.9925 - val_eval_dice: 0.0524 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9177 - accuracy: 0.8874 - eval_dice: 0.0820\n",
      "Epoch 15: val_loss improved from 10.93058 to 10.88851, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 98s 776ms/step - loss: 10.9177 - accuracy: 0.8874 - eval_dice: 0.0820 - val_loss: 10.8885 - val_accuracy: 0.9929 - val_eval_dice: 0.0465 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8271 - accuracy: 0.8877 - eval_dice: 0.0791\n",
      "Epoch 16: val_loss improved from 10.88851 to 10.80173, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 98s 769ms/step - loss: 10.8271 - accuracy: 0.8877 - eval_dice: 0.0791 - val_loss: 10.8017 - val_accuracy: 0.9929 - val_eval_dice: 0.0538 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.7158 - accuracy: 0.8961 - eval_dice: 0.0728\n",
      "Epoch 17: val_loss improved from 10.80173 to 10.66867, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 96s 762ms/step - loss: 10.7158 - accuracy: 0.8961 - eval_dice: 0.0728 - val_loss: 10.6687 - val_accuracy: 0.9923 - val_eval_dice: 0.0463 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.6391 - accuracy: 0.8885 - eval_dice: 0.0754\n",
      "Epoch 18: val_loss improved from 10.66867 to 10.56595, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 94s 724ms/step - loss: 10.6391 - accuracy: 0.8885 - eval_dice: 0.0754 - val_loss: 10.5660 - val_accuracy: 0.9908 - val_eval_dice: 0.0380 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.4431 - accuracy: 0.8861 - eval_dice: 0.0744\n",
      "Epoch 19: val_loss improved from 10.56595 to 10.37558, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 730ms/step - loss: 10.4431 - accuracy: 0.8861 - eval_dice: 0.0744 - val_loss: 10.3756 - val_accuracy: 0.9926 - val_eval_dice: 0.0379 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2630 - accuracy: 0.8862 - eval_dice: 0.0734\n",
      "Epoch 20: val_loss improved from 10.37558 to 10.26127, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 731ms/step - loss: 10.2630 - accuracy: 0.8862 - eval_dice: 0.0734 - val_loss: 10.2613 - val_accuracy: 0.9923 - val_eval_dice: 0.0548 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1894 - accuracy: 0.8854 - eval_dice: 0.0736\n",
      "Epoch 21: val_loss improved from 10.26127 to 10.21064, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 91s 714ms/step - loss: 10.1894 - accuracy: 0.8854 - eval_dice: 0.0736 - val_loss: 10.2106 - val_accuracy: 0.9923 - val_eval_dice: 0.0388 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0646 - accuracy: 0.8894 - eval_dice: 0.0701\n",
      "Epoch 22: val_loss improved from 10.21064 to 10.07154, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 94s 730ms/step - loss: 10.0646 - accuracy: 0.8894 - eval_dice: 0.0701 - val_loss: 10.0715 - val_accuracy: 0.9934 - val_eval_dice: 0.0396 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.9424 - accuracy: 0.8944 - eval_dice: 0.0679\n",
      "Epoch 23: val_loss did not improve from 10.07154\n",
      "74/74 [==============================] - 91s 713ms/step - loss: 9.9424 - accuracy: 0.8944 - eval_dice: 0.0679 - val_loss: 10.1361 - val_accuracy: 0.9940 - val_eval_dice: 0.0517 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8848 - accuracy: 0.8945 - eval_dice: 0.0672\n",
      "Epoch 24: val_loss improved from 10.07154 to 9.84204, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 92s 723ms/step - loss: 9.8848 - accuracy: 0.8945 - eval_dice: 0.0672 - val_loss: 9.8420 - val_accuracy: 0.9937 - val_eval_dice: 0.0391 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7498 - accuracy: 0.8913 - eval_dice: 0.0689\n",
      "Epoch 25: val_loss improved from 9.84204 to 9.72917, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 92s 713ms/step - loss: 9.7498 - accuracy: 0.8913 - eval_dice: 0.0689 - val_loss: 9.7292 - val_accuracy: 0.9930 - val_eval_dice: 0.0417 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6588 - accuracy: 0.8910 - eval_dice: 0.0692\n",
      "Epoch 26: val_loss improved from 9.72917 to 9.68279, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 724ms/step - loss: 9.6588 - accuracy: 0.8910 - eval_dice: 0.0692 - val_loss: 9.6828 - val_accuracy: 0.9926 - val_eval_dice: 0.0321 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5948 - accuracy: 0.8889 - eval_dice: 0.0704\n",
      "Epoch 27: val_loss improved from 9.68279 to 9.65111, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 722ms/step - loss: 9.5948 - accuracy: 0.8889 - eval_dice: 0.0704 - val_loss: 9.6511 - val_accuracy: 0.9931 - val_eval_dice: 0.0334 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5909 - accuracy: 0.8944 - eval_dice: 0.0680\n",
      "Epoch 28: val_loss improved from 9.65111 to 9.64569, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 91s 718ms/step - loss: 9.5909 - accuracy: 0.8944 - eval_dice: 0.0680 - val_loss: 9.6457 - val_accuracy: 0.9927 - val_eval_dice: 0.0442 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5225 - accuracy: 0.8866 - eval_dice: 0.0721\n",
      "Epoch 29: val_loss improved from 9.64569 to 9.62637, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 94s 728ms/step - loss: 9.5225 - accuracy: 0.8866 - eval_dice: 0.0721 - val_loss: 9.6264 - val_accuracy: 0.9916 - val_eval_dice: 0.0323 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4345 - accuracy: 0.8899 - eval_dice: 0.0706\n",
      "Epoch 30: val_loss improved from 9.62637 to 9.49504, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 92s 722ms/step - loss: 9.4345 - accuracy: 0.8899 - eval_dice: 0.0706 - val_loss: 9.4950 - val_accuracy: 0.9932 - val_eval_dice: 0.0401 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3868 - accuracy: 0.8911 - eval_dice: 0.0694\n",
      "Epoch 31: val_loss did not improve from 9.49504\n",
      "74/74 [==============================] - 93s 741ms/step - loss: 9.3868 - accuracy: 0.8911 - eval_dice: 0.0694 - val_loss: 9.5073 - val_accuracy: 0.9907 - val_eval_dice: 0.0384 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3490 - accuracy: 0.9000 - eval_dice: 0.0651\n",
      "Epoch 32: val_loss improved from 9.49504 to 9.46214, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 97s 753ms/step - loss: 9.3490 - accuracy: 0.9000 - eval_dice: 0.0651 - val_loss: 9.4621 - val_accuracy: 0.9925 - val_eval_dice: 0.0284 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3548 - accuracy: 0.8862 - eval_dice: 0.0736\n",
      "Epoch 33: val_loss did not improve from 9.46214\n",
      "74/74 [==============================] - 98s 782ms/step - loss: 9.3548 - accuracy: 0.8862 - eval_dice: 0.0736 - val_loss: 9.5476 - val_accuracy: 0.9920 - val_eval_dice: 0.0380 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3473 - accuracy: 0.8961 - eval_dice: 0.0677\n",
      "Epoch 34: val_loss did not improve from 9.46214\n",
      "74/74 [==============================] - 92s 708ms/step - loss: 9.3473 - accuracy: 0.8961 - eval_dice: 0.0677 - val_loss: 9.4750 - val_accuracy: 0.9933 - val_eval_dice: 0.0347 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3036 - accuracy: 0.8913 - eval_dice: 0.0699\n",
      "Epoch 35: val_loss did not improve from 9.46214\n",
      "74/74 [==============================] - 90s 713ms/step - loss: 9.3036 - accuracy: 0.8913 - eval_dice: 0.0699 - val_loss: 9.4919 - val_accuracy: 0.9942 - val_eval_dice: 0.0316 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2967 - accuracy: 0.8939 - eval_dice: 0.0698\n",
      "Epoch 36: val_loss did not improve from 9.46214\n",
      "74/74 [==============================] - 91s 708ms/step - loss: 9.2967 - accuracy: 0.8939 - eval_dice: 0.0698 - val_loss: 9.4958 - val_accuracy: 0.9931 - val_eval_dice: 0.0314 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3039 - accuracy: 0.8896 - eval_dice: 0.0728\n",
      "Epoch 37: val_loss did not improve from 9.46214\n",
      "74/74 [==============================] - 92s 721ms/step - loss: 9.3039 - accuracy: 0.8896 - eval_dice: 0.0728 - val_loss: 9.4965 - val_accuracy: 0.9929 - val_eval_dice: 0.0353 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2792 - accuracy: 0.8963 - eval_dice: 0.0694\n",
      "Epoch 38: val_loss improved from 9.46214 to 9.45065, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 93s 732ms/step - loss: 9.2792 - accuracy: 0.8963 - eval_dice: 0.0694 - val_loss: 9.4506 - val_accuracy: 0.9923 - val_eval_dice: 0.0338 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2837 - accuracy: 0.8892 - eval_dice: 0.0717\n",
      "Epoch 39: val_loss did not improve from 9.45065\n",
      "74/74 [==============================] - 91s 711ms/step - loss: 9.2837 - accuracy: 0.8892 - eval_dice: 0.0717 - val_loss: 9.4873 - val_accuracy: 0.9941 - val_eval_dice: 0.0376 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2426 - accuracy: 0.8908 - eval_dice: 0.0698\n",
      "Epoch 40: val_loss improved from 9.45065 to 9.41103, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 92s 720ms/step - loss: 9.2426 - accuracy: 0.8908 - eval_dice: 0.0698 - val_loss: 9.4110 - val_accuracy: 0.9932 - val_eval_dice: 0.0339 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2501 - accuracy: 0.8888 - eval_dice: 0.0707\n",
      "Epoch 41: val_loss did not improve from 9.41103\n",
      "74/74 [==============================] - 92s 720ms/step - loss: 9.2501 - accuracy: 0.8888 - eval_dice: 0.0707 - val_loss: 9.4562 - val_accuracy: 0.9931 - val_eval_dice: 0.0315 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2146 - accuracy: 0.8949 - eval_dice: 0.0671\n",
      "Epoch 42: val_loss did not improve from 9.41103\n",
      "74/74 [==============================] - 91s 713ms/step - loss: 9.2146 - accuracy: 0.8949 - eval_dice: 0.0671 - val_loss: 9.4893 - val_accuracy: 0.9928 - val_eval_dice: 0.0398 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2434 - accuracy: 0.8911 - eval_dice: 0.0689\n",
      "Epoch 43: val_loss improved from 9.41103 to 9.40236, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 91s 718ms/step - loss: 9.2434 - accuracy: 0.8911 - eval_dice: 0.0689 - val_loss: 9.4024 - val_accuracy: 0.9917 - val_eval_dice: 0.0320 - lr: 1.0000e-04\n",
      "Epoch 44/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2527 - accuracy: 0.8886 - eval_dice: 0.0707\n",
      "Epoch 44: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 92s 707ms/step - loss: 9.2527 - accuracy: 0.8886 - eval_dice: 0.0707 - val_loss: 9.4190 - val_accuracy: 0.9935 - val_eval_dice: 0.0293 - lr: 1.0000e-04\n",
      "Epoch 45/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2435 - accuracy: 0.8972 - eval_dice: 0.0681\n",
      "Epoch 45: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 89s 702ms/step - loss: 9.2435 - accuracy: 0.8972 - eval_dice: 0.0681 - val_loss: 9.4227 - val_accuracy: 0.9896 - val_eval_dice: 0.0359 - lr: 1.0000e-04\n",
      "Epoch 46/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2288 - accuracy: 0.8879 - eval_dice: 0.0722\n",
      "Epoch 46: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 92s 725ms/step - loss: 9.2288 - accuracy: 0.8879 - eval_dice: 0.0722 - val_loss: 9.4300 - val_accuracy: 0.9912 - val_eval_dice: 0.0334 - lr: 1.0000e-04\n",
      "Epoch 47/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2263 - accuracy: 0.8828 - eval_dice: 0.0748\n",
      "Epoch 47: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 98s 774ms/step - loss: 9.2263 - accuracy: 0.8828 - eval_dice: 0.0748 - val_loss: 9.4190 - val_accuracy: 0.9893 - val_eval_dice: 0.0359 - lr: 1.0000e-04\n",
      "Epoch 48/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1897 - accuracy: 0.8902 - eval_dice: 0.0715\n",
      "Epoch 48: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 94s 729ms/step - loss: 9.1897 - accuracy: 0.8902 - eval_dice: 0.0715 - val_loss: 9.4399 - val_accuracy: 0.9869 - val_eval_dice: 0.0410 - lr: 1.0000e-04\n",
      "Epoch 49/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2064 - accuracy: 0.8849 - eval_dice: 0.0759\n",
      "Epoch 49: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 90s 698ms/step - loss: 9.2064 - accuracy: 0.8849 - eval_dice: 0.0759 - val_loss: 9.4803 - val_accuracy: 0.9849 - val_eval_dice: 0.0475 - lr: 1.0000e-04\n",
      "Epoch 50/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2007 - accuracy: 0.8860 - eval_dice: 0.0761\n",
      "Epoch 50: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 92s 712ms/step - loss: 9.2007 - accuracy: 0.8860 - eval_dice: 0.0761 - val_loss: 9.4186 - val_accuracy: 0.9894 - val_eval_dice: 0.0429 - lr: 1.0000e-04\n",
      "Epoch 51/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2301 - accuracy: 0.8887 - eval_dice: 0.0756\n",
      "Epoch 51: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 91s 710ms/step - loss: 9.2301 - accuracy: 0.8887 - eval_dice: 0.0756 - val_loss: 9.4544 - val_accuracy: 0.9882 - val_eval_dice: 0.0404 - lr: 1.0000e-04\n",
      "Epoch 52/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1973 - accuracy: 0.8931 - eval_dice: 0.0730\n",
      "Epoch 52: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 92s 709ms/step - loss: 9.1973 - accuracy: 0.8931 - eval_dice: 0.0730 - val_loss: 9.4388 - val_accuracy: 0.9862 - val_eval_dice: 0.0418 - lr: 2.0000e-05\n",
      "Epoch 53/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1845 - accuracy: 0.8903 - eval_dice: 0.0741\n",
      "Epoch 53: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 90s 713ms/step - loss: 9.1845 - accuracy: 0.8903 - eval_dice: 0.0741 - val_loss: 9.4182 - val_accuracy: 0.9873 - val_eval_dice: 0.0407 - lr: 2.0000e-05\n",
      "Epoch 54/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1643 - accuracy: 0.8909 - eval_dice: 0.0740\n",
      "Epoch 54: val_loss did not improve from 9.40236\n",
      "74/74 [==============================] - 92s 719ms/step - loss: 9.1643 - accuracy: 0.8909 - eval_dice: 0.0740 - val_loss: 9.4102 - val_accuracy: 0.9899 - val_eval_dice: 0.0370 - lr: 2.0000e-05\n",
      "Epoch 55/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1485 - accuracy: 0.8936 - eval_dice: 0.0722\n",
      "Epoch 55: val_loss improved from 9.40236 to 9.39261, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_AXIAL/Sigma3/BatchNorm/cross_validation/unet3d-GN_fold_5_(2024-07-20)/04.31.41\\cp.ckpt\n",
      "74/74 [==============================] - 90s 710ms/step - loss: 9.1485 - accuracy: 0.8936 - eval_dice: 0.0722 - val_loss: 9.3926 - val_accuracy: 0.9896 - val_eval_dice: 0.0370 - lr: 2.0000e-05\n",
      "Epoch 56/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1560 - accuracy: 0.8919 - eval_dice: 0.0730\n",
      "Epoch 56: val_loss did not improve from 9.39261\n",
      "74/74 [==============================] - 92s 710ms/step - loss: 9.1560 - accuracy: 0.8919 - eval_dice: 0.0730 - val_loss: 9.3981 - val_accuracy: 0.9890 - val_eval_dice: 0.0368 - lr: 2.0000e-05\n",
      "Epoch 57/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1609 - accuracy: 0.8867 - eval_dice: 0.0752\n",
      "Epoch 57: val_loss did not improve from 9.39261\n",
      "74/74 [==============================] - 91s 716ms/step - loss: 9.1609 - accuracy: 0.8867 - eval_dice: 0.0752 - val_loss: 9.4314 - val_accuracy: 0.9894 - val_eval_dice: 0.0374 - lr: 2.0000e-05\n",
      "Epoch 58/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1664 - accuracy: 0.8802 - eval_dice: 0.0790\n",
      "Epoch 58: val_loss did not improve from 9.39261\n",
      "74/74 [==============================] - 92s 718ms/step - loss: 9.1664 - accuracy: 0.8802 - eval_dice: 0.0790 - val_loss: 9.4120 - val_accuracy: 0.9897 - val_eval_dice: 0.0373 - lr: 2.0000e-05\n",
      "Epoch 59/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1409 - accuracy: 0.9018 - eval_dice: 0.0677\n",
      "Epoch 59: val_loss did not improve from 9.39261\n",
      "74/74 [==============================] - 89s 706ms/step - loss: 9.1409 - accuracy: 0.9018 - eval_dice: 0.0677 - val_loss: 9.3945 - val_accuracy: 0.9890 - val_eval_dice: 0.0349 - lr: 2.0000e-05\n",
      "Epoch 60/60\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1587 - accuracy: 0.8968 - eval_dice: 0.0694\n",
      "Epoch 60: val_loss did not improve from 9.39261\n",
      "74/74 [==============================] - 92s 718ms/step - loss: 9.1587 - accuracy: 0.8968 - eval_dice: 0.0694 - val_loss: 9.4065 - val_accuracy: 0.9889 - val_eval_dice: 0.0353 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "histories = run_kfold_cross_val(n_folds,params,tfrecords_dir,test_subjects,batch_size,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,value in enumerate(histories):\n",
    "    history_dict = histories[i].history\n",
    "    train_loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "    train_accuracy = history_dict['accuracy']\n",
    "    val_accuracy = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "    visualize_learning_curves(epochs,train_loss,val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataortho_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
