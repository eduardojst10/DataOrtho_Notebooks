{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataOrtho Sagittal \n",
    "\n",
    "Sagittal Subset Modeling Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 2.10.0\n",
      "tfa: 0.20.0\n",
      "GPU devices:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import  Callback,ModelCheckpoint,TensorBoard, EarlyStopping # ,LearningRateScheduler - using dynamic one\n",
    "\n",
    "print('tf:',tf.__version__)\n",
    "print('tfa:',tfa.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        print('GPU devices: ',gpus)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vars and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resampled_dir  = 'C:/Users/Eduardo/Desktop/DataOrtho_Resampled/'\n",
    "tfrecords_dir = 'C:/Users/Eduardo/Desktop/DataOrtho_Serialized/'\n",
    "logs_dir = 'C:/Users/Eduardo/Desktop/dataortho_edu/logs/' \n",
    "\n",
    "# Cross validation vars\n",
    "fold_idx = 1\n",
    "n_folds = 5\n",
    "\n",
    "# Training parameters\n",
    "params = {'augment':False,\n",
    "          'mode': tf.estimator.ModeKeys.TRAIN, \n",
    "          'seed':42,\n",
    "          'subset':'DATASET_SAGITTAL',\n",
    "          'interpolation':'Linear Interpolation',\n",
    "          'normalization': 'batchnorm',#'batchnorm',\n",
    "          'total_train_samples':0, # value attributed in dataset_split\n",
    "          'total_val_samples':0,   # value attributed in dataset_split\n",
    "          'lr': 0.0001, # 0.001 de forma a ver\n",
    "          'loss':'dice+ce',\n",
    "          'dropout':0.2,\n",
    "          'batch_size':2,\n",
    "          'norm_params_minmax':None, #(0.0, 3893.436),\n",
    "          'norm_params_meanstd':None\n",
    "          }\n",
    "# Direct vars\n",
    "batch_size = 2\n",
    "seed = 42 \n",
    "\n",
    "#Numver of channel for each subset\n",
    "num_channels = {'DATASET_AXIAL': 12,'DATASET_SAGITTAL':8,'DATASET_DYNAMIC':19}\n",
    "\n",
    "# Data Shapes (Before batching) \n",
    "xshape =  {'DATASET_AXIAL': (32,256, 256,1), 'DATASET_SAGITTAL': (32,256, 256,1),'DATASET_DYNAMIC': (64,256, 256,1)}\n",
    "yshape = {'DATASET_AXIAL': (32,256, 256,12), 'DATASET_SAGITTAL': (32,256, 256,8),'DATASET_DYNAMIC': (64, 256, 256, 19)}\n",
    "input_shape={'DATASET_AXIAL': (32,256, 256,1), 'DATASET_SAGITTAL': (32,256, 256,1),'DATASET_DYNAMIC': (64,256, 256,1)}\n",
    "\n",
    "# test subset individuals \n",
    "test_subjects = {'DATASET_SAGITTAL': [5, 20, 23, 34, 45, 54, 64, 70, 75, 81, 12, 13, 38, 42, 44, 49, 62, 68]}\n",
    "\n",
    "# landmark Subset Classes\n",
    "landmarkClasses = {'DATASET_SAGITTAL':\n",
    "                       {0:'S0',\n",
    "                        1:'S1', \n",
    "                        2:'S2', \n",
    "                        3:'S3', \n",
    "                        4:'S4', \n",
    "                        5:'S5', \n",
    "                        6:'S6', \n",
    "                        7:'SB' }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4D (channels dimension) Visualization \n",
    "- Help functions for Data augmentation Visualization\n",
    "- Help functions for Evaluation Visualization\n",
    "- String path refactor for Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_montage_mri_4D_channel(mri_volume,heatmaps_masks,channel, start_slice, end_slice, step=1):\n",
    "    num_landmarks = heatmaps_masks.shape[-1] \n",
    "    \n",
    "    fig, axarr = plt.subplots(1, (end_slice - start_slice) // step, figsize=(20, 5*num_landmarks))\n",
    "    \n",
    "    max_intensity_idx = np.unravel_index(np.argmax(heatmaps_masks[..., channel]), heatmaps_masks[..., channel].shape)\n",
    "    \n",
    "    print('Intensity masks: ', heatmaps_masks[max_intensity_idx[0],max_intensity_idx[1],max_intensity_idx[2], channel])\n",
    "    print('Intensity volume: ', mri_volume[max_intensity_idx[0],max_intensity_idx[1],max_intensity_idx[2], 0])\n",
    "\n",
    "    print(f\"Channel {channel} has maximum intensity at slice: {max_intensity_idx[0]}\")\n",
    "    max_intensity = np.argmax(heatmaps_masks[..., channel])\n",
    "    print('max: ', max_intensity)\n",
    "    for i, idx in enumerate(range(start_slice, end_slice, step)):\n",
    "        axarr[i].imshow(mri_volume[idx,:], cmap='gray') \n",
    "        axarr[i].imshow(heatmaps_masks[idx,:, :,channel], cmap='jet', alpha=0.5,vmin = 0, vmax=1)  # specific landmark heatmap overlay\n",
    "        axarr[i].axis('off')\n",
    "        if i == 0:\n",
    "            if channel == num_landmarks - 1:\n",
    "                axarr[i].set_ylabel(f'Background')\n",
    "            else:\n",
    "                axarr[i].set_ylabel(f'Landmark {channel + 1}')\n",
    "            \n",
    "        axarr[i].set_title(f'Slice: {idx}')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_specific_slice_4Dmask(slice_idx,channel,mri_volume, heatmaps_channel):\n",
    "    fig, axarr = plt.subplots(1, figsize=(16, 8))\n",
    "    axarr.imshow(mri_volume[slice_idx,:,:],cmap='gray')\n",
    "    axarr.imshow(heatmaps_channel[slice_idx,:, :,  channel], cmap='jet', alpha=0.5,vmin = 0, vmax=1)\n",
    "    axarr.set_title(f'Slice: {slice_idx}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#---------- Help functions for Data augmentation Visualization ----------#\n",
    "# Function to visualize a single slice\n",
    "def visualize_slice(volume_slice, mask_slice=None, cmap='gray'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(volume_slice, cmap=cmap)\n",
    "    plt.title('Volume Slice')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if mask_slice is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mask_slice, cmap=cmap)\n",
    "        plt.title('Mask Slice')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#---------- Help functions for Evaluation Visualization ----------#\n",
    "\n",
    "def visualize_learning_curves(epochs,train_loss,val_loss):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "    #plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# not needed in ubuntu\n",
    "def refactor_path(path_example):\n",
    "    return path_example.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# returns the maximum intensity for each channel slice \n",
    "def analyze_heatmaps_predictions(heatmaps_masks,subset):\n",
    "    num_channels = heatmaps_masks.shape[-1] # Number of landmarks (channels)\n",
    "    max_intensity_slices = []\n",
    "    landmarksNames = landmarkClasses[subset]\n",
    "    for channel in range(num_channels):\n",
    "        # Find the index of maximum intensity in the channel\n",
    "        max_intensity_idx = np.unravel_index(np.argmax(heatmaps_masks[..., channel]), \n",
    "                                             heatmaps_masks[..., channel].shape)\n",
    "        # Get the slice number (depth) with maximum intensity\n",
    "        slice_with_max_intensity = max_intensity_idx[0]\n",
    "\n",
    "        max_intensity_slices.append((channel, slice_with_max_intensity))\n",
    "    \n",
    "    for channel, slice_idx in max_intensity_slices:\n",
    "        print(f\"Landmark {landmarksNames[channel]} has maximum intensity at slice: {slice_idx}\")\n",
    "    #return max_intensity_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D procedures from Architecture were analysed and used as base for the following:\n",
    "\n",
    "- random_horizontal_flip()\n",
    "- random_rotate_3d() \n",
    "- random_translate_3d() : 2D only\n",
    "- blur()\n",
    "- noising()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validated**\n",
    "- Random Horizontal Flip 3D : Sagittal needed? - tf.image.flip_up_down\n",
    "- Random Rotate 3D \n",
    "- Random Translate 3D\n",
    "- Blur \n",
    "- Noising\n",
    "\n",
    "**process_augmentation** - main Augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testar para sagittal - 0.5 threshold\n",
    "def random_horizontal_flip(samples, labels, threshold=0.3):\n",
    "    h_flip = tf.random.uniform([]) > threshold \n",
    "    def hflip_volume(volume):\n",
    "        return tf.image.flip_left_right(volume)\n",
    "\n",
    "    samples = tf.cond(h_flip, lambda: hflip_volume(samples), lambda: samples)\n",
    "    labels = tf.cond(h_flip, lambda: hflip_volume(labels), lambda: labels)\n",
    "    return samples, labels\n",
    "\n",
    "# rotate\n",
    "def random_rotate_3d(samples,labels,n_channels_samples,n_channels_labels,angle_range=(-0.7,0.7)):\n",
    "    angle = tf.random.uniform([], minval=angle_range[0], maxval=angle_range[1])\n",
    "    perform_augmentation = tf.random.uniform([]) > 0.1\n",
    "    samples = tf.cond(perform_augmentation, lambda: rotate_volume(samples, angle,n_channels_samples), lambda: samples)\n",
    "    labels = tf.cond(perform_augmentation, lambda: rotate_volume(labels, angle,n_channels_labels), lambda: labels)\n",
    "    return samples, labels\n",
    "\n",
    "\n",
    "def rotate_volume(volume,angle,n_channels):\n",
    "    def rotate_slice(slice):\n",
    "        # ensure the number of channels is known\n",
    "        # angle comes from higher lvl fnction\n",
    "        rotated_channels = [tfa.image.rotate(slice[:, :, c], angle) for c in range(n_channels)]\n",
    "        return tf.stack(rotated_channels, axis=-1)\n",
    "    # Apply the rotation to each slice in the volume or mask\n",
    "    rotated_volume = tf.map_fn(rotate_slice, volume, dtype=volume.dtype)\n",
    "    return rotated_volume\n",
    "\n",
    "# translate\n",
    "def random_translate_3d(samples, labels,n_slices,n_channels_samples,n_channels_labels, threshold=10):\n",
    "    perform_augmentation = tf.random.uniform([]) > 0.1# type: ignore\n",
    "    translations = tf.random.uniform([2], minval=-threshold, maxval=threshold)\n",
    "    samples = tf.cond(perform_augmentation, lambda: translate_volume(samples, translations,n_slices,n_channels_samples), lambda: samples) \n",
    "    labels = tf.cond(perform_augmentation, lambda: translate_volume(labels, translations,n_slices,n_channels_labels), lambda: labels)\n",
    "    return samples, labels\n",
    "\n",
    "\n",
    "def translate_volume(volume, translations,n_slices, n_channels):\n",
    "    # We will collect the translated slices in this list.\n",
    "    translated_slices = []\n",
    "\n",
    "    # Loop over the depth dimension and translate each 2D slice.\n",
    "    for i in range(n_slices):\n",
    "        if n_channels == 1:\n",
    "            # Translate the 2D slice and keep the channel dimension as the last dimension.\n",
    "            slice_2d = volume[i, :, :, 0]  # Extract the 2D slice.\n",
    "            translated_slice = tfa.image.translate(slice_2d, translations)\n",
    "            translated_slice = tf.expand_dims(translated_slice, axis=-1)  # Add the channel dimension back.\n",
    "        else:\n",
    "            # Translate the 2D slice for each channel.\n",
    "            slice_3d = volume[i, :, :, :]  # Extract the 3D slice (depth,height, width, channels).\n",
    "            translated_slice = [tfa.image.translate(slice_3d[:, :, c], translations) for c in range(n_channels)]\n",
    "            translated_slice = tf.stack(translated_slice, axis=-1)\n",
    "\n",
    "        # append the translated slice to the list.\n",
    "        translated_slices.append(translated_slice)\n",
    "\n",
    "    # stack the translated slices along the depth dimension.\n",
    "    translated_volume = tf.stack(translated_slices, axis=0)\n",
    "    \n",
    "    return translated_volume\n",
    "\n",
    "def blur(samples, labels, sigma=2.0):\n",
    "    def blur_slice(slice):\n",
    "        return tfa.image.gaussian_filter2d(slice, sigma=sigma)\n",
    "    \n",
    "    perform_blurring = tf.random.uniform([]) > 0.2 # type: ignore\n",
    "    blurred_samples = tf.cond(perform_blurring,\n",
    "                              lambda: tf.map_fn(blur_slice, samples, dtype=samples.dtype),\n",
    "                              lambda: samples)\n",
    "    return blurred_samples, labels\n",
    "    #blurred_samples = tf.map_fn(lambda slice: tfa.image.gaussian_filter2d(slice, sigma=sigma), samples, dtype=samples.dtype)\n",
    "    #return blurred_samples, labels\n",
    "\n",
    "def noising(samples, labels, mean=0.0, stddev=0.01):\n",
    "    perform_noising = tf.random.uniform([]) > 0.1 # type: ignore\n",
    "    noise = tf.random.normal(shape=tf.shape(samples), mean=mean, stddev=stddev)\n",
    "    noised_samples = tf.cond(perform_noising,\n",
    "                            lambda: samples + noise,\n",
    "                            lambda: samples)\n",
    "    return noised_samples, labels\n",
    "\n",
    "\n",
    "def process_augmentation(samples,labels):\n",
    "    samples,labels = random_rotate_3d(samples,labels,xshape[params['subset']][-1],yshape[params['subset']][-1])\n",
    "    # samples, labels = random_horizontal_flip(samples, labels,threshold=0.5)\n",
    "    samples, labels = random_translate_3d(samples, labels,xshape[params['subset']][0],xshape[params['subset']][-1],yshape[params['subset']][-1])\n",
    "    samples, labels = blur(samples, labels)\n",
    "    samples, labels = noising(samples, labels)\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Not Validated** - Zoom 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_3d(samples, labels, xshape, yshape, zoom_range=(0.8, 1.6)):\n",
    "    zoom_factor = tf.random.uniform([], minval=zoom_range[0], maxval=zoom_range[1])\n",
    "\n",
    "    # Define the zoom function for a single 2D slice\n",
    "    def zoom_slice(slice_2d, zoom_factor, output_size):\n",
    "        # Add a channel dimension to slice_2d if it doesn't have it\n",
    "        if len(slice_2d.shape) == 2:\n",
    "            slice_2d = tf.expand_dims(slice_2d, axis=-1)\n",
    "        \n",
    "        new_size = tf.cast(tf.cast(tf.shape(slice_2d)[:2], tf.float32) * zoom_factor, tf.int32)\n",
    "        resized_slice = tf.image.resize(slice_2d, new_size)\n",
    "        # Resize back to the output size and remove the added channel dimension if it was not originally present\n",
    "        resized_slice = tf.image.resize(resized_slice, output_size)\n",
    "        if resized_slice.shape[-1] == 1:\n",
    "            resized_slice = tf.squeeze(resized_slice, axis=-1)\n",
    "        return resized_slice\n",
    "\n",
    "    # Apply the zoom to each slice for samples\n",
    "    zoomed_samples = tf.map_fn(\n",
    "        lambda slc: zoom_slice(slc, zoom_factor, xshape[:2]), \n",
    "        samples, \n",
    "        dtype=samples.dtype\n",
    "    )\n",
    "\n",
    "    # Apply the zoom to each slice for labels, handling each channel separately\n",
    "    if labels is not None:\n",
    "        def zoom_label_slices(label_3d):\n",
    "            return tf.map_fn(\n",
    "                lambda slc: zoom_slice(slc, zoom_factor, yshape[:2]), \n",
    "                label_3d, \n",
    "                dtype=labels.dtype\n",
    "            )\n",
    "        zoomed_labels = tf.map_fn(\n",
    "            zoom_label_slices, \n",
    "            labels, \n",
    "            dtype=labels.dtype\n",
    "        )\n",
    "\n",
    "    # Set the shapes to match the target shapes\n",
    "    zoomed_samples.set_shape(xshape)\n",
    "    if labels is not None:\n",
    "        zoomed_labels.set_shape(yshape)\n",
    "\n",
    "    return zoomed_samples, zoomed_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input and processing - TFRecords format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input, Load and Normalization\n",
    " - mean and standard deviation calculation for normalization.\n",
    " - type 0 normalization with min and max\n",
    " - type 1 or else for normalization with mean and stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(serialized_sequence):\n",
    "    feature_description = {\n",
    "        'volume': tf.io.FixedLenFeature([], tf.string),\n",
    "        'mask': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    sequence = tf.io.parse_single_example(serialized_sequence,feature_description)\n",
    "    volume = tf.io.parse_tensor(sequence['volume'], out_type=tf.float32)\n",
    "    mask = tf.io.parse_tensor(sequence['mask'], out_type=tf.float32)\n",
    "    return volume,mask\n",
    "\n",
    "\n",
    "def get_norm_params(tfrecords_paths, norm_type=0):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecords_paths)\n",
    "    dataset = dataset.map(parse_tfrecord,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    global_min = tf.constant(float('inf'), tf.float32)\n",
    "    global_max = tf.constant(float('-inf'), tf.float32)\n",
    "\n",
    "    for vol, _ in dataset:\n",
    "        batch_min = tf.reduce_min(vol)\n",
    "        batch_max = tf.reduce_max(vol)\n",
    "        \n",
    "        global_min = tf.reduce_min([global_min, batch_min])\n",
    "        global_max = tf.reduce_max([global_max, batch_max])\n",
    "    \n",
    "    # Convert TensorFlow tensors to numpy values before returning\n",
    "    return global_min.numpy(), global_max.numpy()\n",
    "\n",
    "\n",
    "def tf_min_max_normalize(volume, min_val, max_val):\n",
    "    return (volume - min_val) / (max_val - min_val)\n",
    "\n",
    "def tf_standard_normalize(volume, mean, std):\n",
    "    return (volume - mean) / std\n",
    "\n",
    "# load tfrecords function \n",
    "def load_tfr_dataset(tfrecords_paths, normalization_params, norm_type=0):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecords_paths)\n",
    "    dataset = dataset.map(parse_tfrecord,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if norm_type == 0:\n",
    "        _min, _max = normalization_params\n",
    "        dataset = dataset.map(lambda volume_file, mask_file: (tf_min_max_normalize(volume_file,_min,_max),mask_file))\n",
    "            \n",
    "    else:\n",
    "        mean, std = normalization_params            \n",
    "        dataset = dataset.map(\n",
    "            lambda volume_file, mask_file: (tf_standard_normalize(volume_file, mean, std), mask_file))\n",
    "    \n",
    "    volume_shape = xshape[params['subset']]\n",
    "    mask_shape = yshape[params['subset']]\n",
    "\n",
    "    dataset = dataset.map(lambda volume, mask: (tf.ensure_shape(volume, volume_shape),\n",
    "                                                tf.ensure_shape(mask, mask_shape)))\n",
    "    return dataset\n",
    "\n",
    "def parse_test_tfrecords(data_dir,test_subjects):\n",
    "    sequence_files = []\n",
    "     \n",
    "    for individual in os.listdir(data_dir):\n",
    "        if int(individual) in test_subjects:\n",
    "            individual_sequence = os.path.join(data_dir, individual)\n",
    "            for knee in os.listdir(individual_sequence):\n",
    "                    knee_sequence = os.path.join(individual_sequence, knee)\n",
    "                    for sequence in os.listdir(knee_sequence):\n",
    "                        sequence_path = os.path.join(knee_sequence, sequence)\n",
    "                        file_path = os.path.join(sequence_path, sequence + '.tfrecord')\n",
    "                        sequence_files.append(file_path)\n",
    "\n",
    "    return sequence_files\n",
    "\n",
    "def load_tfr_subject_test(subject_path,normalization_params,norm_type=0):\n",
    "    data = tf.data.TFRecordDataset(subject_path)\n",
    "    data = data.map(parse_tfrecord,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if norm_type == 0:\n",
    "        _min, _max = normalization_params\n",
    "        data = data.map(lambda volume_file, mask_file: (tf_min_max_normalize(volume_file,_min,_max),mask_file))\n",
    "            \n",
    "    else:\n",
    "        mean, std = normalization_params            \n",
    "        dataset = data.map(\n",
    "            lambda volume_file, mask_file: (tf_standard_normalize(volume_file, mean, std), mask_file))\n",
    "    \n",
    "    volume_shape = xshape[params['subset']]\n",
    "    mask_shape = yshape[params['subset']]\n",
    "    data = data.map(lambda vol, mask: (tf.ensure_shape(vol,volume_shape),\n",
    "                                       tf.ensure_shape(mask,mask_shape)))\n",
    "    # input dimension for predict call is 5D\n",
    "    data = data.batch(1)\n",
    "    return data\n",
    "\n",
    "# List of tuples, where each tuple contains the path to a volume file and its corresponding mask file.\n",
    "def create_subject_tfrpaths(subset_dir,test_subjects):\n",
    "    sequence_files = []\n",
    "\n",
    "    for individual in os.listdir(subset_dir):\n",
    "        if int(individual) not in test_subjects:\n",
    "            individual_sequences = os.path.join(subset_dir, individual) \n",
    "            for knee in os.listdir(individual_sequences):\n",
    "                knee_sequences = os.path.join(individual_sequences, knee)\n",
    "                for sequence in os.listdir(knee_sequences):\n",
    "                    sequence_file = os.path.join(knee_sequences, sequence,sequence + '.tfrecord')\n",
    "                    sequence_files.append(sequence_file)\n",
    "                         \n",
    "    return sequence_files\n",
    "\n",
    "def subset_cross_validation_tfr(subset_dir, test_subjects,fold_idx, n_folds):\n",
    "    # get all subject paths\n",
    "    tfrecords_paths = create_subject_tfrpaths(subset_dir,test_subjects)\n",
    "    # convert to numpy array for easy manipulation\n",
    "    \n",
    "    # perform cross-validation\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    folds = list(kf.split(tfrecords_paths))\n",
    "    \n",
    "    # get the current fold data\n",
    "    train_indices, val_indices = folds[fold_idx]\n",
    "    train_paths = [tfrecords_paths[i] for i in train_indices]\n",
    "    val_paths = [tfrecords_paths[i] for i in val_indices]\n",
    "\n",
    "    return train_paths, val_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tfr_fn(subject_paths,normalization_params_train,norm_type,batch_size,seed,params):\n",
    "        \"\"\" Create dataset for training \"\"\"\n",
    "        dataset = load_tfr_dataset(subject_paths,normalization_params_train,norm_type)\n",
    "\n",
    "        if params['augment']:\n",
    "            dataset = dataset.map(\n",
    "                map_func=lambda x, y: process_augmentation(x, y),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "            )\n",
    "        dataset = dataset.shuffle(100, seed)\n",
    "        dataset = dataset.batch(batch_size,\n",
    "                                drop_remainder=True)\n",
    "        dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "def val_tfr_fn(val_paths,normalization_params,batch_size):\n",
    "    \"\"\" Create dataset for Validation \"\"\"\n",
    "    dataset = load_tfr_dataset(val_paths, normalization_params)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=False) # not\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def test_tfr_fn(test_paths,normalization_params):\n",
    "    \"\"\" Create dataset for Test\"\"\"\n",
    "    dataset = load_tfr_dataset(test_paths, normalization_params)\n",
    "    dataset = dataset.batch(1)\n",
    "                            #drop_remainder=self.params.benchmark)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    #print_dataset_shapes(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def validate_dataset(filenames, reader_opts=None):\n",
    "    \"\"\"\n",
    "    Attempt to iterate over every record in the supplied iterable of TFRecord filenames\n",
    "    :param filenames: iterable of filenames to read\n",
    "    :param reader_opts: (optional) tf.python_io.TFRecordOptions to use when constructing the record iterator\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    corrupts = []\n",
    "    corrupt = 0\n",
    "    for fname in filenames:\n",
    "        #print('validating ', fname)\n",
    "        record_iterator = tf.compat.v1.io.tf_record_iterator(path=fname, options=reader_opts)\n",
    "        try:\n",
    "            for _ in record_iterator:\n",
    "                i += 1\n",
    "        except Exception as e:\n",
    "            print('error in {} at record {}'.format(fname, i))\n",
    "            corrupt = 1\n",
    "            corrupts.append(fname)\n",
    "            print(e)\n",
    "    \n",
    "    return corrupt\n",
    "\n",
    "def dataset_tfr_split():\n",
    "    data_dir = os.path.join(tfrecords_dir,params['subset'])\n",
    "\n",
    "    test_paths = parse_test_tfrecords(data_dir,test_subjects[params['subset']])\n",
    "    # perform cross-validation on the paths that are valid for training,\n",
    "    # subset_cross_validation must make sure that trains_paths and val_paths return without\n",
    "    # any of the subject indicated on test_subjects list \n",
    "    train_paths, val_paths  = subset_cross_validation_tfr(data_dir, test_subjects[params['subset']], fold_idx, n_folds) #separate norm_params training and validation\n",
    "\n",
    "    if params['norm_params_minmax']: \n",
    "        normalization_params_train = params['norm_params_minmax']\n",
    "    else:\n",
    "        normalization_params_train = get_norm_params(train_paths,0)\n",
    "    print(\"Number of training tuple paths:\", len(train_paths))\n",
    "    print(\"Number of validation tuple paths:\", len(val_paths))\n",
    "    print(\"Number of test tuple paths:\", len(test_paths))\n",
    "    print(\"Normalization parameters training:\", normalization_params_train)\n",
    "    print(\"Fold id:\",fold_idx)\n",
    "    \n",
    "    # defined for number of steps on the model fit\n",
    "    params['total_train_samples'] = len(train_paths)\n",
    "    params['total_val_samples'] =  len(val_paths)\n",
    "    train_ds = None\n",
    "    val_ds = None\n",
    "    # create the train_ds input and tensorflow.python.data.ops.map_op._MapDataset Dataset\n",
    "    if validate_dataset(train_paths) == 0:\n",
    "        train_ds = train_tfr_fn(train_paths,normalization_params_train,0,batch_size,seed,params)\n",
    "        val_ds = val_tfr_fn(val_paths,normalization_params_train,batch_size)\n",
    "    \n",
    "        return train_paths,val_paths,train_ds,val_ds, test_paths ,normalization_params_train\n",
    "    else:\n",
    "        print('Corrupted files')\n",
    "        return train_paths,val_paths,train_ds,val_ds, test_paths ,normalization_params_train\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the tfrecords dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_inspect_tfrecord(file_path):\n",
    "    feature_description = {\n",
    "        'volume': tf.io.FixedLenFeature([], tf.string),\n",
    "        'mask': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    for i, serialized_example in enumerate(raw_dataset):\n",
    "        try:\n",
    "            parsed_example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "            volume = tf.io.parse_tensor(parsed_example['volume'], out_type=tf.float32)\n",
    "            mask = tf.io.parse_tensor(parsed_example['mask'], out_type=tf.float32)\n",
    "            inspect_data(volume, f'Volume {i}')\n",
    "            inspect_data(mask, f'Mask {i}')\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing record {i}: {e}\")\n",
    "    \n",
    "def inspect_data(data, label):\n",
    "    print(f\"Inspecting {label}:\")\n",
    "    print(f\"Shape: {data.shape}, Dtype: {data.dtype}\")\n",
    "    print(f\"Max: {np.max(data)}, Min: {np.min(data)}\")\n",
    "    print(f\"NaNs: {np.isnan(data).sum()}, Infs: {np.isinf(data).sum()}\")\n",
    "\n",
    "def validate_tfrecord(file_path):\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    record_count = 0\n",
    "    try:\n",
    "        for raw_record in raw_dataset:\n",
    "            record_count += 1\n",
    "    except tf.errors.DataLossError as e:\n",
    "        print(f\"Error reading record {record_count}: {e}\")\n",
    "        return False\n",
    "    print(f\"All {record_count} records read successfully.\")\n",
    "    return True\n",
    "\n",
    "def is_tfrecord_corrupted(tfrecord_file):\n",
    "    try:\n",
    "        for record in tf.data.TFRecordDataset(tfrecord_file):\n",
    "            # Attempt to parse the record\n",
    "            _ = tf.train.Example.FromString(record.numpy())\n",
    "    except tf.errors.DataLossError as e:\n",
    "        print(f\"DataLossError encountered: {e}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Volume 0:\n",
      "Shape: (32, 256, 256, 1), Dtype: <dtype: 'float32'>\n",
      "Max: 508.46875, Min: 0.0\n",
      "NaNs: 0, Infs: 0\n",
      "Inspecting Mask 0:\n",
      "Shape: (32, 256, 256, 8), Dtype: <dtype: 'float32'>\n",
      "Max: 1.0, Min: -0.7778438925743103\n",
      "NaNs: 0, Infs: 0\n"
     ]
    }
   ],
   "source": [
    "parse_and_inspect_tfrecord(corrupt)\n",
    "validate_dataset(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 276 records read successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_tfrecord(train_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Layers\n",
    "\n",
    "Methods based on basic 3D U-Net architecture [https://catalog.ngc.nvidia.com/orgs/nvidia/resources/unet3d_medical_for_tensorflow](https://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:lightblue\"> Lower level methods </span>\n",
    "\n",
    "Convolution, normalization and activation methods:\n",
    " - more control of the architecture\n",
    " - use of regularization (?): Kernel Initialiser: how the weights of the kernels are initially set before training begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:lightblue\"> Higher Level methods </span>\n",
    "\n",
    "Not using MaxPooling! The key difference between using strided convolutions and MaxPooling for downsampling is that strided convolutions involve learnable parameters and can learn to downsample in a more data-driven manner, whereas MaxPooling is a fixed operation that simply takes the maximum value over the pooling window.\n",
    "\n",
    "By not applying normalization or activation immediately after upsampling, you allow the model to first merge these upsampled features with the skip connection features. This can be important because the skip connections carry high-resolution spatial information from the encoder, which can be more effectively integrated with the upsampled features before any further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalization(inputs, name, mode):\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    if name == 'instancenorm':\n",
    "        return tf.keras.layers.LayerNormalization(\n",
    "            axis=[1, 2, 3],  # Normalizing across the spatial dimensions\n",
    "            center=True,\n",
    "            scale=True,\n",
    "            epsilon=1e-6)(inputs)\n",
    "\n",
    "    if name == 'groupnorm':\n",
    "        return tfa.layers.GroupNormalization(\n",
    "            groups=4,\n",
    "            axis=-1,  # Channel axis\n",
    "            epsilon=1e-5)(inputs)\n",
    "\n",
    "    if name == 'batchnorm':\n",
    "        return tf.keras.layers.BatchNormalization(axis=-1, #channels index is the last one\n",
    "                                                  trainable=True,\n",
    "                                                  virtual_batch_size=None)(inputs, training=training)\n",
    "    if name == 'none':\n",
    "        return inputs\n",
    "\n",
    "    raise ValueError('Invalid normalization layer')\n",
    "\n",
    "\n",
    "def _activation(out, activation):\n",
    "    if activation == 'relu':\n",
    "        return tf.keras.layers.ReLU()(out)\n",
    "    if activation == 'leaky_relu':\n",
    "        return tf.keras.layers.LeakyReLU(alpha=0.01)(out)\n",
    "    if activation == 'sigmoid':\n",
    "        return tf.keras.layers.Activation('sigmoid')(out)\n",
    "    if activation == 'softmax':\n",
    "        return tf.keras.layers.Activation('softmax')(out)\n",
    "    if activation == 'none':\n",
    "        return out\n",
    "\n",
    "    raise ValueError(\"Unknown activation {}\".format(activation))\n",
    "\n",
    "def convolution(inputs,  \n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                normalization='batchnorm',\n",
    "                activation='relu',\n",
    "                transpose=False):\n",
    "\n",
    "    if transpose:\n",
    "        conv = tf.keras.layers.Conv3DTranspose\n",
    "    else:\n",
    "        conv = tf.keras.layers.Conv3D\n",
    "    regularizer = None #tf.keras.regularizers.l2(1e-5) # trying L2 Regularization\n",
    "\n",
    "    use_bias = normalization == \"none\"\n",
    "    inputs = conv(filters=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=stride,\n",
    "                  activation=None,\n",
    "                  padding='same',\n",
    "                  data_format='channels_last',\n",
    "                  kernel_initializer=tf.compat.v1.initializers.he_uniform(), # use HE with ReLU\n",
    "                  kernel_regularizer=regularizer,\n",
    "                  bias_initializer='zeros',\n",
    "                  bias_regularizer=regularizer,\n",
    "                  use_bias=use_bias)(inputs)\n",
    "    \n",
    "    # batch normalization before each activation\n",
    "    inputs = _normalization(inputs, normalization, mode)\n",
    "    #print(' Convolution INPUTS SHAPE',inputs.shape)\n",
    "    return _activation(inputs, activation)\n",
    "\n",
    "\n",
    "''' Padding and Cropping (Not currently used)'''\n",
    "# if feature maps align perfectly, we dont need this method\n",
    "def dynamic_crop_and_concat(up_conv,skip_feature):\n",
    "    print('Skip feature before crop :',up_conv.shape)\n",
    "\n",
    "    crop_size = [(up_conv.shape[i+1] - skip_feature.shape[i+1]) // 2 for i in range(3)]\n",
    "    additional_crop = [(up_conv.shape[i+1] - skip_feature.shape[i+1]) % 2 for i in range(3)]\n",
    "    crop_size = [(crop_size[i], crop_size[i] + additional_crop[i]) for i in range(3)]\n",
    "    \n",
    "    # Concatenate along the feature axis\n",
    "    cropped_up_conv = tf.keras.layers.Cropping3D(cropping=crop_size)(up_conv)\n",
    "    print('INPUT SHAPE cropped to CONCATENATE:',cropped_up_conv.shape,'Skip feature to CONCATENATE:',skip_feature.shape)\n",
    "\n",
    "    return tf.keras.layers.Concatenate(axis=-1)([cropped_up_conv, skip_feature])\n",
    "\n",
    "'''Encoding'''\n",
    "# Input block\n",
    "def input_block(inputs, out_channels, normalization, mode):\n",
    "    #stride = 1 kernel_size= 3\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    print('Input shape input block with filter',out_channels,':',inputs.shape)\n",
    "    return inputs\n",
    "\n",
    "# Downsample with Residual blocks\n",
    "def downsample_Residual_block(inputs, out_channels, normalization, mode):\n",
    "    # Convolutional path\n",
    "    #the next convolution imitates the maxpooling behaviour\n",
    "    # offering additional benefits in feature learning and representation\n",
    "    conv_path = convolution(inputs, out_channels=out_channels, normalization=normalization, \n",
    "                            mode=mode, stride=2)\n",
    "    conv_path = convolution(conv_path, out_channels=out_channels, normalization=normalization, \n",
    "                            mode=mode)\n",
    "\n",
    "    # Residual path modification adds a residual connection that includes a 1x1x1 \n",
    "    # convolution with a stride of 2 to downsample the input before adding  it \n",
    "    # to the output of the convolutional layers within the block\n",
    "    # previous kernel = 3\n",
    "    residual_path = convolution(inputs, out_channels=out_channels, kernel_size=1, stride=2,\n",
    "                                normalization=normalization, mode=mode, activation='none')\n",
    "    \n",
    "    # Add the residual connection\n",
    "    out = tf.keras.layers.Add()([conv_path, residual_path])\n",
    "    out = _activation(out, 'relu')\n",
    "\n",
    "    return out\n",
    "\n",
    "# classic U-Net\n",
    "def downsample_block(inputs, out_channels, normalization, mode):\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode, stride=2)\n",
    "    print('Input shape downsample block with filter',out_channels,':',inputs.shape)\n",
    "    return convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "\n",
    "\n",
    "'''Decoding'''\n",
    "\n",
    "def attention_gate(inputs,attention,inter_channel):\n",
    "    theta_x = tf.keras.layers.Conv3D(inter_channel,kernel_size=2,strides=2,padding='same')(inputs)\n",
    "    phi_g = tf.keras.layers.Conv3D(inter_channel, kernel_size=1, padding='same')(attention)\n",
    "\n",
    "    concat_xg = tf.keras.layers.Add()([theta_x, phi_g])\n",
    "    act_xg = tf.keras.layers.Activation('relu')(concat_xg)\n",
    "    psi = tf.keras.layers.Conv3D(1, kernel_size=1, padding='same')(act_xg)\n",
    "    sigmoid_xg = tf.keras.layers.Activation('sigmoid')(psi)\n",
    "    \n",
    "    upsample_psi = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(sigmoid_xg)\n",
    "    scale_attention = tf.keras.layers.Multiply()([upsample_psi, inputs])\n",
    "\n",
    "    return scale_attention\n",
    "\n",
    "# Upsample with attention gates\n",
    "def upsample_attention_block(inputs, skip_connection, out_channels, normalization, mode):\n",
    "    # attention gate where we give special importance to features that are the most revelant\n",
    "    attention = attention_gate(skip_connection,inputs,out_channels//2)\n",
    "    inputs = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                         normalization='none', activation='none', transpose=True)\n",
    "\n",
    "    # Use dynamic crop and concat\n",
    "    #inputs = dynamic_crop_and_concat(inputs, skip_connection)\n",
    "    inputs = tf.keras.layers.Concatenate(axis=-1)([inputs, attention])\n",
    "    \n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    print('Input shape AFTER concatenate:',inputs.shape)\n",
    "    return inputs\n",
    "\n",
    "# Upsample with residual block\n",
    "def upsample_Residual_block(inputs, skip_connection, out_channels, normalization, mode, residual_kernel=1):\n",
    "    main_path = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                            normalization=normalization, activation='none', transpose=True)\n",
    "    main_path = tf.keras.layers.Concatenate(axis=-1)([main_path, skip_connection])\n",
    "    main_path = convolution(main_path, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    main_path = convolution(main_path, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "\n",
    "    # Residual path: Transposed convolution (or another upsampling technique) to match the dimensions\n",
    "    residual_path = convolution(inputs, out_channels=out_channels, kernel_size=residual_kernel, stride=2,\n",
    "                                normalization=normalization, mode=mode, activation='none', transpose=True)\n",
    "    \n",
    "\n",
    " \n",
    "    #residual_path = tf.keras.layers.UpSampling3D(size=(2, 2, 2))(inputs)\n",
    "    #residual_path = convolution(residual_path, out_channels=out_channels, kernel_size=1, normalization=normalization, mode=mode)\n",
    "\n",
    "    # Add the residual connection\n",
    "    out = tf.keras.layers.Add()([main_path, residual_path])\n",
    "    out = _activation(out, 'relu')\n",
    "    return out\n",
    "\n",
    "# Upsample Layer with Residual block and attention gates\n",
    "def upsample_ResidualAttention_block(inputs, skip_connection,out_channels,normalization,mode):\n",
    "\n",
    "    attention = attention_gate(skip_connection,inputs,out_channels//2)\n",
    "\n",
    "    upsampled = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                         normalization='none', activation='none', transpose=True)\n",
    "    \n",
    "    concat = tf.keras.layers.Concatenate(axis=-1)([upsampled, attention])\n",
    "\n",
    "    # Convolutional path\n",
    "    conv_path = convolution(concat, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    conv_path = convolution(conv_path, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "\n",
    "    residual_path = convolution(inputs, out_channels=out_channels, kernel_size=1, stride=2,\n",
    "                                normalization=normalization, mode=mode, activation='none', transpose=True)\n",
    "    \n",
    "    out = tf.keras.layers.Add()([conv_path, residual_path])\n",
    "    out = _activation(out, 'relu')\n",
    "    return out\n",
    "\n",
    "# normal 3D U-Net upsample block\n",
    "def upsample_block(inputs, skip_connection, out_channels, normalization, mode):\n",
    "    inputs = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                         normalization='none', activation='none', transpose=True)\n",
    "\n",
    "    # Use dynamic crop and concat\n",
    "    #inputs = dynamic_crop_and_concat(inputs, skip_connection)\n",
    "    inputs = tf.keras.layers.Concatenate(axis=-1)([inputs, skip_connection])\n",
    "    \n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    return inputs\n",
    "\n",
    "def output_layer(inputs, out_channels, activation):\n",
    "    return convolution(inputs, out_channels=out_channels, kernel_size=3, normalization='none', activation=activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures\n",
    "- param n_classes: Number of output channels\n",
    "- param mode: Estimator's execution mode\n",
    "- param normalization: Name of the normalization layer    \n",
    "- param features: Input features\n",
    "- return: Output of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####      Simple UNet3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet3d_mod(n_classes,mode,features,normalization='none'):\n",
    "\n",
    "        skip_1 = input_block(inputs=features,\n",
    "                               out_channels=16,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        skip_2 = downsample_block(inputs=skip_1,\n",
    "                                   out_channels=32,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_3 = downsample_block(inputs=skip_2,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        skip_4 = downsample_block(inputs=skip_3,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # bridge\n",
    "        out = downsample_block(inputs=skip_4,\n",
    "                               out_channels=512,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "        out = tf.keras.layers.Dropout(params['dropout'])(out)\n",
    "\n",
    "        out = upsample_block(out, skip_4,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_3,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_2,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_block(out, skip_1,\n",
    "                             out_channels=16,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The features (input volumes) are represented as 5D tensor with the shape \n",
    "**[batch_size, depth, height, width, channels]**. Since medical volumes are often single-channel (grayscale), this last dimension might be 1.\n",
    "\n",
    "- The labels (masks), being a multi-class segmentation where each channel represents a different class, the channels dimension typically is the last dimension. So the masks are shaped as **[batch_size, depth, height, width, channels]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    Residual 3D U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unet3d(n_classes, mode, features, normalization='batchnorm'):\n",
    "    skip_connections = []\n",
    "    out_channels_sequence = [16,32,64,128]\n",
    "\n",
    "    # input block\n",
    "    features = input_block(inputs=features,\n",
    "                           out_channels=out_channels_sequence[0],\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    skip_connections.append(features)\n",
    "    \n",
    "    # downsampling blocks\n",
    "    for out_channels in out_channels_sequence[1:]:  # first one used on the input_block\n",
    "        features = downsample_Residual_block(inputs=features,\n",
    "                                             out_channels=out_channels,\n",
    "                                             normalization=normalization,\n",
    "                                             mode=mode)\n",
    "        skip_connections.append(features)\n",
    "    \n",
    "    # Bottom layer add residual to this one \n",
    "    out = downsample_Residual_block(inputs=features,\n",
    "                           out_channels=512,\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    \n",
    "    # upsampling blocks\n",
    "    for out_channels, skip_connection in zip(reversed(out_channels_sequence), reversed(skip_connections)):\n",
    "        out = upsample_Residual_block(inputs=out,\n",
    "                             skip_connection=skip_connection,\n",
    "                             out_channels=out_channels,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)       \n",
    "    # output layer\n",
    "    out = output_layer(out, out_channels=n_classes, activation='softmax')\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    3D U-Net with Attention Gates on Decoder path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the weights also get trained making the model pay more attention to relevant regions. It adds weights to voxels based on the relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttUnet3dFirst(n_classes, mode, features, normalization='batchnorm'):\n",
    "    skip_connections = []\n",
    "    out_channels_sequence = [16,32,64,128]\n",
    "\n",
    "    # input block\n",
    "    features = input_block(inputs=features,\n",
    "                           out_channels=out_channels_sequence[0],\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    skip_connections.append(features)\n",
    "    \n",
    "    # downsampling blocks\n",
    "    for out_channels in out_channels_sequence[1:]:  # first one used on the input_block\n",
    "        features = downsample_block(inputs=features,\n",
    "                                             out_channels=out_channels,\n",
    "                                             normalization=normalization,\n",
    "                                             mode=mode)\n",
    "        #features = tf.keras.layers.Dropout(params['dropout'])(features, training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "        skip_connections.append(features)\n",
    "    \n",
    "    # Bottom layer add residual to this one \n",
    "    bottleneck = downsample_block(inputs=features,\n",
    "                           out_channels= 512,\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "    \n",
    "    # upsampling blocks with attention mechanioms: attention gates\n",
    "    for out_channels, skip_connection in zip(reversed(out_channels_sequence), reversed(skip_connections)):\n",
    "        bottleneck = upsample_attention_block(inputs=bottleneck, skip_connection=skip_connection, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    \n",
    "    # Output layer\n",
    "    output = output_layer(bottleneck, out_channels=n_classes, activation='softmax')\n",
    "    return output\n",
    "\n",
    "def AttUnet3d(n_classes, mode, features, normalization):\n",
    "        skip_1 = input_block(inputs=features,\n",
    "                               out_channels=16,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "        #skip_64\n",
    "        skip_2 = downsample_block(inputs=skip_1,\n",
    "                                   out_channels=32,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_32\n",
    "        skip_3 = downsample_block(inputs=skip_2,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_16\n",
    "        skip_4 = downsample_block(inputs=skip_3,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        # bridge\n",
    "        out = downsample_block(inputs=skip_4,\n",
    "                               out_channels=512,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "\n",
    "\n",
    "        out = upsample_attention_block(out, skip_4,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_attention_block(out, skip_3,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_attention_block(out, skip_2,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_attention_block(out, skip_1,\n",
    "                             out_channels=16,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    Residual Attention U-Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resAtt_unet3d(n_classes, mode, features, normalization='batchnorm'):\n",
    "        #skip_128\n",
    "        skip_1 = input_block(inputs=features,\n",
    "                               out_channels=16,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "        #skip_64\n",
    "        skip_2 = downsample_Residual_block(inputs=skip_1,\n",
    "                                   out_channels=32,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_32\n",
    "        skip_3 = downsample_Residual_block(inputs=skip_2,\n",
    "                                   out_channels=64,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "        # skip_16\n",
    "        skip_4 = downsample_Residual_block(inputs=skip_3,\n",
    "                                   out_channels=128,\n",
    "                                   normalization=normalization,\n",
    "                                   mode=mode)\n",
    "\n",
    "        # bridge\n",
    "        out = downsample_Residual_block(inputs=skip_4,\n",
    "                               out_channels=512,\n",
    "                               normalization=normalization,\n",
    "                               mode=mode)\n",
    "        out = tf.keras.layers.Dropout(params['dropout'])(out)\n",
    "\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_4,\n",
    "                             out_channels=128,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_3,\n",
    "                             out_channels=64,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_2,\n",
    "                             out_channels=32,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        out = upsample_ResidualAttention_block(out, skip_1,\n",
    "                             out_channels=16,\n",
    "                             normalization=normalization,\n",
    "                             mode=mode)\n",
    "\n",
    "        return output_layer(out,\n",
    "                            out_channels=n_classes,\n",
    "                            activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Metrics for Landmark Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Categorical Loss entropy: perhaps good on 2D problems. \n",
    "- Dice Similarity Coefficient: Commonly used for segmentation tasks, it measures the spatial overlap between predicted and ground truth landmarks.\n",
    "- Mean Squared Error (MSE) between predicted and ground truth heatmaps can be used (Heatmap-based metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loss(y_true, y_pred):\n",
    "    \"\"\" Factory method for loss functions\n",
    "\n",
    "    :param params: Dict with additional parameters\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: Loss\n",
    "    \"\"\"\n",
    "    if params['loss'] == 'dice':\n",
    "        return _dice(y_true, y_pred)\n",
    "    if params['loss'] == 'ce':\n",
    "        return _ce(y_true, y_pred)\n",
    "    if params['loss'] == 'dice+ce':\n",
    "        return tf.add(_ce(y_true, y_pred), _dice(y_true, y_pred), name=\"total_loss_ref\")\n",
    "    if params['loss'] == 'mse':\n",
    "        return _mse(y_true, y_pred)\n",
    "\n",
    "    raise ValueError('Unknown loss: {}'.format(params['loss']))\n",
    "\n",
    "\n",
    "def _ce(y_true, y_pred):\n",
    "    \"\"\" Crossentropy\n",
    "\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    return tf.reduce_sum(\n",
    "        tf.reduce_mean(tf.keras.backend.categorical_crossentropy(tf.cast(y_true, tf.float32), y_pred), axis=[0, 1, 2, 3]),\n",
    "        name='crossentropy_loss_ref')\n",
    "\n",
    "def _mse(y_true, y_pred):\n",
    "    \"\"\" Mean Squared Error loss.\n",
    "    \n",
    "    :param y_true: Ground truth labels.\n",
    "    :param y_pred: Predicted labels.\n",
    "    :return: MSE loss.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "def _dice(y_true, y_pred):\n",
    "    \"\"\" Training dice\n",
    "\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    return tf.reduce_sum(dice_loss(predictions=y_pred, targets=y_true), name='dice_loss_ref')\n",
    "\n",
    "def eval_dice(y_true, y_pred):\n",
    "    \"\"\" Evaluation dice\n",
    "\n",
    "    :param y_true: Ground truth labels\n",
    "    :param y_pred: Predicted labels\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    return eval_dice_loss(predictions=y_pred, targets=y_true)\n",
    "\n",
    "\n",
    "def eval_dice_loss(predictions,\n",
    "              targets,\n",
    "              squared_pred=False,\n",
    "              smooth=1e-5,\n",
    "              top_smooth=0.0):\n",
    "    \"\"\" Dice\n",
    "\n",
    "    :param predictions: Predicted labels\n",
    "    :param targets: Ground truth labels\n",
    "    :param squared_pred: Square the predicate\n",
    "    :param smooth: Smooth term for denominator\n",
    "    :param top_smooth: Smooth term for numerator\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    n_len = len(predictions.shape)\n",
    "    #print('n_len:',n_len)\n",
    "    reduce_axis = list(range(1, n_len))\n",
    "    #print(reduce_axis)\n",
    "    intersection = tf.reduce_sum(targets * predictions, axis=reduce_axis)\n",
    "\n",
    "    if squared_pred:\n",
    "        targets = tf.square(targets)\n",
    "        predictions = tf.square(predictions)\n",
    "\n",
    "    y_true_o = tf.reduce_sum(targets, axis=reduce_axis)\n",
    "    y_pred_o = tf.reduce_sum(predictions, axis=reduce_axis)\n",
    "\n",
    "    denominator = y_true_o + y_pred_o \n",
    "\n",
    "    dice = (2.0 * intersection + top_smooth) / (denominator + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice, axis=0)\n",
    "\n",
    "def dice_loss(predictions,\n",
    "              targets,\n",
    "              squared_pred=False,\n",
    "              smooth=1e-5,\n",
    "              top_smooth=0.0):\n",
    "    \"\"\" Dice\n",
    "\n",
    "    :param predictions: Predicted labels\n",
    "    :param targets: Ground truth labels\n",
    "    :param squared_pred: Square the predicate\n",
    "    :param smooth: Smooth term for denominator\n",
    "    :param top_smooth: Smooth term for numerator\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    is_channels_first = False\n",
    "\n",
    "    n_len = len(predictions.get_shape())\n",
    "    reduce_axis = list(range(2, n_len)) if is_channels_first else list(range(1, n_len - 1))\n",
    "    intersection = tf.reduce_sum(targets * predictions, axis=reduce_axis)\n",
    "\n",
    "    if squared_pred:\n",
    "        targets = tf.square(targets)\n",
    "        predictions = tf.square(predictions)\n",
    "\n",
    "    y_true_o = tf.reduce_sum(targets, axis=reduce_axis)\n",
    "    y_pred_o = tf.reduce_sum(predictions, axis=reduce_axis)\n",
    "\n",
    "    denominator = y_true_o + y_pred_o\n",
    "\n",
    "    dice = (2.0 * intersection + top_smooth) / (denominator + smooth)\n",
    "\n",
    "    return 1 - tf.reduce_mean(dice, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avoiding overfitting\n",
    "- early stopping when validation accuracy no longer drops for a number of epochs\n",
    "- record session to be available on tensorboard. **cd into log directory and <: tensorboard --logdir (logs/path if not in lod directoy)**\n",
    "- learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminateOnNaN(Callback):\n",
    "    # terminates training when a NaN loss is encountered.\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print('Stopping training due to NaN loss')\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "class LearningCurveSaver(Callback):\n",
    "    def __init__(self, save_path):\n",
    "        super(LearningCurveSaver, self).__init__()\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        history = self.model.history.history\n",
    "        learning_curve_data = {\n",
    "            'loss': history['loss'],\n",
    "            'val_loss': history['val_loss']\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(self.save_path, 'learning_curve.json'), 'w') as f:\n",
    "            json.dump(learning_curve_data, f, indent=4)\n",
    "\n",
    "def prepareCallbacks(path,log_and_model_path):\n",
    "\n",
    "    file_path = f'{log_and_model_path}/{path}/cp.ckpt'\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath= file_path, \n",
    "                                monitor = 'val_loss',\n",
    "                                verbose=1, \n",
    "                                save_weights_only=True,\n",
    "                                save_best_only=True)\n",
    "\n",
    "\n",
    "    earlyStopper = EarlyStopping(monitor='val_loss', min_delta = 0.0001,\n",
    "                                patience = 12, \n",
    "                                verbose = 1)\n",
    "\n",
    "    tbCallBack = TensorBoard(log_dir=f'{log_and_model_path}/{path}_log', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "    # reducing \n",
    "    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                  monitor='val_loss', factor=0.2, patience=7, min_lr=1e-6)\n",
    "    \n",
    "    # nan loss values monitor\n",
    "    terminateNan = TerminateOnNaN()\n",
    "\n",
    "    # store loss image\n",
    "    save_lr_path = f'{log_and_model_path}/{path}'\n",
    "    learnCurve = LearningCurveSaver(save_lr_path)\n",
    "\n",
    "\n",
    "    return file_path, [checkpointer, earlyStopper, tbCallBack, lr_scheduler,terminateNan,learnCurve] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Fit Approach - Sagittal Subset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data input\n",
    "\n",
    "For test data lets get first the paths that we have at our disposal, this way we can get one subject and correctly compare the ground truth with the correspondent subject.\n",
    "\n",
    "Try to use the same runned train_paths and val paths for the same model when testing different normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training tuple paths: 276\n",
      "Number of validation tuple paths: 69\n",
      "Number of test tuple paths: 84\n",
      "Normalization parameters training: (0.0, 3893.436)\n",
      "Fold id: 1\n",
      "WARNING:tensorflow:From C:\\Users\\Eduardo\\AppData\\Local\\Temp\\ipykernel_13464\\107171388.py:46: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "# tfrecords\n",
    "train_paths,val_paths, train_sagittal, val_sagittal,test_paths, norm_params = dataset_tfr_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (TensorSpec(shape=(2, 32, 256, 256, 1), dtype=tf.float32, name=None), TensorSpec(shape=(2, 32, 256, 256, 8), dtype=tf.float32, name=None))\n",
      "Val: (TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 32, 256, 256, 8), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print('Train:',train_sagittal.element_spec)\n",
    "print('Val:',val_sagittal.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'augment': True,\n",
       " 'mode': 'train',\n",
       " 'seed': 42,\n",
       " 'subset': 'DATASET_SAGITTAL',\n",
       " 'interpolation': 'Linear Interpolation',\n",
       " 'normalization': 'groupnorm',\n",
       " 'total_train_samples': 276,\n",
       " 'total_val_samples': 69,\n",
       " 'lr': 0.0001,\n",
       " 'loss': 'dice+ce',\n",
       " 'dropout': 0.2,\n",
       " 'batch_size': 2,\n",
       " 'norm_params_minmax': None,\n",
       " 'norm_params_meanstd': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['normalization'] = 'groupnorm'\n",
    "params['augment'] = True\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - Res_unet3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL\n",
      "Training session id: Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\n"
     ]
    }
   ],
   "source": [
    "logs_sagittal = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "# Define a unique path for this training session\n",
    "training_session_path = 'Sigma3/GroupNorm/residualUnet3d-BN{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_sagittal)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_sagittal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual_unet3d input: 8 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") True groupnorm\n",
      "Input shape input block with filter 16 : (None, 32, 256, 256, 16)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 32, 256, 256  432         ['input_1[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization (GroupNorm  (None, 32, 256, 256  32         ['conv3d[0][0]']                 \n",
      " alization)                     , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 32, 256, 256  0           ['group_normalization[0][0]']    \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 32, 256, 256  6912        ['re_lu[0][0]']                  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_1 (GroupNo  (None, 32, 256, 256  32         ['conv3d_1[0][0]']               \n",
      " rmalization)                   , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 32, 256, 256  0           ['group_normalization_1[0][0]']  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 16, 128, 128  13824       ['re_lu_1[0][0]']                \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_2 (GroupNo  (None, 16, 128, 128  64         ['conv3d_2[0][0]']               \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 16, 128, 128  0           ['group_normalization_2[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 16, 128, 128  27648       ['re_lu_2[0][0]']                \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_3 (GroupNo  (None, 16, 128, 128  64         ['conv3d_3[0][0]']               \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 16, 128, 128  512         ['re_lu_1[0][0]']                \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 16, 128, 128  0           ['group_normalization_3[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_4 (GroupNo  (None, 16, 128, 128  64         ['conv3d_4[0][0]']               \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 128, 128  0           ['re_lu_3[0][0]',                \n",
      "                                , 32)                             'group_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 16, 128, 128  0           ['add[0][0]']                    \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 8, 64, 64, 6  55296       ['re_lu_4[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_5 (GroupNo  (None, 8, 64, 64, 6  128        ['conv3d_5[0][0]']               \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 8, 64, 64, 6  0           ['group_normalization_5[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 8, 64, 64, 6  110592      ['re_lu_5[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_6 (GroupNo  (None, 8, 64, 64, 6  128        ['conv3d_6[0][0]']               \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 8, 64, 64, 6  2048        ['re_lu_4[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 8, 64, 64, 6  0           ['group_normalization_6[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_7 (GroupNo  (None, 8, 64, 64, 6  128        ['conv3d_7[0][0]']               \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 8, 64, 64, 6  0           ['re_lu_6[0][0]',                \n",
      "                                4)                                'group_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 8, 64, 64, 6  0           ['add_1[0][0]']                  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 4, 32, 32, 1  221184      ['re_lu_7[0][0]']                \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_8 (GroupNo  (None, 4, 32, 32, 1  256        ['conv3d_8[0][0]']               \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 4, 32, 32, 1  0           ['group_normalization_8[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 4, 32, 32, 1  442368      ['re_lu_8[0][0]']                \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_9 (GroupNo  (None, 4, 32, 32, 1  256        ['conv3d_9[0][0]']               \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 4, 32, 32, 1  8192        ['re_lu_7[0][0]']                \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 4, 32, 32, 1  0           ['group_normalization_9[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_10 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_10[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 4, 32, 32, 1  0           ['re_lu_9[0][0]',                \n",
      "                                28)                               'group_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 4, 32, 32, 1  0           ['add_2[0][0]']                  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 2, 16, 16, 5  1769472     ['re_lu_10[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_11 (GroupN  (None, 2, 16, 16, 5  1024       ['conv3d_11[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_11[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 2, 16, 16, 5  7077888     ['re_lu_11[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_12 (GroupN  (None, 2, 16, 16, 5  1024       ['conv3d_12[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 2, 16, 16, 5  65536       ['re_lu_10[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_12[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_13 (GroupN  (None, 2, 16, 16, 5  1024       ['conv3d_13[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 2, 16, 16, 5  0           ['re_lu_12[0][0]',               \n",
      "                                12)                               'group_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 2, 16, 16, 5  0           ['add_3[0][0]']                  \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 4, 32, 32, 1  1769472    ['re_lu_13[0][0]']               \n",
      " ose)                           28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_14 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_transpose[0][0]']       \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 32, 32, 2  0           ['group_normalization_14[0][0]', \n",
      "                                56)                               're_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 4, 32, 32, 1  884736      ['concatenate[0][0]']            \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_15 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_14[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_15[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_14[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_16 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_15[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 4, 32, 32, 1  65536      ['re_lu_13[0][0]']               \n",
      " spose)                         28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_16[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_17 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_transpose_1[0][0]']     \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4, 32, 32, 1  0           ['re_lu_15[0][0]',               \n",
      "                                28)                               'group_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 4, 32, 32, 1  0           ['add_4[0][0]']                  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 8, 64, 64, 6  221184     ['re_lu_16[0][0]']               \n",
      " spose)                         4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_18 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_transpose_2[0][0]']     \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 64, 64, 1  0           ['group_normalization_18[0][0]', \n",
      "                                28)                               're_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)             (None, 8, 64, 64, 6  221184      ['concatenate_1[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_19 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_16[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_19[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_17[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_20 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_17[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_3 (Conv3DTran  (None, 8, 64, 64, 6  8192       ['re_lu_16[0][0]']               \n",
      " spose)                         4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_20[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_21 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_transpose_3[0][0]']     \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 64, 64, 6  0           ['re_lu_18[0][0]',               \n",
      "                                4)                                'group_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 8, 64, 64, 6  0           ['add_5[0][0]']                  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_4 (Conv3DTran  (None, 16, 128, 128  55296      ['re_lu_19[0][0]']               \n",
      " spose)                         , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_22 (GroupN  (None, 16, 128, 128  64         ['conv3d_transpose_4[0][0]']     \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 16, 128, 128  0           ['group_normalization_22[0][0]', \n",
      "                                , 64)                             're_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d_18 (Conv3D)             (None, 16, 128, 128  55296       ['concatenate_2[0][0]']          \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_23 (GroupN  (None, 16, 128, 128  64         ['conv3d_18[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_23[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_20[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_24 (GroupN  (None, 16, 128, 128  64         ['conv3d_19[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_5 (Conv3DTran  (None, 16, 128, 128  2048       ['re_lu_19[0][0]']               \n",
      " spose)                         , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_24[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_25 (GroupN  (None, 16, 128, 128  64         ['conv3d_transpose_5[0][0]']     \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 16, 128, 128  0           ['re_lu_21[0][0]',               \n",
      "                                , 32)                             'group_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 16, 128, 128  0           ['add_6[0][0]']                  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_6 (Conv3DTran  (None, 32, 256, 256  13824      ['re_lu_22[0][0]']               \n",
      " spose)                         , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_26 (GroupN  (None, 32, 256, 256  32         ['conv3d_transpose_6[0][0]']     \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 256, 256  0           ['group_normalization_26[0][0]', \n",
      "                                , 32)                             're_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)             (None, 32, 256, 256  13824       ['concatenate_3[0][0]']          \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_27 (GroupN  (None, 32, 256, 256  32         ['conv3d_20[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_27[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_23[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_28 (GroupN  (None, 32, 256, 256  32         ['conv3d_21[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_7 (Conv3DTran  (None, 32, 256, 256  512        ['re_lu_22[0][0]']               \n",
      " spose)                         , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_28[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_29 (GroupN  (None, 32, 256, 256  32         ['conv3d_transpose_7[0][0]']     \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 32, 256, 256  0           ['re_lu_24[0][0]',               \n",
      "                                , 16)                             'group_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 32, 256, 256  0           ['add_7[0][0]']                  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_22 (Conv3D)             (None, 32, 256, 256  3464        ['re_lu_25[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 256, 256  0           ['conv3d_22[0][0]']              \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,710,392\n",
      "Trainable params: 13,710,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initial input features\n",
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('residual_unet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'],params['normalization'])\n",
    "output = residual_unet3d(yshape[params['subset']][-1],params['mode'],features,params['normalization'])\n",
    "res_unet_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "res_unet_model.compile(optimizer=Adam(learning_rate=params['lr']), # type: ignore\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])\n",
    "res_unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SESSION ID: Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44 2 groupnorm\n",
      "Epoch 1/60\n",
      "    138/Unknown - 138s 823ms/step - loss: 7.3657 - eval_dice: 0.1454\n",
      "Epoch 1: val_loss improved from inf to 7.04683, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 152s 926ms/step - loss: 7.3657 - eval_dice: 0.1454 - val_loss: 7.0468 - val_eval_dice: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0334 - eval_dice: 0.0154\n",
      "Epoch 2: val_loss improved from 7.04683 to 7.00692, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 138s 890ms/step - loss: 7.0334 - eval_dice: 0.0154 - val_loss: 7.0069 - val_eval_dice: 0.0155 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.8908 - eval_dice: 0.0107\n",
      "Epoch 3: val_loss improved from 7.00692 to 6.79230, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 129s 824ms/step - loss: 6.8908 - eval_dice: 0.0107 - val_loss: 6.7923 - val_eval_dice: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.5621 - eval_dice: 0.0060\n",
      "Epoch 4: val_loss improved from 6.79230 to 6.50738, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 129s 825ms/step - loss: 6.5621 - eval_dice: 0.0060 - val_loss: 6.5074 - val_eval_dice: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.2442 - eval_dice: 0.0049\n",
      "Epoch 5: val_loss improved from 6.50738 to 6.16149, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 134s 863ms/step - loss: 6.2442 - eval_dice: 0.0049 - val_loss: 6.1615 - val_eval_dice: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.0269 - eval_dice: 0.0046\n",
      "Epoch 6: val_loss improved from 6.16149 to 6.05460, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 139s 889ms/step - loss: 6.0269 - eval_dice: 0.0046 - val_loss: 6.0546 - val_eval_dice: 0.0054 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.8380 - eval_dice: 0.0044\n",
      "Epoch 7: val_loss improved from 6.05460 to 5.86697, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 132s 844ms/step - loss: 5.8380 - eval_dice: 0.0044 - val_loss: 5.8670 - val_eval_dice: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.6018 - eval_dice: 0.0043\n",
      "Epoch 8: val_loss improved from 5.86697 to 5.68931, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 131s 838ms/step - loss: 5.6018 - eval_dice: 0.0043 - val_loss: 5.6893 - val_eval_dice: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4291 - eval_dice: 0.0041\n",
      "Epoch 9: val_loss improved from 5.68931 to 5.56375, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 137s 883ms/step - loss: 5.4291 - eval_dice: 0.0041 - val_loss: 5.5637 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.3271 - eval_dice: 0.0039\n",
      "Epoch 10: val_loss improved from 5.56375 to 5.56040, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 129s 826ms/step - loss: 5.3271 - eval_dice: 0.0039 - val_loss: 5.5604 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2014 - eval_dice: 0.0039\n",
      "Epoch 11: val_loss improved from 5.56040 to 5.42187, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 128s 817ms/step - loss: 5.2014 - eval_dice: 0.0039 - val_loss: 5.4219 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1173 - eval_dice: 0.0039\n",
      "Epoch 12: val_loss did not improve from 5.42187\n",
      "138/138 [==============================] - 133s 851ms/step - loss: 5.1173 - eval_dice: 0.0039 - val_loss: 5.4585 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0724 - eval_dice: 0.0040\n",
      "Epoch 13: val_loss improved from 5.42187 to 5.40420, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 137s 887ms/step - loss: 5.0724 - eval_dice: 0.0040 - val_loss: 5.4042 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0226 - eval_dice: 0.0040\n",
      "Epoch 14: val_loss did not improve from 5.40420\n",
      "138/138 [==============================] - 142s 895ms/step - loss: 5.0226 - eval_dice: 0.0040 - val_loss: 5.4186 - val_eval_dice: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.9906 - eval_dice: 0.0042\n",
      "Epoch 15: val_loss improved from 5.40420 to 5.39866, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 133s 855ms/step - loss: 4.9906 - eval_dice: 0.0042 - val_loss: 5.3987 - val_eval_dice: 0.0048 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8946 - eval_dice: 0.0043\n",
      "Epoch 16: val_loss improved from 5.39866 to 5.20501, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 129s 826ms/step - loss: 4.8946 - eval_dice: 0.0043 - val_loss: 5.2050 - val_eval_dice: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5243 - eval_dice: 0.0042\n",
      "Epoch 17: val_loss improved from 5.20501 to 4.85954, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 132s 844ms/step - loss: 4.5243 - eval_dice: 0.0042 - val_loss: 4.8595 - val_eval_dice: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2814 - eval_dice: 0.0039\n",
      "Epoch 18: val_loss improved from 4.85954 to 4.79144, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 130s 830ms/step - loss: 4.2814 - eval_dice: 0.0039 - val_loss: 4.7914 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1607 - eval_dice: 0.0037\n",
      "Epoch 19: val_loss improved from 4.79144 to 4.76956, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 134s 856ms/step - loss: 4.1607 - eval_dice: 0.0037 - val_loss: 4.7696 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1010 - eval_dice: 0.0036\n",
      "Epoch 20: val_loss improved from 4.76956 to 4.75137, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 145s 919ms/step - loss: 4.1010 - eval_dice: 0.0036 - val_loss: 4.7514 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0415 - eval_dice: 0.0035\n",
      "Epoch 21: val_loss did not improve from 4.75137\n",
      "138/138 [==============================] - 140s 877ms/step - loss: 4.0415 - eval_dice: 0.0035 - val_loss: 4.7911 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0028 - eval_dice: 0.0035\n",
      "Epoch 22: val_loss did not improve from 4.75137\n",
      "138/138 [==============================] - 132s 844ms/step - loss: 4.0028 - eval_dice: 0.0035 - val_loss: 4.7561 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9660 - eval_dice: 0.0034\n",
      "Epoch 23: val_loss did not improve from 4.75137\n",
      "138/138 [==============================] - 139s 895ms/step - loss: 3.9660 - eval_dice: 0.0034 - val_loss: 4.7966 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9559 - eval_dice: 0.0034\n",
      "Epoch 24: val_loss did not improve from 4.75137\n",
      "138/138 [==============================] - 138s 893ms/step - loss: 3.9559 - eval_dice: 0.0034 - val_loss: 4.7794 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9340 - eval_dice: 0.0034\n",
      "Epoch 25: val_loss did not improve from 4.75137\n",
      "138/138 [==============================] - 130s 833ms/step - loss: 3.9340 - eval_dice: 0.0034 - val_loss: 4.7684 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9214 - eval_dice: 0.0033\n",
      "Epoch 26: val_loss improved from 4.75137 to 4.69365, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44\\cp.ckpt\n",
      "138/138 [==============================] - 132s 844ms/step - loss: 3.9214 - eval_dice: 0.0033 - val_loss: 4.6936 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9177 - eval_dice: 0.0033\n",
      "Epoch 27: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 131s 837ms/step - loss: 3.9177 - eval_dice: 0.0033 - val_loss: 4.7536 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9147 - eval_dice: 0.0033\n",
      "Epoch 28: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 136s 873ms/step - loss: 3.9147 - eval_dice: 0.0033 - val_loss: 4.7745 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9095 - eval_dice: 0.0033\n",
      "Epoch 29: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 147s 941ms/step - loss: 3.9095 - eval_dice: 0.0033 - val_loss: 4.7347 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9121 - eval_dice: 0.0033\n",
      "Epoch 30: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 147s 945ms/step - loss: 3.9121 - eval_dice: 0.0033 - val_loss: 4.7808 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9105 - eval_dice: 0.0033\n",
      "Epoch 31: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 136s 860ms/step - loss: 3.9105 - eval_dice: 0.0033 - val_loss: 4.7611 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9104 - eval_dice: 0.0033\n",
      "Epoch 32: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 136s 865ms/step - loss: 3.9104 - eval_dice: 0.0033 - val_loss: 4.7780 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9089 - eval_dice: 0.0033\n",
      "Epoch 33: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 143s 916ms/step - loss: 3.9089 - eval_dice: 0.0033 - val_loss: 4.7992 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8955 - eval_dice: 0.0033\n",
      "Epoch 34: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 138s 874ms/step - loss: 3.8955 - eval_dice: 0.0033 - val_loss: 4.7209 - val_eval_dice: 0.0039 - lr: 2.0000e-05\n",
      "Epoch 35/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8820 - eval_dice: 0.0033\n",
      "Epoch 35: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 126s 801ms/step - loss: 3.8820 - eval_dice: 0.0033 - val_loss: 4.7307 - val_eval_dice: 0.0039 - lr: 2.0000e-05\n",
      "Epoch 36/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8781 - eval_dice: 0.0033\n",
      "Epoch 36: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 126s 801ms/step - loss: 3.8781 - eval_dice: 0.0033 - val_loss: 4.7308 - val_eval_dice: 0.0039 - lr: 2.0000e-05\n",
      "Epoch 37/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8760 - eval_dice: 0.0033\n",
      "Epoch 37: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 132s 848ms/step - loss: 3.8760 - eval_dice: 0.0033 - val_loss: 4.7319 - val_eval_dice: 0.0039 - lr: 2.0000e-05\n",
      "Epoch 38/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8744 - eval_dice: 0.0033\n",
      "Epoch 38: val_loss did not improve from 4.69365\n",
      "138/138 [==============================] - 147s 942ms/step - loss: 3.8744 - eval_dice: 0.0033 - val_loss: 4.7390 - val_eval_dice: 0.0039 - lr: 2.0000e-05\n",
      "Epoch 38: early stopping\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING SESSION ID:', training_session_path, batch_size,params['normalization'])\n",
    "# Fit the model\n",
    "history1 = res_unet_model.fit(\n",
    "                train_sagittal,\n",
    "                epochs=60,\n",
    "                validation_data=val_sagittal,\n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - U-Net3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL\n",
      "Training session id: Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\n"
     ]
    }
   ],
   "source": [
    "logs_sagittal = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "training_session_path = 'Sigma3/GroupNorm/unet3d_{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_sagittal)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_sagittal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet3d input: 8 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\") True\n",
      "Input shape input block with filter 16 : (None, 32, 256, 256, 16)\n",
      "Input shape downsample block with filter 32 : (None, 16, 128, 128, 32)\n",
      "Input shape downsample block with filter 64 : (None, 8, 64, 64, 64)\n",
      "Input shape downsample block with filter 128 : (None, 4, 32, 32, 128)\n",
      "Input shape downsample block with filter 512 : (None, 2, 16, 16, 512)\n"
     ]
    }
   ],
   "source": [
    "# Initial input features\n",
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('unet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'])\n",
    "output = unet3d_mod(yshape[params['subset']][-1],params['mode'],features,params['normalization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)             (None, 32, 256, 256  432         ['input_2[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization (GroupNorm  (None, 32, 256, 256  32         ['conv3d_19[0][0]']              \n",
      " alization)                     , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 32, 256, 256  0           ['group_normalization[0][0]']    \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_18[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_1 (GroupNo  (None, 32, 256, 256  32         ['conv3d_20[0][0]']              \n",
      " rmalization)                   , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_1[0][0]']  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)             (None, 16, 128, 128  13824       ['re_lu_19[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_2 (GroupNo  (None, 16, 128, 128  64         ['conv3d_21[0][0]']              \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_2[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_22 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_20[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_3 (GroupNo  (None, 16, 128, 128  64         ['conv3d_22[0][0]']              \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_3[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_23 (Conv3D)             (None, 8, 64, 64, 6  55296       ['re_lu_21[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_4 (GroupNo  (None, 8, 64, 64, 6  128        ['conv3d_23[0][0]']              \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_4[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_24 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_22[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_5 (GroupNo  (None, 8, 64, 64, 6  128        ['conv3d_24[0][0]']              \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_5[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_25 (Conv3D)             (None, 4, 32, 32, 1  221184      ['re_lu_23[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_6 (GroupNo  (None, 4, 32, 32, 1  256        ['conv3d_25[0][0]']              \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_6[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_26 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_24[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_7 (GroupNo  (None, 4, 32, 32, 1  256        ['conv3d_26[0][0]']              \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_7[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_27 (Conv3D)             (None, 2, 16, 16, 5  1769472     ['re_lu_25[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_8 (GroupNo  (None, 2, 16, 16, 5  1024       ['conv3d_27[0][0]']              \n",
      " rmalization)                   12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_8[0][0]']  \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_28 (Conv3D)             (None, 2, 16, 16, 5  7077888     ['re_lu_26[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_9 (GroupNo  (None, 2, 16, 16, 5  1024       ['conv3d_28[0][0]']              \n",
      " rmalization)                   12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 2, 16, 16, 5  0           ['group_normalization_9[0][0]']  \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 2, 16, 16, 5  0           ['re_lu_27[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_4 (Conv3DTran  (None, 4, 32, 32, 1  1769600    ['dropout_1[0][0]']              \n",
      " spose)                         28)                                                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 4, 32, 32, 2  0           ['conv3d_transpose_4[0][0]',     \n",
      "                                56)                               're_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_29 (Conv3D)             (None, 4, 32, 32, 1  884736      ['concatenate_4[0][0]']          \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_10 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_29[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_10[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_30 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_28[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " group_normalization_11 (GroupN  (None, 4, 32, 32, 1  256        ['conv3d_30[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 4, 32, 32, 1  0           ['group_normalization_11[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_5 (Conv3DTran  (None, 8, 64, 64, 6  221248     ['re_lu_29[0][0]']               \n",
      " spose)                         4)                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 8, 64, 64, 1  0           ['conv3d_transpose_5[0][0]',     \n",
      "                                28)                               're_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_31 (Conv3D)             (None, 8, 64, 64, 6  221184      ['concatenate_5[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_12 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_31[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_12[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_32 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_30[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " group_normalization_13 (GroupN  (None, 8, 64, 64, 6  128        ['conv3d_32[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 8, 64, 64, 6  0           ['group_normalization_13[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_6 (Conv3DTran  (None, 16, 128, 128  55328      ['re_lu_31[0][0]']               \n",
      " spose)                         , 32)                                                             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 16, 128, 128  0           ['conv3d_transpose_6[0][0]',     \n",
      "                                , 64)                             're_lu_21[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_33 (Conv3D)             (None, 16, 128, 128  55296       ['concatenate_6[0][0]']          \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_14 (GroupN  (None, 16, 128, 128  64         ['conv3d_33[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_14[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_34 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_32[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_15 (GroupN  (None, 16, 128, 128  64         ['conv3d_34[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 16, 128, 128  0           ['group_normalization_15[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_7 (Conv3DTran  (None, 32, 256, 256  13840      ['re_lu_33[0][0]']               \n",
      " spose)                         , 16)                                                             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 32, 256, 256  0           ['conv3d_transpose_7[0][0]',     \n",
      "                                , 32)                             're_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_35 (Conv3D)             (None, 32, 256, 256  13824       ['concatenate_7[0][0]']          \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_16 (GroupN  (None, 32, 256, 256  32         ['conv3d_35[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_16[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_36 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_34[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " group_normalization_17 (GroupN  (None, 32, 256, 256  32         ['conv3d_36[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 32, 256, 256  0           ['group_normalization_17[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_37 (Conv3D)             (None, 32, 256, 256  3464        ['re_lu_35[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 256, 256  0           ['conv3d_37[0][0]']              \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,555,624\n",
      "Trainable params: 13,555,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet3d_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "unet3d_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])\n",
    "unet3d_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session id: Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\n",
      "Epoch 1/100\n",
      "    138/Unknown - 114s 698ms/step - loss: 8.4818 - eval_dice: 0.5432\n",
      "Epoch 1: val_loss improved from inf to 7.35139, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 123s 765ms/step - loss: 8.4818 - eval_dice: 0.5432 - val_loss: 7.3514 - val_eval_dice: 0.2016 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.1781 - eval_dice: 0.1066\n",
      "Epoch 2: val_loss improved from 7.35139 to 7.09136, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 116s 737ms/step - loss: 7.1781 - eval_dice: 0.1066 - val_loss: 7.0914 - val_eval_dice: 0.0558 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0572 - eval_dice: 0.0427\n",
      "Epoch 3: val_loss improved from 7.09136 to 7.00015, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 113s 714ms/step - loss: 7.0572 - eval_dice: 0.0427 - val_loss: 7.0001 - val_eval_dice: 0.0358 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.8763 - eval_dice: 0.0249\n",
      "Epoch 4: val_loss improved from 7.00015 to 6.64216, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 113s 713ms/step - loss: 6.8763 - eval_dice: 0.0249 - val_loss: 6.6422 - val_eval_dice: 0.0153 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.3220 - eval_dice: 0.0090\n",
      "Epoch 5: val_loss improved from 6.64216 to 6.19356, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 114s 722ms/step - loss: 6.3220 - eval_dice: 0.0090 - val_loss: 6.1936 - val_eval_dice: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.8724 - eval_dice: 0.0061\n",
      "Epoch 6: val_loss improved from 6.19356 to 5.80680, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 116s 735ms/step - loss: 5.8724 - eval_dice: 0.0061 - val_loss: 5.8068 - val_eval_dice: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.5406 - eval_dice: 0.0050\n",
      "Epoch 7: val_loss improved from 5.80680 to 5.56885, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 115s 725ms/step - loss: 5.5406 - eval_dice: 0.0050 - val_loss: 5.5689 - val_eval_dice: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.3838 - eval_dice: 0.0045\n",
      "Epoch 8: val_loss improved from 5.56885 to 5.53737, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 116s 733ms/step - loss: 5.3838 - eval_dice: 0.0045 - val_loss: 5.5374 - val_eval_dice: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.3013 - eval_dice: 0.0042\n",
      "Epoch 9: val_loss improved from 5.53737 to 5.46420, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 114s 720ms/step - loss: 5.3013 - eval_dice: 0.0042 - val_loss: 5.4642 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2551 - eval_dice: 0.0041\n",
      "Epoch 10: val_loss did not improve from 5.46420\n",
      "138/138 [==============================] - 111s 706ms/step - loss: 5.2551 - eval_dice: 0.0041 - val_loss: 5.4761 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1898 - eval_dice: 0.0040\n",
      "Epoch 11: val_loss did not improve from 5.46420\n",
      "138/138 [==============================] - 112s 706ms/step - loss: 5.1898 - eval_dice: 0.0040 - val_loss: 5.4715 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0945 - eval_dice: 0.0040\n",
      "Epoch 12: val_loss improved from 5.46420 to 5.34155, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 112s 707ms/step - loss: 5.0945 - eval_dice: 0.0040 - val_loss: 5.3415 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8982 - eval_dice: 0.0038\n",
      "Epoch 13: val_loss improved from 5.34155 to 5.26724, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 110s 697ms/step - loss: 4.8982 - eval_dice: 0.0038 - val_loss: 5.2672 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8278 - eval_dice: 0.0037\n",
      "Epoch 14: val_loss improved from 5.26724 to 5.14633, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 110s 697ms/step - loss: 4.8278 - eval_dice: 0.0037 - val_loss: 5.1463 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7113 - eval_dice: 0.0036\n",
      "Epoch 15: val_loss improved from 5.14633 to 5.13342, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 110s 697ms/step - loss: 4.7113 - eval_dice: 0.0036 - val_loss: 5.1334 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6858 - eval_dice: 0.0036\n",
      "Epoch 16: val_loss did not improve from 5.13342\n",
      "138/138 [==============================] - 113s 718ms/step - loss: 4.6858 - eval_dice: 0.0036 - val_loss: 5.1494 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6394 - eval_dice: 0.0035\n",
      "Epoch 17: val_loss improved from 5.13342 to 5.11125, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 113s 714ms/step - loss: 4.6394 - eval_dice: 0.0035 - val_loss: 5.1113 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5214 - eval_dice: 0.0035\n",
      "Epoch 18: val_loss improved from 5.11125 to 5.05701, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 114s 716ms/step - loss: 4.5214 - eval_dice: 0.0035 - val_loss: 5.0570 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4810 - eval_dice: 0.0034\n",
      "Epoch 19: val_loss improved from 5.05701 to 5.02943, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 112s 711ms/step - loss: 4.4810 - eval_dice: 0.0034 - val_loss: 5.0294 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4570 - eval_dice: 0.0034\n",
      "Epoch 20: val_loss improved from 5.02943 to 5.02798, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 112s 709ms/step - loss: 4.4570 - eval_dice: 0.0034 - val_loss: 5.0280 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4459 - eval_dice: 0.0034\n",
      "Epoch 21: val_loss did not improve from 5.02798\n",
      "138/138 [==============================] - 112s 704ms/step - loss: 4.4459 - eval_dice: 0.0034 - val_loss: 5.0601 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4354 - eval_dice: 0.0034\n",
      "Epoch 22: val_loss did not improve from 5.02798\n",
      "138/138 [==============================] - 115s 726ms/step - loss: 4.4354 - eval_dice: 0.0034 - val_loss: 5.0362 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4217 - eval_dice: 0.0035\n",
      "Epoch 23: val_loss improved from 5.02798 to 5.02421, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 114s 723ms/step - loss: 4.4217 - eval_dice: 0.0035 - val_loss: 5.0242 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3672 - eval_dice: 0.0037\n",
      "Epoch 24: val_loss improved from 5.02421 to 4.85488, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 113s 714ms/step - loss: 4.3672 - eval_dice: 0.0037 - val_loss: 4.8549 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1323 - eval_dice: 0.0036\n",
      "Epoch 25: val_loss improved from 4.85488 to 4.69580, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 110s 698ms/step - loss: 4.1323 - eval_dice: 0.0036 - val_loss: 4.6958 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0691 - eval_dice: 0.0035\n",
      "Epoch 26: val_loss did not improve from 4.69580\n",
      "138/138 [==============================] - 110s 697ms/step - loss: 4.0691 - eval_dice: 0.0035 - val_loss: 4.7347 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0135 - eval_dice: 0.0035\n",
      "Epoch 27: val_loss did not improve from 4.69580\n",
      "138/138 [==============================] - 112s 710ms/step - loss: 4.0135 - eval_dice: 0.0035 - val_loss: 4.7047 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9841 - eval_dice: 0.0034\n",
      "Epoch 28: val_loss did not improve from 4.69580\n",
      "138/138 [==============================] - 110s 695ms/step - loss: 3.9841 - eval_dice: 0.0034 - val_loss: 4.7144 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9688 - eval_dice: 0.0034\n",
      "Epoch 29: val_loss improved from 4.69580 to 4.65732, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 111s 700ms/step - loss: 3.9688 - eval_dice: 0.0034 - val_loss: 4.6573 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9528 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 112s 698ms/step - loss: 3.9528 - eval_dice: 0.0034 - val_loss: 4.6990 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9427 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 120s 760ms/step - loss: 3.9427 - eval_dice: 0.0034 - val_loss: 4.7315 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9308 - eval_dice: 0.0033\n",
      "Epoch 32: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 120s 761ms/step - loss: 3.9308 - eval_dice: 0.0033 - val_loss: 4.7119 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9181 - eval_dice: 0.0033\n",
      "Epoch 33: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 117s 736ms/step - loss: 3.9181 - eval_dice: 0.0033 - val_loss: 4.7093 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9112 - eval_dice: 0.0033\n",
      "Epoch 34: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.9112 - eval_dice: 0.0033 - val_loss: 4.6912 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9020 - eval_dice: 0.0033\n",
      "Epoch 35: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.9020 - eval_dice: 0.0033 - val_loss: 4.6731 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9011 - eval_dice: 0.0033\n",
      "Epoch 36: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.9011 - eval_dice: 0.0033 - val_loss: 4.7005 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9000 - eval_dice: 0.0033\n",
      "Epoch 37: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.9000 - eval_dice: 0.0033 - val_loss: 4.6771 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8992 - eval_dice: 0.0033\n",
      "Epoch 38: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8992 - eval_dice: 0.0033 - val_loss: 4.6708 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9024 - eval_dice: 0.0033\n",
      "Epoch 39: val_loss did not improve from 4.65732\n",
      "138/138 [==============================] - 116s 728ms/step - loss: 3.9024 - eval_dice: 0.0033 - val_loss: 4.6804 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8876 - eval_dice: 0.0033\n",
      "Epoch 40: val_loss improved from 4.65732 to 4.65498, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d_(2024-07-18)/01.44.09\\cp.ckpt\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8876 - eval_dice: 0.0033 - val_loss: 4.6550 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8776 - eval_dice: 0.0033\n",
      "Epoch 41: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 120s 761ms/step - loss: 3.8776 - eval_dice: 0.0033 - val_loss: 4.6608 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8743 - eval_dice: 0.0033\n",
      "Epoch 42: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 117s 738ms/step - loss: 3.8743 - eval_dice: 0.0033 - val_loss: 4.6608 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8721 - eval_dice: 0.0033\n",
      "Epoch 43: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 116s 733ms/step - loss: 3.8721 - eval_dice: 0.0033 - val_loss: 4.6608 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8707 - eval_dice: 0.0033\n",
      "Epoch 44: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 115s 721ms/step - loss: 3.8707 - eval_dice: 0.0033 - val_loss: 4.6587 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8696 - eval_dice: 0.0033\n",
      "Epoch 45: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8696 - eval_dice: 0.0033 - val_loss: 4.6665 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8687 - eval_dice: 0.0033\n",
      "Epoch 46: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8687 - eval_dice: 0.0033 - val_loss: 4.6645 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8679 - eval_dice: 0.0033\n",
      "Epoch 47: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8679 - eval_dice: 0.0033 - val_loss: 4.6661 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8672 - eval_dice: 0.0033\n",
      "Epoch 48: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8672 - eval_dice: 0.0033 - val_loss: 4.6644 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8666 - eval_dice: 0.0033\n",
      "Epoch 49: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8666 - eval_dice: 0.0033 - val_loss: 4.6651 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8662 - eval_dice: 0.0033\n",
      "Epoch 50: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 113s 713ms/step - loss: 3.8662 - eval_dice: 0.0033 - val_loss: 4.6625 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8653 - eval_dice: 0.0033\n",
      "Epoch 51: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.8653 - eval_dice: 0.0033 - val_loss: 4.6616 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8652 - eval_dice: 0.0033\n",
      "Epoch 52: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 118s 739ms/step - loss: 3.8652 - eval_dice: 0.0033 - val_loss: 4.6625 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8649 - eval_dice: 0.0033\n",
      "Epoch 53: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 117s 731ms/step - loss: 3.8649 - eval_dice: 0.0033 - val_loss: 4.6633 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8648 - eval_dice: 0.0033\n",
      "Epoch 54: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 117s 729ms/step - loss: 3.8648 - eval_dice: 0.0033 - val_loss: 4.6620 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8646 - eval_dice: 0.0033\n",
      "Epoch 55: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 116s 725ms/step - loss: 3.8646 - eval_dice: 0.0033 - val_loss: 4.6635 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8645 - eval_dice: 0.0033\n",
      "Epoch 56: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 114s 711ms/step - loss: 3.8645 - eval_dice: 0.0033 - val_loss: 4.6621 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8644 - eval_dice: 0.0033\n",
      "Epoch 57: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.8644 - eval_dice: 0.0033 - val_loss: 4.6661 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8642 - eval_dice: 0.0033\n",
      "Epoch 58: val_loss did not improve from 4.65498\n",
      "138/138 [==============================] - 114s 711ms/step - loss: 3.8642 - eval_dice: 0.0033 - val_loss: 4.6639 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 58: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "print('Training session id:', training_session_path)\n",
    "history1_unet = unet3d_model.fit(\n",
    "                train_sagittal,\n",
    "                epochs=100,\n",
    "                validation_data=val_sagittal, \n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - AttUnet3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL\n",
      "Training session id: Sigma3/BatchNorm/attunet3d_(2024-07-18)/17.39.59\n"
     ]
    }
   ],
   "source": [
    "logs_axial = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "training_session_path = 'Sigma3/BatchNorm/attunet3d_{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_axial)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_axial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttUnet3d input: 8 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\") True\n",
      "Input shape input block with filter 16 : (None, 32, 256, 256, 16)\n",
      "Input shape downsample block with filter 32 : (None, 16, 128, 128, 32)\n",
      "Input shape downsample block with filter 64 : (None, 8, 64, 64, 64)\n",
      "Input shape downsample block with filter 128 : (None, 4, 32, 32, 128)\n",
      "Input shape downsample block with filter 512 : (None, 2, 16, 16, 512)\n",
      "Input shape AFTER concatenate: (None, 4, 32, 32, 128)\n",
      "Input shape AFTER concatenate: (None, 8, 64, 64, 64)\n",
      "Input shape AFTER concatenate: (None, 16, 128, 128, 32)\n",
      "Input shape AFTER concatenate: (None, 32, 256, 256, 16)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_62 (Conv3D)             (None, 32, 256, 256  432         ['input_4[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 256, 256  64         ['conv3d_62[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_18[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_63 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_36[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 256, 256  64         ['conv3d_63[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_19[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_64 (Conv3D)             (None, 16, 128, 128  13824       ['re_lu_37[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 128, 128  128        ['conv3d_64[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_20[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_65 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_38[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 128, 128  128        ['conv3d_65[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_21[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_66 (Conv3D)             (None, 8, 64, 64, 6  55296       ['re_lu_39[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_66[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_22[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_67 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_40[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_67[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_23[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_68 (Conv3D)             (None, 4, 32, 32, 1  221184      ['re_lu_41[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_68[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_24[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_69 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_42[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_69[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_25[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_70 (Conv3D)             (None, 2, 16, 16, 5  1769472     ['re_lu_43[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 2, 16, 16, 5  2048       ['conv3d_70[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 2, 16, 16, 5  0           ['batch_normalization_26[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_71 (Conv3D)             (None, 2, 16, 16, 5  7077888     ['re_lu_44[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 2, 16, 16, 5  2048       ['conv3d_71[0][0]']              \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 2, 16, 16, 5  0           ['batch_normalization_27[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_72 (Conv3D)             (None, 2, 16, 16, 6  65600       ['re_lu_43[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_73 (Conv3D)             (None, 2, 16, 16, 6  32832       ['re_lu_45[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 2, 16, 16, 6  0           ['conv3d_72[0][0]',              \n",
      "                                4)                                'conv3d_73[0][0]']              \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 2, 16, 16, 6  0           ['add_8[0][0]']                  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_74 (Conv3D)             (None, 2, 16, 16, 1  65          ['activation_18[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 2, 16, 16, 1  0           ['conv3d_74[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_8 (UpSampling3D)  (None, 4, 32, 32, 1  0          ['activation_19[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_8 (Conv3DTran  (None, 4, 32, 32, 1  1769600    ['re_lu_45[0][0]']               \n",
      " spose)                         28)                                                               \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 4, 32, 32, 1  0           ['up_sampling3d_8[0][0]',        \n",
      "                                28)                               're_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 4, 32, 32, 2  0           ['conv3d_transpose_8[0][0]',     \n",
      "                                56)                               'multiply_8[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_75 (Conv3D)             (None, 4, 32, 32, 1  884736      ['concatenate_8[0][0]']          \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_75[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_28[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_76 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_46[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_76[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_29[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_77 (Conv3D)             (None, 4, 32, 32, 3  16416       ['re_lu_41[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_78 (Conv3D)             (None, 4, 32, 32, 3  4128        ['re_lu_47[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4, 32, 32, 3  0           ['conv3d_77[0][0]',              \n",
      "                                2)                                'conv3d_78[0][0]']              \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 4, 32, 32, 3  0           ['add_9[0][0]']                  \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_79 (Conv3D)             (None, 4, 32, 32, 1  33          ['activation_20[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 4, 32, 32, 1  0           ['conv3d_79[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_9 (UpSampling3D)  (None, 8, 64, 64, 1  0          ['activation_21[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_9 (Conv3DTran  (None, 8, 64, 64, 6  221248     ['re_lu_47[0][0]']               \n",
      " spose)                         4)                                                                \n",
      "                                                                                                  \n",
      " multiply_9 (Multiply)          (None, 8, 64, 64, 6  0           ['up_sampling3d_9[0][0]',        \n",
      "                                4)                                're_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 8, 64, 64, 1  0           ['conv3d_transpose_9[0][0]',     \n",
      "                                28)                               'multiply_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_80 (Conv3D)             (None, 8, 64, 64, 6  221184      ['concatenate_9[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_80[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_30[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_81 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_48[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_81[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_31[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_82 (Conv3D)             (None, 8, 64, 64, 1  4112        ['re_lu_39[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_83 (Conv3D)             (None, 8, 64, 64, 1  1040        ['re_lu_49[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 8, 64, 64, 1  0           ['conv3d_82[0][0]',              \n",
      "                                6)                                'conv3d_83[0][0]']              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 64, 64, 1  0           ['add_10[0][0]']                 \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_84 (Conv3D)             (None, 8, 64, 64, 1  17          ['activation_22[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 8, 64, 64, 1  0           ['conv3d_84[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_10 (UpSampling3D  (None, 16, 128, 128  0          ['activation_23[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_10 (Conv3DTra  (None, 16, 128, 128  55328      ['re_lu_49[0][0]']               \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " multiply_10 (Multiply)         (None, 16, 128, 128  0           ['up_sampling3d_10[0][0]',       \n",
      "                                , 32)                             're_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 16, 128, 128  0           ['conv3d_transpose_10[0][0]',    \n",
      "                                , 64)                             'multiply_10[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_85 (Conv3D)             (None, 16, 128, 128  55296       ['concatenate_10[0][0]']         \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 16, 128, 128  128        ['conv3d_85[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_32[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_86 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_50[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 16, 128, 128  128        ['conv3d_86[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_33[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_87 (Conv3D)             (None, 16, 128, 128  1032        ['re_lu_37[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_88 (Conv3D)             (None, 16, 128, 128  264         ['re_lu_51[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 16, 128, 128  0           ['conv3d_87[0][0]',              \n",
      "                                , 8)                              'conv3d_88[0][0]']              \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 128, 128  0           ['add_11[0][0]']                 \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_89 (Conv3D)             (None, 16, 128, 128  9           ['activation_24[0][0]']          \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 128, 128  0           ['conv3d_89[0][0]']              \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " up_sampling3d_11 (UpSampling3D  (None, 32, 256, 256  0          ['activation_25[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_11 (Conv3DTra  (None, 32, 256, 256  13840      ['re_lu_51[0][0]']               \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " multiply_11 (Multiply)         (None, 32, 256, 256  0           ['up_sampling3d_11[0][0]',       \n",
      "                                , 16)                             're_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 32, 256, 256  0           ['conv3d_transpose_11[0][0]',    \n",
      "                                , 32)                             'multiply_11[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_90 (Conv3D)             (None, 32, 256, 256  13824       ['concatenate_11[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 32, 256, 256  64         ['conv3d_90[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_34[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_91 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_52[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 32, 256, 256  64         ['conv3d_91[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_35[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_92 (Conv3D)             (None, 32, 256, 256  3464        ['re_lu_53[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 32, 256, 256  0           ['conv3d_92[0][0]']              \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,685,140\n",
      "Trainable params: 13,681,172\n",
      "Non-trainable params: 3,968\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initial input features\n",
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('AttUnet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'])\n",
    "output = AttUnet3d(yshape[params['subset']][-1],params['mode'],features,params['normalization'])\n",
    "attunet_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "attunet_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])\n",
    "attunet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session id: Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37 2 groupnorm\n",
      "Epoch 1/60\n",
      "    138/Unknown - 126s 729ms/step - loss: 7.9446 - eval_dice: 0.3969\n",
      "Epoch 1: val_loss improved from inf to 7.17636, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 135s 796ms/step - loss: 7.9446 - eval_dice: 0.3969 - val_loss: 7.1764 - val_eval_dice: 0.1075 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0826 - eval_dice: 0.0636\n",
      "Epoch 2: val_loss improved from 7.17636 to 7.01558, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 121s 770ms/step - loss: 7.0826 - eval_dice: 0.0636 - val_loss: 7.0156 - val_eval_dice: 0.0403 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.9363 - eval_dice: 0.0265\n",
      "Epoch 3: val_loss improved from 7.01558 to 6.86039, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 122s 766ms/step - loss: 6.9363 - eval_dice: 0.0265 - val_loss: 6.8604 - val_eval_dice: 0.0155 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.5146 - eval_dice: 0.0118\n",
      "Epoch 4: val_loss improved from 6.86039 to 6.00191, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 132s 840ms/step - loss: 6.5146 - eval_dice: 0.0118 - val_loss: 6.0019 - val_eval_dice: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4914 - eval_dice: 0.0056\n",
      "Epoch 5: val_loss improved from 6.00191 to 5.38948, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 131s 819ms/step - loss: 5.4914 - eval_dice: 0.0056 - val_loss: 5.3895 - val_eval_dice: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0710 - eval_dice: 0.0047\n",
      "Epoch 6: val_loss improved from 5.38948 to 5.16537, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 130s 830ms/step - loss: 5.0710 - eval_dice: 0.0047 - val_loss: 5.1654 - val_eval_dice: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8478 - eval_dice: 0.0045\n",
      "Epoch 7: val_loss improved from 5.16537 to 5.04252, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 133s 834ms/step - loss: 4.8478 - eval_dice: 0.0045 - val_loss: 5.0425 - val_eval_dice: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7221 - eval_dice: 0.0043\n",
      "Epoch 8: val_loss improved from 5.04252 to 4.93351, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 125s 789ms/step - loss: 4.7221 - eval_dice: 0.0043 - val_loss: 4.9335 - val_eval_dice: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6293 - eval_dice: 0.0041\n",
      "Epoch 9: val_loss improved from 4.93351 to 4.90256, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 134s 840ms/step - loss: 4.6293 - eval_dice: 0.0041 - val_loss: 4.9026 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5724 - eval_dice: 0.0040\n",
      "Epoch 10: val_loss did not improve from 4.90256\n",
      "138/138 [==============================] - 128s 802ms/step - loss: 4.5724 - eval_dice: 0.0040 - val_loss: 5.0003 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5189 - eval_dice: 0.0039\n",
      "Epoch 11: val_loss did not improve from 4.90256\n",
      "138/138 [==============================] - 119s 757ms/step - loss: 4.5189 - eval_dice: 0.0039 - val_loss: 5.0093 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4972 - eval_dice: 0.0039\n",
      "Epoch 12: val_loss did not improve from 4.90256\n",
      "138/138 [==============================] - 118s 746ms/step - loss: 4.4972 - eval_dice: 0.0039 - val_loss: 4.9112 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4432 - eval_dice: 0.0038\n",
      "Epoch 13: val_loss did not improve from 4.90256\n",
      "138/138 [==============================] - 118s 745ms/step - loss: 4.4432 - eval_dice: 0.0038 - val_loss: 4.9364 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3989 - eval_dice: 0.0037\n",
      "Epoch 14: val_loss improved from 4.90256 to 4.89146, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 118s 748ms/step - loss: 4.3989 - eval_dice: 0.0037 - val_loss: 4.8915 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3580 - eval_dice: 0.0036\n",
      "Epoch 15: val_loss did not improve from 4.89146\n",
      "138/138 [==============================] - 118s 747ms/step - loss: 4.3580 - eval_dice: 0.0036 - val_loss: 5.0027 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3293 - eval_dice: 0.0036\n",
      "Epoch 16: val_loss improved from 4.89146 to 4.86374, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 120s 762ms/step - loss: 4.3293 - eval_dice: 0.0036 - val_loss: 4.8637 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3081 - eval_dice: 0.0036\n",
      "Epoch 17: val_loss did not improve from 4.86374\n",
      "138/138 [==============================] - 118s 747ms/step - loss: 4.3081 - eval_dice: 0.0036 - val_loss: 4.9440 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2901 - eval_dice: 0.0035\n",
      "Epoch 18: val_loss did not improve from 4.86374\n",
      "138/138 [==============================] - 116s 734ms/step - loss: 4.2901 - eval_dice: 0.0035 - val_loss: 4.9277 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2644 - eval_dice: 0.0035\n",
      "Epoch 19: val_loss did not improve from 4.86374\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 4.2644 - eval_dice: 0.0035 - val_loss: 4.9200 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2423 - eval_dice: 0.0035\n",
      "Epoch 20: val_loss did not improve from 4.86374\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 4.2423 - eval_dice: 0.0035 - val_loss: 4.9317 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2250 - eval_dice: 0.0034\n",
      "Epoch 21: val_loss did not improve from 4.86374\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 4.2250 - eval_dice: 0.0034 - val_loss: 4.9219 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2137 - eval_dice: 0.0034\n",
      "Epoch 22: val_loss did not improve from 4.86374\n",
      "138/138 [==============================] - 116s 730ms/step - loss: 4.2137 - eval_dice: 0.0034 - val_loss: 4.9203 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1048 - eval_dice: 0.0034\n",
      "Epoch 23: val_loss improved from 4.86374 to 4.85001, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 735ms/step - loss: 4.1048 - eval_dice: 0.0034 - val_loss: 4.8500 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0916 - eval_dice: 0.0034\n",
      "Epoch 24: val_loss did not improve from 4.85001\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 4.0916 - eval_dice: 0.0034 - val_loss: 4.8552 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0938 - eval_dice: 0.0034\n",
      "Epoch 25: val_loss did not improve from 4.85001\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 4.0938 - eval_dice: 0.0034 - val_loss: 4.8614 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0638 - eval_dice: 0.0034\n",
      "Epoch 26: val_loss improved from 4.85001 to 4.84440, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 735ms/step - loss: 4.0638 - eval_dice: 0.0034 - val_loss: 4.8444 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0493 - eval_dice: 0.0034\n",
      "Epoch 27: val_loss improved from 4.84440 to 4.81344, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 734ms/step - loss: 4.0493 - eval_dice: 0.0034 - val_loss: 4.8134 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 28/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0461 - eval_dice: 0.0034\n",
      "Epoch 28: val_loss did not improve from 4.81344\n",
      "138/138 [==============================] - 116s 730ms/step - loss: 4.0461 - eval_dice: 0.0034 - val_loss: 4.8395 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0442 - eval_dice: 0.0034\n",
      "Epoch 29: val_loss improved from 4.81344 to 4.78949, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 734ms/step - loss: 4.0442 - eval_dice: 0.0034 - val_loss: 4.7895 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0380 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss improved from 4.78949 to 4.78579, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 735ms/step - loss: 4.0380 - eval_dice: 0.0034 - val_loss: 4.7858 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0276 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss improved from 4.78579 to 4.76637, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 734ms/step - loss: 4.0276 - eval_dice: 0.0034 - val_loss: 4.7664 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9185 - eval_dice: 0.0034\n",
      "Epoch 32: val_loss improved from 4.76637 to 4.73529, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 734ms/step - loss: 3.9185 - eval_dice: 0.0034 - val_loss: 4.7353 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9257 - eval_dice: 0.0034\n",
      "Epoch 33: val_loss improved from 4.73529 to 4.73334, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 735ms/step - loss: 3.9257 - eval_dice: 0.0034 - val_loss: 4.7333 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9176 - eval_dice: 0.0034\n",
      "Epoch 34: val_loss did not improve from 4.73334\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 3.9176 - eval_dice: 0.0034 - val_loss: 4.7748 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9049 - eval_dice: 0.0033\n",
      "Epoch 35: val_loss did not improve from 4.73334\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 3.9049 - eval_dice: 0.0033 - val_loss: 4.7708 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8950 - eval_dice: 0.0033\n",
      "Epoch 36: val_loss improved from 4.73334 to 4.72270, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 737ms/step - loss: 3.8950 - eval_dice: 0.0033 - val_loss: 4.7227 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8865 - eval_dice: 0.0033\n",
      "Epoch 37: val_loss did not improve from 4.72270\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 3.8865 - eval_dice: 0.0033 - val_loss: 4.7347 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8855 - eval_dice: 0.0033\n",
      "Epoch 38: val_loss did not improve from 4.72270\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 3.8855 - eval_dice: 0.0033 - val_loss: 4.7334 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8838 - eval_dice: 0.0033\n",
      "Epoch 39: val_loss did not improve from 4.72270\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 3.8838 - eval_dice: 0.0033 - val_loss: 4.7615 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8856 - eval_dice: 0.0033\n",
      "Epoch 40: val_loss did not improve from 4.72270\n",
      "138/138 [==============================] - 115s 731ms/step - loss: 3.8856 - eval_dice: 0.0033 - val_loss: 4.7522 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8862 - eval_dice: 0.0033\n",
      "Epoch 41: val_loss did not improve from 4.72270\n",
      "138/138 [==============================] - 116s 731ms/step - loss: 3.8862 - eval_dice: 0.0033 - val_loss: 4.7420 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8821 - eval_dice: 0.0033\n",
      "Epoch 42: val_loss improved from 4.72270 to 4.71671, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 116s 734ms/step - loss: 3.8821 - eval_dice: 0.0033 - val_loss: 4.7167 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8829 - eval_dice: 0.0033\n",
      "Epoch 43: val_loss improved from 4.71671 to 4.71445, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 125s 796ms/step - loss: 3.8829 - eval_dice: 0.0033 - val_loss: 4.7145 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 44/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8853 - eval_dice: 0.0033\n",
      "Epoch 44: val_loss improved from 4.71445 to 4.69942, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/attunet3d_(2024-07-18)/15.21.37\\cp.ckpt\n",
      "138/138 [==============================] - 126s 803ms/step - loss: 3.8853 - eval_dice: 0.0033 - val_loss: 4.6994 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 45/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8823 - eval_dice: 0.0033\n",
      "Epoch 45: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 124s 793ms/step - loss: 3.8823 - eval_dice: 0.0033 - val_loss: 4.7391 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 46/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8809 - eval_dice: 0.0033\n",
      "Epoch 46: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 118s 751ms/step - loss: 3.8809 - eval_dice: 0.0033 - val_loss: 4.7394 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 47/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8807 - eval_dice: 0.0033\n",
      "Epoch 47: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 118s 750ms/step - loss: 3.8807 - eval_dice: 0.0033 - val_loss: 4.7867 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 48/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8860 - eval_dice: 0.0033\n",
      "Epoch 48: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 118s 750ms/step - loss: 3.8860 - eval_dice: 0.0033 - val_loss: 4.7292 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 49/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8841 - eval_dice: 0.0033\n",
      "Epoch 49: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 118s 751ms/step - loss: 3.8841 - eval_dice: 0.0033 - val_loss: 4.7383 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 50/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8842 - eval_dice: 0.0033\n",
      "Epoch 50: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 119s 751ms/step - loss: 3.8842 - eval_dice: 0.0033 - val_loss: 4.7346 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 51/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8893 - eval_dice: 0.0033\n",
      "Epoch 51: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 118s 751ms/step - loss: 3.8893 - eval_dice: 0.0033 - val_loss: 4.7719 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 52/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8730 - eval_dice: 0.0033\n",
      "Epoch 52: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 118s 751ms/step - loss: 3.8730 - eval_dice: 0.0033 - val_loss: 4.7114 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 53/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8615 - eval_dice: 0.0033\n",
      "Epoch 53: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 124s 794ms/step - loss: 3.8615 - eval_dice: 0.0033 - val_loss: 4.7135 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 54/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8582 - eval_dice: 0.0033\n",
      "Epoch 54: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 125s 796ms/step - loss: 3.8582 - eval_dice: 0.0033 - val_loss: 4.7059 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 55/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8565 - eval_dice: 0.0033\n",
      "Epoch 55: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 122s 775ms/step - loss: 3.8565 - eval_dice: 0.0033 - val_loss: 4.7097 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 56/60\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8553 - eval_dice: 0.0033\n",
      "Epoch 56: val_loss did not improve from 4.69942\n",
      "138/138 [==============================] - 118s 750ms/step - loss: 3.8553 - eval_dice: 0.0033 - val_loss: 4.7080 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "print('Training session id:', training_session_path,batch_size,params['normalization'])\n",
    "history1 = attunet_model.fit(\n",
    "                train_sagittal,\n",
    "                epochs=60,\n",
    "                validation_data=val_sagittal,\n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MODEL] - Residual Attention U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs Directory: C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL\n",
      "Training session id: Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\n"
     ]
    }
   ],
   "source": [
    "logs_axial = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "training_session_path = 'Sigma3/BatchNorm/resattunet3d_{}'.format(datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\"))\n",
    "print('Logs Directory:',logs_axial)\n",
    "print('Training session id:', training_session_path)\n",
    "file_path, callbacks_list = prepareCallbacks(training_session_path, logs_axial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttResUnet3d input: 8 train KerasTensor(type_spec=TensorSpec(shape=(None, 32, 256, 256, 1), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\") True\n",
      "Input shape input block with filter 16 : (None, 32, 256, 256, 16)\n"
     ]
    }
   ],
   "source": [
    "features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "print('AttResUnet3d input:',yshape[params['subset']][-1],params['mode'],features,params['augment'])\n",
    "output = resAtt_unet3d(yshape[params['subset']][-1],params['mode'],features,params['normalization'])\n",
    "attres_unet_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "attres_unet_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                   loss=make_loss, \n",
    "                   metrics=[eval_dice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_93 (Conv3D)             (None, 32, 256, 256  432         ['input_5[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 32, 256, 256  64         ['conv3d_93[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_36[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_94 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_54[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 32, 256, 256  64         ['conv3d_94[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_37[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_95 (Conv3D)             (None, 16, 128, 128  13824       ['re_lu_55[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 16, 128, 128  128        ['conv3d_95[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_38[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_96 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_56[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 16, 128, 128  128        ['conv3d_96[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_97 (Conv3D)             (None, 16, 128, 128  512         ['re_lu_55[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_39[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 16, 128, 128  128        ['conv3d_97[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 16, 128, 128  0           ['re_lu_57[0][0]',               \n",
      "                                , 32)                             'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 16, 128, 128  0           ['add_12[0][0]']                 \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_98 (Conv3D)             (None, 8, 64, 64, 6  55296       ['re_lu_58[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_98[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_41[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_99 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_59[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_99[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_100 (Conv3D)            (None, 8, 64, 64, 6  2048        ['re_lu_58[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_42[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_100[0][0]']             \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 8, 64, 64, 6  0           ['re_lu_60[0][0]',               \n",
      "                                4)                                'batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 8, 64, 64, 6  0           ['add_13[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_101 (Conv3D)            (None, 4, 32, 32, 1  221184      ['re_lu_61[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_101[0][0]']             \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_62 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_44[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_102 (Conv3D)            (None, 4, 32, 32, 1  442368      ['re_lu_62[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_102[0][0]']             \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_103 (Conv3D)            (None, 4, 32, 32, 1  8192        ['re_lu_61[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_63 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_45[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_103[0][0]']             \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 4, 32, 32, 1  0           ['re_lu_63[0][0]',               \n",
      "                                28)                               'batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_64 (ReLU)                (None, 4, 32, 32, 1  0           ['add_14[0][0]']                 \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_104 (Conv3D)            (None, 2, 16, 16, 5  1769472     ['re_lu_64[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 2, 16, 16, 5  2048       ['conv3d_104[0][0]']             \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 2, 16, 16, 5  0           ['batch_normalization_47[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_105 (Conv3D)            (None, 2, 16, 16, 5  7077888     ['re_lu_65[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 2, 16, 16, 5  2048       ['conv3d_105[0][0]']             \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_106 (Conv3D)            (None, 2, 16, 16, 5  65536       ['re_lu_64[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 2, 16, 16, 5  0           ['batch_normalization_48[0][0]'] \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 2, 16, 16, 5  2048       ['conv3d_106[0][0]']             \n",
      " ormalization)                  12)                                                               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 2, 16, 16, 5  0           ['re_lu_66[0][0]',               \n",
      "                                12)                               'batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 2, 16, 16, 5  0           ['add_15[0][0]']                 \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2, 16, 16, 5  0           ['re_lu_67[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_107 (Conv3D)            (None, 2, 16, 16, 6  65600       ['re_lu_64[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_108 (Conv3D)            (None, 2, 16, 16, 6  32832       ['dropout[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 2, 16, 16, 6  0           ['conv3d_107[0][0]',             \n",
      "                                4)                                'conv3d_108[0][0]']             \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 2, 16, 16, 6  0           ['add_16[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_109 (Conv3D)            (None, 2, 16, 16, 1  65          ['activation_27[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 2, 16, 16, 1  0           ['conv3d_109[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_12 (UpSampling3D  (None, 4, 32, 32, 1  0          ['activation_28[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_12 (Conv3DTra  (None, 4, 32, 32, 1  1769600    ['dropout[0][0]']                \n",
      " nspose)                        28)                                                               \n",
      "                                                                                                  \n",
      " multiply_12 (Multiply)         (None, 4, 32, 32, 1  0           ['up_sampling3d_12[0][0]',       \n",
      "                                28)                               're_lu_64[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 4, 32, 32, 2  0           ['conv3d_transpose_12[0][0]',    \n",
      "                                56)                               'multiply_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_110 (Conv3D)            (None, 4, 32, 32, 1  884736      ['concatenate_12[0][0]']         \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_110[0][0]']             \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_50[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_111 (Conv3D)            (None, 4, 32, 32, 1  442368      ['re_lu_68[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_111[0][0]']             \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_13 (Conv3DTra  (None, 4, 32, 32, 1  65536      ['dropout[0][0]']                \n",
      " nspose)                        28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_51[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_transpose_13[0][0]']    \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 4, 32, 32, 1  0           ['re_lu_69[0][0]',               \n",
      "                                28)                               'batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 4, 32, 32, 1  0           ['add_17[0][0]']                 \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_112 (Conv3D)            (None, 4, 32, 32, 3  16416       ['re_lu_61[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_113 (Conv3D)            (None, 4, 32, 32, 3  4128        ['re_lu_70[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 4, 32, 32, 3  0           ['conv3d_112[0][0]',             \n",
      "                                2)                                'conv3d_113[0][0]']             \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 4, 32, 32, 3  0           ['add_18[0][0]']                 \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_114 (Conv3D)            (None, 4, 32, 32, 1  33          ['activation_29[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4, 32, 32, 1  0           ['conv3d_114[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_13 (UpSampling3D  (None, 8, 64, 64, 1  0          ['activation_30[0][0]']          \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_transpose_14 (Conv3DTra  (None, 8, 64, 64, 6  221248     ['re_lu_70[0][0]']               \n",
      " nspose)                        4)                                                                \n",
      "                                                                                                  \n",
      " multiply_13 (Multiply)         (None, 8, 64, 64, 6  0           ['up_sampling3d_13[0][0]',       \n",
      "                                4)                                're_lu_61[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 8, 64, 64, 1  0           ['conv3d_transpose_14[0][0]',    \n",
      "                                28)                               'multiply_13[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_115 (Conv3D)            (None, 8, 64, 64, 6  221184      ['concatenate_13[0][0]']         \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_115[0][0]']             \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_53[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_116 (Conv3D)            (None, 8, 64, 64, 6  110592      ['re_lu_71[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_116[0][0]']             \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_15 (Conv3DTra  (None, 8, 64, 64, 6  8192       ['re_lu_70[0][0]']               \n",
      " nspose)                        4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_54[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_transpose_15[0][0]']    \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 8, 64, 64, 6  0           ['re_lu_72[0][0]',               \n",
      "                                4)                                'batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)                (None, 8, 64, 64, 6  0           ['add_19[0][0]']                 \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_117 (Conv3D)            (None, 8, 64, 64, 1  4112        ['re_lu_58[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_118 (Conv3D)            (None, 8, 64, 64, 1  1040        ['re_lu_73[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 8, 64, 64, 1  0           ['conv3d_117[0][0]',             \n",
      "                                6)                                'conv3d_118[0][0]']             \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 8, 64, 64, 1  0           ['add_20[0][0]']                 \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3d_119 (Conv3D)            (None, 8, 64, 64, 1  17          ['activation_31[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 8, 64, 64, 1  0           ['conv3d_119[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling3d_14 (UpSampling3D  (None, 16, 128, 128  0          ['activation_32[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_16 (Conv3DTra  (None, 16, 128, 128  55328      ['re_lu_73[0][0]']               \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " multiply_14 (Multiply)         (None, 16, 128, 128  0           ['up_sampling3d_14[0][0]',       \n",
      "                                , 32)                             're_lu_58[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 16, 128, 128  0           ['conv3d_transpose_16[0][0]',    \n",
      "                                , 64)                             'multiply_14[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_120 (Conv3D)            (None, 16, 128, 128  55296       ['concatenate_14[0][0]']         \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 16, 128, 128  128        ['conv3d_120[0][0]']             \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_56[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_121 (Conv3D)            (None, 16, 128, 128  27648       ['re_lu_74[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 16, 128, 128  128        ['conv3d_121[0][0]']             \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_17 (Conv3DTra  (None, 16, 128, 128  2048       ['re_lu_73[0][0]']               \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_57[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 16, 128, 128  128        ['conv3d_transpose_17[0][0]']    \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 16, 128, 128  0           ['re_lu_75[0][0]',               \n",
      "                                , 32)                             'batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 16, 128, 128  0           ['add_21[0][0]']                 \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_122 (Conv3D)            (None, 16, 128, 128  1032        ['re_lu_55[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_123 (Conv3D)            (None, 16, 128, 128  264         ['re_lu_76[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 16, 128, 128  0           ['conv3d_122[0][0]',             \n",
      "                                , 8)                              'conv3d_123[0][0]']             \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 16, 128, 128  0           ['add_22[0][0]']                 \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " conv3d_124 (Conv3D)            (None, 16, 128, 128  9           ['activation_33[0][0]']          \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 16, 128, 128  0           ['conv3d_124[0][0]']             \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      " up_sampling3d_15 (UpSampling3D  (None, 32, 256, 256  0          ['activation_34[0][0]']          \n",
      " )                              , 1)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_18 (Conv3DTra  (None, 32, 256, 256  13840      ['re_lu_76[0][0]']               \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " multiply_15 (Multiply)         (None, 32, 256, 256  0           ['up_sampling3d_15[0][0]',       \n",
      "                                , 16)                             're_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 32, 256, 256  0           ['conv3d_transpose_18[0][0]',    \n",
      "                                , 32)                             'multiply_15[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_125 (Conv3D)            (None, 32, 256, 256  13824       ['concatenate_15[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 32, 256, 256  64         ['conv3d_125[0][0]']             \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_59[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_126 (Conv3D)            (None, 32, 256, 256  6912        ['re_lu_77[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 32, 256, 256  64         ['conv3d_126[0][0]']             \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_19 (Conv3DTra  (None, 32, 256, 256  512        ['re_lu_76[0][0]']               \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_78 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_60[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 32, 256, 256  64         ['conv3d_transpose_19[0][0]']    \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 32, 256, 256  0           ['re_lu_78[0][0]',               \n",
      "                                , 16)                             'batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_79 (ReLU)                (None, 32, 256, 256  0           ['add_23[0][0]']                 \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_127 (Conv3D)            (None, 32, 256, 256  3464        ['re_lu_79[0][0]']               \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 32, 256, 256  0           ['conv3d_127[0][0]']             \n",
      "                                , 8)                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,841,620\n",
      "Trainable params: 13,835,700\n",
      "Non-trainable params: 5,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attres_unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "    138/Unknown - 121s 735ms/step - loss: 8.2372 - eval_dice: 0.4465\n",
      "Epoch 1: val_loss improved from inf to 7.14649, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 130s 804ms/step - loss: 8.2372 - eval_dice: 0.4465 - val_loss: 7.1465 - val_eval_dice: 0.0836 - lr: 1.0000e-04\n",
      "Epoch 2/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0778 - eval_dice: 0.0425\n",
      "Epoch 2: val_loss improved from 7.14649 to 7.04666, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 126s 803ms/step - loss: 7.0778 - eval_dice: 0.0425 - val_loss: 7.0467 - val_eval_dice: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 3/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0364 - eval_dice: 0.0174\n",
      "Epoch 3: val_loss improved from 7.04666 to 7.02857, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 121s 770ms/step - loss: 7.0364 - eval_dice: 0.0174 - val_loss: 7.0286 - val_eval_dice: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 4/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.9836 - eval_dice: 0.0155\n",
      "Epoch 4: val_loss improved from 7.02857 to 6.92194, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 119s 756ms/step - loss: 6.9836 - eval_dice: 0.0155 - val_loss: 6.9219 - val_eval_dice: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 5/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.8650 - eval_dice: 0.0106\n",
      "Epoch 5: val_loss improved from 6.92194 to 6.82650, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 119s 756ms/step - loss: 6.8650 - eval_dice: 0.0106 - val_loss: 6.8265 - val_eval_dice: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 6/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.6352 - eval_dice: 0.0068\n",
      "Epoch 6: val_loss improved from 6.82650 to 6.49798, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 119s 756ms/step - loss: 6.6352 - eval_dice: 0.0068 - val_loss: 6.4980 - val_eval_dice: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 7/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.0262 - eval_dice: 0.0051\n",
      "Epoch 7: val_loss improved from 6.49798 to 5.86587, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 123s 785ms/step - loss: 6.0262 - eval_dice: 0.0051 - val_loss: 5.8659 - val_eval_dice: 0.0048 - lr: 1.0000e-04\n",
      "Epoch 8/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.5614 - eval_dice: 0.0044\n",
      "Epoch 8: val_loss improved from 5.86587 to 5.71568, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 127s 809ms/step - loss: 5.5614 - eval_dice: 0.0044 - val_loss: 5.7157 - val_eval_dice: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 9/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.3937 - eval_dice: 0.0041\n",
      "Epoch 9: val_loss improved from 5.71568 to 5.59143, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 126s 802ms/step - loss: 5.3937 - eval_dice: 0.0041 - val_loss: 5.5914 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 10/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2674 - eval_dice: 0.0040\n",
      "Epoch 10: val_loss improved from 5.59143 to 5.50771, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 119s 758ms/step - loss: 5.2674 - eval_dice: 0.0040 - val_loss: 5.5077 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 11/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2074 - eval_dice: 0.0039\n",
      "Epoch 11: val_loss did not improve from 5.50771\n",
      "138/138 [==============================] - 119s 753ms/step - loss: 5.2074 - eval_dice: 0.0039 - val_loss: 5.5258 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 12/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1287 - eval_dice: 0.0038\n",
      "Epoch 12: val_loss did not improve from 5.50771\n",
      "138/138 [==============================] - 123s 783ms/step - loss: 5.1287 - eval_dice: 0.0038 - val_loss: 5.5291 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 13/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0766 - eval_dice: 0.0038\n",
      "Epoch 13: val_loss did not improve from 5.50771\n",
      "138/138 [==============================] - 126s 805ms/step - loss: 5.0766 - eval_dice: 0.0038 - val_loss: 5.5389 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 14/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0217 - eval_dice: 0.0038\n",
      "Epoch 14: val_loss improved from 5.50771 to 5.44371, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 126s 803ms/step - loss: 5.0217 - eval_dice: 0.0038 - val_loss: 5.4437 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 15/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.9123 - eval_dice: 0.0039\n",
      "Epoch 15: val_loss improved from 5.44371 to 5.42085, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 120s 758ms/step - loss: 4.9123 - eval_dice: 0.0039 - val_loss: 5.4208 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 16/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7763 - eval_dice: 0.0039\n",
      "Epoch 16: val_loss improved from 5.42085 to 5.29804, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 120s 763ms/step - loss: 4.7763 - eval_dice: 0.0039 - val_loss: 5.2980 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 17/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6983 - eval_dice: 0.0038\n",
      "Epoch 17: val_loss did not improve from 5.29804\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 4.6983 - eval_dice: 0.0038 - val_loss: 5.3120 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 18/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6139 - eval_dice: 0.0037\n",
      "Epoch 18: val_loss improved from 5.29804 to 5.18134, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 120s 759ms/step - loss: 4.6139 - eval_dice: 0.0037 - val_loss: 5.1813 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 19/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3820 - eval_dice: 0.0036\n",
      "Epoch 19: val_loss improved from 5.18134 to 5.05825, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 120s 759ms/step - loss: 4.3820 - eval_dice: 0.0036 - val_loss: 5.0583 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 20/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3298 - eval_dice: 0.0036\n",
      "Epoch 20: val_loss did not improve from 5.05825\n",
      "138/138 [==============================] - 126s 805ms/step - loss: 4.3298 - eval_dice: 0.0036 - val_loss: 5.1523 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 21/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2929 - eval_dice: 0.0035\n",
      "Epoch 21: val_loss did not improve from 5.05825\n",
      "138/138 [==============================] - 126s 807ms/step - loss: 4.2929 - eval_dice: 0.0035 - val_loss: 5.0896 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 22/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2196 - eval_dice: 0.0035\n",
      "Epoch 22: val_loss improved from 5.05825 to 5.00581, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 125s 793ms/step - loss: 4.2196 - eval_dice: 0.0035 - val_loss: 5.0058 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 23/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0791 - eval_dice: 0.0035\n",
      "Epoch 23: val_loss improved from 5.00581 to 4.94973, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 120s 758ms/step - loss: 4.0791 - eval_dice: 0.0035 - val_loss: 4.9497 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 24/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0085 - eval_dice: 0.0035\n",
      "Epoch 24: val_loss did not improve from 4.94973\n",
      "138/138 [==============================] - 125s 795ms/step - loss: 4.0085 - eval_dice: 0.0035 - val_loss: 4.9653 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 25/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9808 - eval_dice: 0.0034\n",
      "Epoch 25: val_loss improved from 4.94973 to 4.91709, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 127s 813ms/step - loss: 3.9808 - eval_dice: 0.0034 - val_loss: 4.9171 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 26/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9667 - eval_dice: 0.0034\n",
      "Epoch 26: val_loss improved from 4.91709 to 4.88952, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 125s 797ms/step - loss: 3.9667 - eval_dice: 0.0034 - val_loss: 4.8895 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 27/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9496 - eval_dice: 0.0034\n",
      "Epoch 27: val_loss did not improve from 4.88952\n",
      "138/138 [==============================] - 118s 746ms/step - loss: 3.9496 - eval_dice: 0.0034 - val_loss: 4.9150 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 28/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9379 - eval_dice: 0.0034\n",
      "Epoch 28: val_loss improved from 4.88952 to 4.82977, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 118s 750ms/step - loss: 3.9379 - eval_dice: 0.0034 - val_loss: 4.8298 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 29/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9279 - eval_dice: 0.0034\n",
      "Epoch 29: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 751ms/step - loss: 3.9279 - eval_dice: 0.0034 - val_loss: 4.8401 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 30/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9332 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.9332 - eval_dice: 0.0034 - val_loss: 4.9025 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 31/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9298 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.9298 - eval_dice: 0.0034 - val_loss: 4.8735 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 32/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9232 - eval_dice: 0.0033\n",
      "Epoch 32: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.9232 - eval_dice: 0.0033 - val_loss: 4.8497 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 33/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9186 - eval_dice: 0.0033\n",
      "Epoch 33: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 3.9186 - eval_dice: 0.0033 - val_loss: 4.8299 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 34/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9168 - eval_dice: 0.0033\n",
      "Epoch 34: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.9168 - eval_dice: 0.0033 - val_loss: 4.8611 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 35/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9127 - eval_dice: 0.0033\n",
      "Epoch 35: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 3.9127 - eval_dice: 0.0033 - val_loss: 4.8918 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 36/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8978 - eval_dice: 0.0033\n",
      "Epoch 36: val_loss did not improve from 4.82977\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8978 - eval_dice: 0.0033 - val_loss: 4.8375 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 37/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8917 - eval_dice: 0.0033\n",
      "Epoch 37: val_loss improved from 4.82977 to 4.81847, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/BatchNorm/resattunet3d_(2024-07-18)/17.40.20\\cp.ckpt\n",
      "138/138 [==============================] - 120s 759ms/step - loss: 3.8917 - eval_dice: 0.0033 - val_loss: 4.8185 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 38/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8886 - eval_dice: 0.0033\n",
      "Epoch 38: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 3.8886 - eval_dice: 0.0033 - val_loss: 4.8397 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 39/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8867 - eval_dice: 0.0033\n",
      "Epoch 39: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8867 - eval_dice: 0.0033 - val_loss: 4.8270 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 40/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8846 - eval_dice: 0.0033\n",
      "Epoch 40: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 3.8846 - eval_dice: 0.0033 - val_loss: 4.8241 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 41/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8836 - eval_dice: 0.0033\n",
      "Epoch 41: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8836 - eval_dice: 0.0033 - val_loss: 4.8307 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 42/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8836 - eval_dice: 0.0033\n",
      "Epoch 42: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8836 - eval_dice: 0.0033 - val_loss: 4.8256 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 43/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8830 - eval_dice: 0.0033\n",
      "Epoch 43: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 3.8830 - eval_dice: 0.0033 - val_loss: 4.8251 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 44/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8809 - eval_dice: 0.0033\n",
      "Epoch 44: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 3.8809 - eval_dice: 0.0033 - val_loss: 4.8332 - val_eval_dice: 0.0040 - lr: 2.0000e-05\n",
      "Epoch 45/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8799 - eval_dice: 0.0033\n",
      "Epoch 45: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8799 - eval_dice: 0.0033 - val_loss: 4.8257 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 46/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8792 - eval_dice: 0.0033\n",
      "Epoch 46: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8792 - eval_dice: 0.0033 - val_loss: 4.8311 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 47/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8791 - eval_dice: 0.0033\n",
      "Epoch 47: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8791 - eval_dice: 0.0033 - val_loss: 4.8313 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 48/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8785 - eval_dice: 0.0033\n",
      "Epoch 48: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 754ms/step - loss: 3.8785 - eval_dice: 0.0033 - val_loss: 4.8315 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 49/70\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8792 - eval_dice: 0.0033\n",
      "Epoch 49: val_loss did not improve from 4.81847\n",
      "138/138 [==============================] - 119s 755ms/step - loss: 3.8792 - eval_dice: 0.0033 - val_loss: 4.8314 - val_eval_dice: 0.0040 - lr: 4.0000e-06\n",
      "Epoch 49: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1 = attres_unet_model.fit(\n",
    "                train_sagittal,\n",
    "                epochs=70,\n",
    "                validation_data=val_sagittal,\n",
    "                callbacks=callbacks_list  # callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was saved during training, reconstruction must be made with the weights. Reusing the model of training (same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/residualUnet3d-BN(2024-07-19)/00.09.44/cp.ckpt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pratical example file path (log analysis): '**logs/Linear Interpolation/DATASET_SAGITTAL/residual_unet3d_2023-11-20/11.53.28/cp.ckpt**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/unet3d-GN(2024-01-21)/23.44.12/cp.ckpt'\n",
    "#current_model = res_unet_model \n",
    "current_model = attres_unet_model\n",
    "#current_model = unet3d_model\n",
    "#current_model = attunet_model\n",
    "current_file_path = file_path\n",
    "current_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curves (Current fitted model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history1.history\n",
    "#history_dict = history1_unet.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "visualize_learning_curves(epochs,train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold cross validation - Sagittal Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params\n",
    "params['normalization'] =  'groupnorm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_cross_validation(subset_dir, test_subjects,fold_idx, n_folds):\n",
    "    tfrecords_paths = create_subject_tfrpaths(subset_dir,test_subjects)\n",
    "    #subject_paths_array = np.array(subject_paths)\n",
    "\n",
    "    # perform cross-validation\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    folds = list(kf.split(tfrecords_paths))\n",
    "\n",
    "    # get the current fold data\n",
    "    train_indices, val_indices = folds[fold_idx]\n",
    "    train_paths = [tfrecords_paths[i] for i in train_indices]\n",
    "    val_paths = [tfrecords_paths[i] for i in val_indices]\n",
    "\n",
    "    return train_paths, val_paths\n",
    "\n",
    "def train_fold(fold_idx, n_folds, params, tfrecords_dir, test_subjects, batch_size, seed):\n",
    "    data_dir = data_dir = os.path.join(tfrecords_dir,params['subset'])\n",
    "    logs_and_model_path = refactor_path(os.path.join(logs_dir,params['interpolation'],params['subset']))\n",
    "    test_paths = parse_test_tfrecords(data_dir, test_subjects[params['subset']])\n",
    "    \n",
    "    train_paths, val_paths = subset_cross_validation(data_dir, test_subjects[params['subset']], fold_idx, n_folds)\n",
    "    \n",
    "    normalization_params_train = get_norm_params(train_paths,0)\n",
    "    print(f\"Fold {fold_idx + 1}/{n_folds}\")\n",
    "    print(\"Number of training tuple paths:\", len(train_paths))\n",
    "    print(\"Number of validation tuple paths:\", len(val_paths))\n",
    "    print(\"Number of test tuple paths:\", len(test_paths))\n",
    "    print(\"Normalization parameters training:\", normalization_params_train)\n",
    "    print(\"Layer Normalization: \", params['normalization'])\n",
    "    \n",
    "    params['total_train_samples'] = len(train_paths)\n",
    "    params['total_val_samples'] = len(val_paths)\n",
    "    \n",
    "    train_d = train_tfr_fn(train_paths, normalization_params_train, 0, batch_size, seed, params)\n",
    "    val_ds = val_tfr_fn(val_paths, normalization_params_train, batch_size)\n",
    "    \n",
    "    training_session_path = f'Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_{fold_idx + 1}_{datetime.datetime.now().strftime(\"(%Y-%m-%d)/%H.%M.%S\")}'\n",
    "    file_path, callbacks_list = prepareCallbacks(training_session_path, logs_and_model_path)\n",
    "    \n",
    "    features = tf.keras.layers.Input(shape=input_shape[params['subset']])\n",
    "    output = unet3d_mod(yshape[params['subset']][-1], params['mode'], features, params['normalization'])\n",
    "    unet3d_model = tf.keras.Model(inputs=features, outputs=output)\n",
    "    unet3d_model.compile(optimizer=Adam(learning_rate=params['lr']),\n",
    "                         loss=make_loss, \n",
    "                         metrics=['accuracy', eval_dice])\n",
    "    \n",
    "    history = unet3d_model.fit(\n",
    "        train_d,\n",
    "        epochs=100,\n",
    "        validation_data=val_ds, \n",
    "        callbacks=callbacks_list\n",
    "    )    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_cross_val(n_folds, params, resampled_dir, test_subjects,batch_size,seed):\n",
    "    history_reg = []\n",
    "    for fold_id in range(n_folds):\n",
    "        # fold_idx, n_folds, params, log_and_model_path, resampled_dir, test_subjects, batch_size, seed\n",
    "        history = train_fold(fold_id,n_folds, params, resampled_dir, test_subjects, batch_size, seed)\n",
    "        history_reg.append(history)\n",
    "    return history_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Number of training tuple paths: 276\n",
      "Number of validation tuple paths: 69\n",
      "Number of test tuple paths: 84\n",
      "Normalization parameters training: (0.0, 3963.4688)\n",
      "Layer Normalization:  groupnorm\n",
      "Epoch 1/100\n",
      "    138/Unknown - 116s 702ms/step - loss: 7.7649 - accuracy: 0.9151 - eval_dice: 0.3417\n",
      "Epoch 1: val_loss improved from inf to 7.15643, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 129s 793ms/step - loss: 7.7649 - accuracy: 0.9151 - eval_dice: 0.3417 - val_loss: 7.1564 - val_accuracy: 0.9988 - val_eval_dice: 0.0969 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0644 - accuracy: 0.9978 - eval_dice: 0.0593\n",
      "Epoch 2: val_loss improved from 7.15643 to 6.98430, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 122s 766ms/step - loss: 7.0644 - accuracy: 0.9978 - eval_dice: 0.0593 - val_loss: 6.9843 - val_accuracy: 0.9969 - val_eval_dice: 0.0343 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.8496 - accuracy: 0.9956 - eval_dice: 0.0228\n",
      "Epoch 3: val_loss improved from 6.98430 to 6.63632, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 121s 764ms/step - loss: 6.8496 - accuracy: 0.9956 - eval_dice: 0.0228 - val_loss: 6.6363 - val_accuracy: 0.9954 - val_eval_dice: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.2637 - accuracy: 0.9963 - eval_dice: 0.0080\n",
      "Epoch 4: val_loss improved from 6.63632 to 6.15115, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 122s 768ms/step - loss: 6.2637 - accuracy: 0.9963 - eval_dice: 0.0080 - val_loss: 6.1512 - val_accuracy: 0.9975 - val_eval_dice: 0.0054 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.8973 - accuracy: 0.9971 - eval_dice: 0.0053\n",
      "Epoch 5: val_loss improved from 6.15115 to 5.87069, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 120s 760ms/step - loss: 5.8973 - accuracy: 0.9971 - eval_dice: 0.0053 - val_loss: 5.8707 - val_accuracy: 0.9974 - val_eval_dice: 0.0048 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.7257 - accuracy: 0.9975 - eval_dice: 0.0045\n",
      "Epoch 6: val_loss improved from 5.87069 to 5.73294, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 715ms/step - loss: 5.7257 - accuracy: 0.9975 - eval_dice: 0.0045 - val_loss: 5.7329 - val_accuracy: 0.9972 - val_eval_dice: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.6009 - accuracy: 0.9975 - eval_dice: 0.0042\n",
      "Epoch 7: val_loss improved from 5.73294 to 5.72957, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 718ms/step - loss: 5.6009 - accuracy: 0.9975 - eval_dice: 0.0042 - val_loss: 5.7296 - val_accuracy: 0.9972 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.5374 - accuracy: 0.9976 - eval_dice: 0.0040\n",
      "Epoch 8: val_loss did not improve from 5.72957\n",
      "138/138 [==============================] - 113s 702ms/step - loss: 5.5374 - accuracy: 0.9976 - eval_dice: 0.0040 - val_loss: 5.7310 - val_accuracy: 0.9975 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4968 - accuracy: 0.9976 - eval_dice: 0.0039\n",
      "Epoch 9: val_loss improved from 5.72957 to 5.66960, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 113s 706ms/step - loss: 5.4968 - accuracy: 0.9976 - eval_dice: 0.0039 - val_loss: 5.6696 - val_accuracy: 0.9977 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4558 - accuracy: 0.9977 - eval_dice: 0.0038\n",
      "Epoch 10: val_loss did not improve from 5.66960\n",
      "138/138 [==============================] - 114s 709ms/step - loss: 5.4558 - accuracy: 0.9977 - eval_dice: 0.0038 - val_loss: 5.6930 - val_accuracy: 0.9977 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4578 - accuracy: 0.9977 - eval_dice: 0.0039\n",
      "Epoch 11: val_loss improved from 5.66960 to 5.65565, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 715ms/step - loss: 5.4578 - accuracy: 0.9977 - eval_dice: 0.0039 - val_loss: 5.6557 - val_accuracy: 0.9977 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.3360 - accuracy: 0.9977 - eval_dice: 0.0039\n",
      "Epoch 12: val_loss improved from 5.65565 to 5.51932, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 717ms/step - loss: 5.3360 - accuracy: 0.9977 - eval_dice: 0.0039 - val_loss: 5.5193 - val_accuracy: 0.9978 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1964 - accuracy: 0.9975 - eval_dice: 0.0042\n",
      "Epoch 13: val_loss improved from 5.51932 to 5.28604, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 113s 707ms/step - loss: 5.1964 - accuracy: 0.9975 - eval_dice: 0.0042 - val_loss: 5.2860 - val_accuracy: 0.9975 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.9502 - accuracy: 0.9974 - eval_dice: 0.0039\n",
      "Epoch 14: val_loss improved from 5.28604 to 5.24041, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 708ms/step - loss: 4.9502 - accuracy: 0.9974 - eval_dice: 0.0039 - val_loss: 5.2404 - val_accuracy: 0.9975 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8834 - accuracy: 0.9975 - eval_dice: 0.0038\n",
      "Epoch 15: val_loss improved from 5.24041 to 5.21293, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 4.8834 - accuracy: 0.9975 - eval_dice: 0.0038 - val_loss: 5.2129 - val_accuracy: 0.9975 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8457 - accuracy: 0.9975 - eval_dice: 0.0037\n",
      "Epoch 16: val_loss improved from 5.21293 to 5.19297, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 4.8457 - accuracy: 0.9975 - eval_dice: 0.0037 - val_loss: 5.1930 - val_accuracy: 0.9973 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8150 - accuracy: 0.9976 - eval_dice: 0.0037\n",
      "Epoch 17: val_loss improved from 5.19297 to 5.15160, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 4.8150 - accuracy: 0.9976 - eval_dice: 0.0037 - val_loss: 5.1516 - val_accuracy: 0.9974 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7838 - accuracy: 0.9976 - eval_dice: 0.0036\n",
      "Epoch 18: val_loss did not improve from 5.15160\n",
      "138/138 [==============================] - 114s 711ms/step - loss: 4.7838 - accuracy: 0.9976 - eval_dice: 0.0036 - val_loss: 5.1806 - val_accuracy: 0.9976 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7608 - accuracy: 0.9976 - eval_dice: 0.0037\n",
      "Epoch 19: val_loss did not improve from 5.15160\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 4.7608 - accuracy: 0.9976 - eval_dice: 0.0037 - val_loss: 5.1827 - val_accuracy: 0.9976 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7472 - accuracy: 0.9977 - eval_dice: 0.0037\n",
      "Epoch 20: val_loss did not improve from 5.15160\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 4.7472 - accuracy: 0.9977 - eval_dice: 0.0037 - val_loss: 5.1867 - val_accuracy: 0.9976 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7057 - accuracy: 0.9977 - eval_dice: 0.0040\n",
      "Epoch 21: val_loss improved from 5.15160 to 5.00834, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 715ms/step - loss: 4.7057 - accuracy: 0.9977 - eval_dice: 0.0040 - val_loss: 5.0083 - val_accuracy: 0.9975 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4313 - accuracy: 0.9972 - eval_dice: 0.0039\n",
      "Epoch 22: val_loss improved from 5.00834 to 4.86722, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 716ms/step - loss: 4.4313 - accuracy: 0.9972 - eval_dice: 0.0039 - val_loss: 4.8672 - val_accuracy: 0.9970 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3545 - accuracy: 0.9973 - eval_dice: 0.0037\n",
      "Epoch 23: val_loss did not improve from 4.86722\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 4.3545 - accuracy: 0.9973 - eval_dice: 0.0037 - val_loss: 4.8694 - val_accuracy: 0.9973 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3208 - accuracy: 0.9974 - eval_dice: 0.0037\n",
      "Epoch 24: val_loss improved from 4.86722 to 4.79982, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 716ms/step - loss: 4.3208 - accuracy: 0.9974 - eval_dice: 0.0037 - val_loss: 4.7998 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2012 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 25: val_loss improved from 4.79982 to 4.72666, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 716ms/step - loss: 4.2012 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.7267 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1320 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 26: val_loss improved from 4.72666 to 4.68887, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 715ms/step - loss: 4.1320 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6889 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1381 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 27: val_loss improved from 4.68887 to 4.68509, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 715ms/step - loss: 4.1381 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6851 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0308 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 28: val_loss did not improve from 4.68509\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 4.0308 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6857 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9790 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 29: val_loss improved from 4.68509 to 4.64121, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 716ms/step - loss: 3.9790 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6412 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9555 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss did not improve from 4.64121\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.9555 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6451 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9428 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss improved from 4.64121 to 4.63284, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 716ms/step - loss: 3.9428 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6328 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9320 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 32: val_loss improved from 4.63284 to 4.63183, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 715ms/step - loss: 3.9320 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6318 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9258 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 33: val_loss did not improve from 4.63183\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.9258 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6392 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9208 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 34: val_loss improved from 4.63183 to 4.60857, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 114s 715ms/step - loss: 3.9208 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6086 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9136 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 35: val_loss improved from 4.60857 to 4.59856, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 716ms/step - loss: 3.9136 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5986 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9097 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 36: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 711ms/step - loss: 3.9097 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6190 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9153 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 37: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.9153 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6297 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9211 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 38: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.9211 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6476 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9140 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 39: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.9140 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6244 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9182 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 40: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.9182 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6418 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9158 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 41: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.9158 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6088 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9281 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 42: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.9281 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6030 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9267 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 43: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.9267 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6237 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9141 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 44: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.9141 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6030 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9019 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 45: val_loss did not improve from 4.59856\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.9019 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.6140 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8870 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 46: val_loss improved from 4.59856 to 4.58484, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_1_(2024-06-22)/11.04.14\\cp.ckpt\n",
      "138/138 [==============================] - 115s 716ms/step - loss: 3.8870 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5848 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8784 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 47: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.8784 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.6012 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8755 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 48: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.8755 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5954 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8738 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 49: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 712ms/step - loss: 3.8738 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5960 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8728 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 50: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8728 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5985 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8720 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 51: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8720 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5989 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8715 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 52: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8715 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5998 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8710 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 53: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8710 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5972 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8707 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 54: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8707 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5984 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8710 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 55: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8710 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5967 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8711 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 56: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8711 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.6020 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8700 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 57: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8700 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.6008 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 2.5000e-05\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8680 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 58: val_loss did not improve from 4.58484\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 3.8680 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5972 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 2.5000e-05\n",
      "Epoch 58: early stopping\n",
      "Fold 2/5\n",
      "Number of training tuple paths: 276\n",
      "Number of validation tuple paths: 69\n",
      "Number of test tuple paths: 84\n",
      "Normalization parameters training: (0.0, 3893.436)\n",
      "Layer Normalization:  groupnorm\n",
      "Epoch 1/100\n",
      "    138/Unknown - 106s 655ms/step - loss: 8.1653 - accuracy: 0.8352 - eval_dice: 0.4631\n",
      "Epoch 1: val_loss improved from inf to 7.22140, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 118s 743ms/step - loss: 8.1653 - accuracy: 0.8352 - eval_dice: 0.4631 - val_loss: 7.2214 - val_accuracy: 0.9984 - val_eval_dice: 0.1327 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.1192 - accuracy: 0.9988 - eval_dice: 0.0721\n",
      "Epoch 2: val_loss improved from 7.22140 to 7.07152, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 713ms/step - loss: 7.1192 - accuracy: 0.9988 - eval_dice: 0.0721 - val_loss: 7.0715 - val_accuracy: 0.9984 - val_eval_dice: 0.0414 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0171 - accuracy: 0.9983 - eval_dice: 0.0341\n",
      "Epoch 3: val_loss improved from 7.07152 to 6.94231, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 113s 714ms/step - loss: 7.0171 - accuracy: 0.9983 - eval_dice: 0.0341 - val_loss: 6.9423 - val_accuracy: 0.9977 - val_eval_dice: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.8676 - accuracy: 0.9974 - eval_dice: 0.0178\n",
      "Epoch 4: val_loss improved from 6.94231 to 6.76542, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 6.8676 - accuracy: 0.9974 - eval_dice: 0.0178 - val_loss: 6.7654 - val_accuracy: 0.9949 - val_eval_dice: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.4153 - accuracy: 0.9961 - eval_dice: 0.0087\n",
      "Epoch 5: val_loss improved from 6.76542 to 6.08765, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 6.4153 - accuracy: 0.9961 - eval_dice: 0.0087 - val_loss: 6.0876 - val_accuracy: 0.9967 - val_eval_dice: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.7114 - accuracy: 0.9965 - eval_dice: 0.0053\n",
      "Epoch 6: val_loss improved from 6.08765 to 5.69206, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 5.7114 - accuracy: 0.9965 - eval_dice: 0.0053 - val_loss: 5.6921 - val_accuracy: 0.9966 - val_eval_dice: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4439 - accuracy: 0.9970 - eval_dice: 0.0044\n",
      "Epoch 7: val_loss improved from 5.69206 to 5.56876, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 113s 713ms/step - loss: 5.4439 - accuracy: 0.9970 - eval_dice: 0.0044 - val_loss: 5.5688 - val_accuracy: 0.9969 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.3439 - accuracy: 0.9971 - eval_dice: 0.0042\n",
      "Epoch 8: val_loss improved from 5.56876 to 5.52062, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 5.3439 - accuracy: 0.9971 - eval_dice: 0.0042 - val_loss: 5.5206 - val_accuracy: 0.9967 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2703 - accuracy: 0.9973 - eval_dice: 0.0040\n",
      "Epoch 9: val_loss improved from 5.52062 to 5.42324, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 5.2703 - accuracy: 0.9973 - eval_dice: 0.0040 - val_loss: 5.4232 - val_accuracy: 0.9968 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2076 - accuracy: 0.9973 - eval_dice: 0.0039\n",
      "Epoch 10: val_loss did not improve from 5.42324\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 5.2076 - accuracy: 0.9973 - eval_dice: 0.0039 - val_loss: 5.4388 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1647 - accuracy: 0.9974 - eval_dice: 0.0038\n",
      "Epoch 11: val_loss did not improve from 5.42324\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 5.1647 - accuracy: 0.9974 - eval_dice: 0.0038 - val_loss: 5.4987 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1361 - accuracy: 0.9975 - eval_dice: 0.0038\n",
      "Epoch 12: val_loss improved from 5.42324 to 5.39143, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 5.1361 - accuracy: 0.9975 - eval_dice: 0.0038 - val_loss: 5.3914 - val_accuracy: 0.9970 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0298 - accuracy: 0.9975 - eval_dice: 0.0038\n",
      "Epoch 13: val_loss improved from 5.39143 to 5.29468, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 5.0298 - accuracy: 0.9975 - eval_dice: 0.0038 - val_loss: 5.2947 - val_accuracy: 0.9970 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.9319 - accuracy: 0.9974 - eval_dice: 0.0040\n",
      "Epoch 14: val_loss improved from 5.29468 to 5.14806, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 4.9319 - accuracy: 0.9974 - eval_dice: 0.0040 - val_loss: 5.1481 - val_accuracy: 0.9964 - val_eval_dice: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6698 - accuracy: 0.9971 - eval_dice: 0.0041\n",
      "Epoch 15: val_loss improved from 5.14806 to 5.06077, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 113s 713ms/step - loss: 4.6698 - accuracy: 0.9971 - eval_dice: 0.0041 - val_loss: 5.0608 - val_accuracy: 0.9968 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5788 - accuracy: 0.9972 - eval_dice: 0.0039\n",
      "Epoch 16: val_loss improved from 5.06077 to 4.95850, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 4.5788 - accuracy: 0.9972 - eval_dice: 0.0039 - val_loss: 4.9585 - val_accuracy: 0.9968 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5031 - accuracy: 0.9973 - eval_dice: 0.0038\n",
      "Epoch 17: val_loss improved from 4.95850 to 4.92878, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 4.5031 - accuracy: 0.9973 - eval_dice: 0.0038 - val_loss: 4.9288 - val_accuracy: 0.9966 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3376 - accuracy: 0.9973 - eval_dice: 0.0038\n",
      "Epoch 18: val_loss did not improve from 4.92878\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.3376 - accuracy: 0.9973 - eval_dice: 0.0038 - val_loss: 4.9380 - val_accuracy: 0.9967 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2842 - accuracy: 0.9974 - eval_dice: 0.0037\n",
      "Epoch 19: val_loss improved from 4.92878 to 4.87080, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 4.2842 - accuracy: 0.9974 - eval_dice: 0.0037 - val_loss: 4.8708 - val_accuracy: 0.9968 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2459 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 20: val_loss did not improve from 4.87080\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.2459 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.8728 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2189 - accuracy: 0.9975 - eval_dice: 0.0036\n",
      "Epoch 21: val_loss did not improve from 4.87080\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.2189 - accuracy: 0.9975 - eval_dice: 0.0036 - val_loss: 4.8966 - val_accuracy: 0.9970 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2020 - accuracy: 0.9975 - eval_dice: 0.0036\n",
      "Epoch 22: val_loss improved from 4.87080 to 4.85824, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 715ms/step - loss: 4.2020 - accuracy: 0.9975 - eval_dice: 0.0036 - val_loss: 4.8582 - val_accuracy: 0.9968 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1723 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 23: val_loss did not improve from 4.85824\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.1723 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.8597 - val_accuracy: 0.9969 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1558 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 24: val_loss did not improve from 4.85824\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.1558 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.8731 - val_accuracy: 0.9969 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1472 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 25: val_loss did not improve from 4.85824\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.1472 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.9119 - val_accuracy: 0.9969 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1291 - accuracy: 0.9976 - eval_dice: 0.0035\n",
      "Epoch 26: val_loss did not improve from 4.85824\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.1291 - accuracy: 0.9976 - eval_dice: 0.0035 - val_loss: 4.8683 - val_accuracy: 0.9970 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1095 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 27: val_loss did not improve from 4.85824\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.1095 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.8594 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0966 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 28: val_loss did not improve from 4.85824\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.0966 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.8871 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0887 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 29: val_loss improved from 4.85824 to 4.83490, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 721ms/step - loss: 4.0887 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.8349 - val_accuracy: 0.9969 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0788 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss improved from 4.83490 to 4.83396, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 4.0788 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.8340 - val_accuracy: 0.9969 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0694 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss did not improve from 4.83396\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 4.0694 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.8577 - val_accuracy: 0.9970 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0664 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 32: val_loss improved from 4.83396 to 4.83160, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 715ms/step - loss: 4.0664 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.8316 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0429 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 33: val_loss improved from 4.83160 to 4.74277, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 715ms/step - loss: 4.0429 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.7428 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9378 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 34: val_loss improved from 4.74277 to 4.71497, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 3.9378 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.7150 - val_accuracy: 0.9968 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9323 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 35: val_loss did not improve from 4.71497\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9323 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.7432 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9267 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 36: val_loss improved from 4.71497 to 4.71211, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 3.9267 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.7121 - val_accuracy: 0.9968 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9188 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 37: val_loss did not improve from 4.71211\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9188 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.7539 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9352 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 38: val_loss did not improve from 4.71211\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9352 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.7638 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9218 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 39: val_loss did not improve from 4.71211\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9218 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.7337 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9214 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 40: val_loss did not improve from 4.71211\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9214 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.7173 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9070 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 41: val_loss improved from 4.71211 to 4.68731, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 715ms/step - loss: 3.9070 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.6873 - val_accuracy: 0.9969 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9019 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 42: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9019 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.7068 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8943 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 43: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.8943 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6976 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8917 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 44: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8917 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.7327 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8894 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 45: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.8894 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.7227 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8953 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 46: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.8953 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.7532 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9067 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 47: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.9067 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.7608 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9136 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 48: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9136 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.7300 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9014 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 49: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.9014 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.7130 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8969 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 50: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8969 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.7034 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8908 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 51: val_loss did not improve from 4.68731\n",
      "138/138 [==============================] - 113s 712ms/step - loss: 3.8908 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.7287 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8777 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 52: val_loss improved from 4.68731 to 4.67400, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 3.8777 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6740 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8682 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 53: val_loss did not improve from 4.67400\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.8682 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6755 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8652 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 54: val_loss improved from 4.67400 to 4.67205, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 114s 714ms/step - loss: 3.8652 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6721 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8637 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 55: val_loss did not improve from 4.67205\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.8637 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6799 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8627 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 56: val_loss did not improve from 4.67205\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.8627 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6937 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8620 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 57: val_loss did not improve from 4.67205\n",
      "138/138 [==============================] - 113s 711ms/step - loss: 3.8620 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6867 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8615 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 58: val_loss improved from 4.67205 to 4.66749, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 117s 740ms/step - loss: 3.8615 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6675 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8616 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 59: val_loss did not improve from 4.66749\n",
      "138/138 [==============================] - 115s 723ms/step - loss: 3.8616 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6954 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 60/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8615 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 60: val_loss improved from 4.66749 to 4.66547, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 118s 740ms/step - loss: 3.8615 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6655 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 61/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8614 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 61: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 142s 917ms/step - loss: 3.8614 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6773 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 62/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8616 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 62: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 1515s 11s/step - loss: 3.8616 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6827 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 63/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8617 - accuracy: 0.9977 - eval_dice: 0.0033 \n",
      "Epoch 63: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 1437s 10s/step - loss: 3.8617 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6949 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 64/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8622 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 64: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 947s 7s/step - loss: 3.8622 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6797 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 65/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8638 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 65: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.8638 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6707 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 66/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8689 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 66: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.8689 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6851 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 67/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8698 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 67: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 111s 692ms/step - loss: 3.8698 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6930 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 68/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8673 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 68: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 111s 692ms/step - loss: 3.8673 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6869 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 69/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8660 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 69: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.8660 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6820 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 70/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8657 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 70: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.8657 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6843 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 71/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8611 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 71: val_loss did not improve from 4.66547\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8611 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6680 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 2.5000e-05\n",
      "Epoch 72/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8571 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 72: val_loss improved from 4.66547 to 4.66112, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_2_(2024-06-22)/12.55.58\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 3.8571 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6611 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 73/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8556 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 73: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8556 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6741 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 2.5000e-05\n",
      "Epoch 74/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8550 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 74: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8550 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6692 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 75/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8547 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 75: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8547 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6759 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 76/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8545 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 76: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8545 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6718 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 77/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8543 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 77: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8543 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6801 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 2.5000e-05\n",
      "Epoch 78/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8541 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 78: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8541 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6800 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 2.5000e-05\n",
      "Epoch 79/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8541 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 79: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8541 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6626 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 80/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8540 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 80: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8540 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6727 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 81/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8539 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 81: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8539 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6797 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 2.5000e-05\n",
      "Epoch 82/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8543 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 82: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 112s 695ms/step - loss: 3.8543 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6761 - val_accuracy: 0.9970 - val_eval_dice: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 83/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8536 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 83: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.8536 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6751 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 1.2500e-05\n",
      "Epoch 84/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8526 - accuracy: 0.9977 - eval_dice: 0.0033\n",
      "Epoch 84: val_loss did not improve from 4.66112\n",
      "138/138 [==============================] - 204s 1s/step - loss: 3.8526 - accuracy: 0.9977 - eval_dice: 0.0033 - val_loss: 4.6738 - val_accuracy: 0.9971 - val_eval_dice: 0.0039 - lr: 1.2500e-05\n",
      "Epoch 84: early stopping\n",
      "Fold 3/5\n",
      "Number of training tuple paths: 276\n",
      "Number of validation tuple paths: 69\n",
      "Number of test tuple paths: 84\n",
      "Normalization parameters training: (0.0, 3963.4688)\n",
      "Layer Normalization:  groupnorm\n",
      "Epoch 1/100\n",
      "    138/Unknown - 105s 641ms/step - loss: 8.0680 - accuracy: 0.8334 - eval_dice: 0.4274\n",
      "Epoch 1: val_loss improved from inf to 7.20659, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 117s 725ms/step - loss: 8.0680 - accuracy: 0.8334 - eval_dice: 0.4274 - val_loss: 7.2066 - val_accuracy: 0.9988 - val_eval_dice: 0.1264 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0977 - accuracy: 0.9987 - eval_dice: 0.0738\n",
      "Epoch 2: val_loss improved from 7.20659 to 7.01030, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 7.0977 - accuracy: 0.9987 - eval_dice: 0.0738 - val_loss: 7.0103 - val_accuracy: 0.9986 - val_eval_dice: 0.0465 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.9288 - accuracy: 0.9984 - eval_dice: 0.0301\n",
      "Epoch 3: val_loss improved from 7.01030 to 6.85973, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 6.9288 - accuracy: 0.9984 - eval_dice: 0.0301 - val_loss: 6.8597 - val_accuracy: 0.9987 - val_eval_dice: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.7834 - accuracy: 0.9980 - eval_dice: 0.0142\n",
      "Epoch 4: val_loss improved from 6.85973 to 6.74624, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 6.7834 - accuracy: 0.9980 - eval_dice: 0.0142 - val_loss: 6.7462 - val_accuracy: 0.9969 - val_eval_dice: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.4889 - accuracy: 0.9972 - eval_dice: 0.0085\n",
      "Epoch 5: val_loss improved from 6.74624 to 6.20851, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 6.4889 - accuracy: 0.9972 - eval_dice: 0.0085 - val_loss: 6.2085 - val_accuracy: 0.9964 - val_eval_dice: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.7551 - accuracy: 0.9969 - eval_dice: 0.0049\n",
      "Epoch 6: val_loss improved from 6.20851 to 5.56204, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 5.7551 - accuracy: 0.9969 - eval_dice: 0.0049 - val_loss: 5.5620 - val_accuracy: 0.9970 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4072 - accuracy: 0.9972 - eval_dice: 0.0040\n",
      "Epoch 7: val_loss improved from 5.56204 to 5.54322, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 5.4072 - accuracy: 0.9972 - eval_dice: 0.0040 - val_loss: 5.5432 - val_accuracy: 0.9972 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2726 - accuracy: 0.9974 - eval_dice: 0.0038\n",
      "Epoch 8: val_loss improved from 5.54322 to 5.44949, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 5.2726 - accuracy: 0.9974 - eval_dice: 0.0038 - val_loss: 5.4495 - val_accuracy: 0.9972 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.2008 - accuracy: 0.9975 - eval_dice: 0.0037\n",
      "Epoch 9: val_loss improved from 5.44949 to 5.40440, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 5.2008 - accuracy: 0.9975 - eval_dice: 0.0037 - val_loss: 5.4044 - val_accuracy: 0.9974 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1409 - accuracy: 0.9976 - eval_dice: 0.0036\n",
      "Epoch 10: val_loss did not improve from 5.40440\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 5.1409 - accuracy: 0.9976 - eval_dice: 0.0036 - val_loss: 5.4260 - val_accuracy: 0.9975 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1049 - accuracy: 0.9977 - eval_dice: 0.0036\n",
      "Epoch 11: val_loss improved from 5.40440 to 5.37503, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 5.1049 - accuracy: 0.9977 - eval_dice: 0.0036 - val_loss: 5.3750 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.9871 - accuracy: 0.9976 - eval_dice: 0.0038\n",
      "Epoch 12: val_loss improved from 5.37503 to 5.11606, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 4.9871 - accuracy: 0.9976 - eval_dice: 0.0038 - val_loss: 5.1161 - val_accuracy: 0.9971 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7082 - accuracy: 0.9973 - eval_dice: 0.0038\n",
      "Epoch 13: val_loss improved from 5.11606 to 5.05062, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 4.7082 - accuracy: 0.9973 - eval_dice: 0.0038 - val_loss: 5.0506 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6467 - accuracy: 0.9974 - eval_dice: 0.0037\n",
      "Epoch 14: val_loss improved from 5.05062 to 4.98201, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 4.6467 - accuracy: 0.9974 - eval_dice: 0.0037 - val_loss: 4.9820 - val_accuracy: 0.9973 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3938 - accuracy: 0.9972 - eval_dice: 0.0039\n",
      "Epoch 15: val_loss improved from 4.98201 to 4.73310, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 4.3938 - accuracy: 0.9972 - eval_dice: 0.0039 - val_loss: 4.7331 - val_accuracy: 0.9969 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2429 - accuracy: 0.9972 - eval_dice: 0.0037\n",
      "Epoch 16: val_loss improved from 4.73310 to 4.64581, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 4.2429 - accuracy: 0.9972 - eval_dice: 0.0037 - val_loss: 4.6458 - val_accuracy: 0.9970 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1759 - accuracy: 0.9973 - eval_dice: 0.0037\n",
      "Epoch 17: val_loss did not improve from 4.64581\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 4.1759 - accuracy: 0.9973 - eval_dice: 0.0037 - val_loss: 4.6561 - val_accuracy: 0.9970 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1270 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 18: val_loss did not improve from 4.64581\n",
      "138/138 [==============================] - 110s 693ms/step - loss: 4.1270 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.6563 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0872 - accuracy: 0.9974 - eval_dice: 0.0035\n",
      "Epoch 19: val_loss did not improve from 4.64581\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 4.0872 - accuracy: 0.9974 - eval_dice: 0.0035 - val_loss: 4.6498 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0894 - accuracy: 0.9974 - eval_dice: 0.0035\n",
      "Epoch 20: val_loss did not improve from 4.64581\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 4.0894 - accuracy: 0.9974 - eval_dice: 0.0035 - val_loss: 4.6545 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0583 - accuracy: 0.9974 - eval_dice: 0.0035\n",
      "Epoch 21: val_loss did not improve from 4.64581\n",
      "138/138 [==============================] - 110s 694ms/step - loss: 4.0583 - accuracy: 0.9974 - eval_dice: 0.0035 - val_loss: 4.6486 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0338 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 22: val_loss improved from 4.64581 to 4.60846, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 4.0338 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6085 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9534 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 23: val_loss did not improve from 4.60846\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9534 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6395 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9603 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 24: val_loss improved from 4.60846 to 4.57337, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 3.9603 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5734 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9486 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 25: val_loss did not improve from 4.57337\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9486 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5846 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9423 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 26: val_loss improved from 4.57337 to 4.57315, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 3.9423 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5731 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9446 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 27: val_loss improved from 4.57315 to 4.57291, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 3.9446 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5729 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9337 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 28: val_loss did not improve from 4.57291\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9337 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6052 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9231 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 29: val_loss did not improve from 4.57291\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9231 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5898 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9155 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss improved from 4.57291 to 4.57254, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 3.9155 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5725 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9147 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss improved from 4.57254 to 4.56978, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 3.9147 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5698 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9089 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 32: val_loss improved from 4.56978 to 4.55460, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 3.9089 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5546 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9070 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 33: val_loss did not improve from 4.55460\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.9070 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5608 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9026 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 34: val_loss did not improve from 4.55460\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.9026 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5701 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9008 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 35: val_loss did not improve from 4.55460\n",
      "138/138 [==============================] - 110s 694ms/step - loss: 3.9008 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5678 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8977 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 36: val_loss improved from 4.55460 to 4.54532, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 3.8977 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5453 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8967 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 37: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8967 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5494 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9005 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 38: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9005 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5776 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9034 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 39: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9034 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5625 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9121 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 40: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9121 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5784 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9049 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 41: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.9049 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5696 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9055 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 42: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.9055 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6445 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9041 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 43: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 110s 694ms/step - loss: 3.9041 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5710 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8982 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 44: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8982 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5753 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8910 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 45: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8910 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5580 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8895 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 46: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.8895 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5780 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8810 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 47: val_loss did not improve from 4.54532\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8810 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5513 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8697 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 48: val_loss improved from 4.54532 to 4.53560, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_3_(2024-06-22)/16.36.07\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 3.8697 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5356 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8660 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 49: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8660 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5474 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8644 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 50: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 110s 694ms/step - loss: 3.8644 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5463 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8634 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 51: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.8634 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5497 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8628 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 52: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8628 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5472 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8623 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 53: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8623 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5455 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8619 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 54: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.8619 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5420 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8617 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 55: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8617 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5431 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8617 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 56: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 3.8617 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5445 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8618 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 57: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.8618 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5401 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8626 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 58: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8626 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5431 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 59/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8614 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 59: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 112s 694ms/step - loss: 3.8614 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5429 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 2.5000e-05\n",
      "Epoch 60/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8587 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 60: val_loss did not improve from 4.53560\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.8587 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5408 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 2.5000e-05\n",
      "Epoch 60: early stopping\n",
      "Fold 4/5\n",
      "Number of training tuple paths: 276\n",
      "Number of validation tuple paths: 69\n",
      "Number of test tuple paths: 84\n",
      "Normalization parameters training: (0.0, 3963.4688)\n",
      "Layer Normalization:  groupnorm\n",
      "Epoch 1/100\n",
      "    138/Unknown - 105s 637ms/step - loss: 8.3245 - accuracy: 0.7823 - eval_dice: 0.5024\n",
      "Epoch 1: val_loss improved from inf to 7.27421, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 118s 725ms/step - loss: 8.3245 - accuracy: 0.7823 - eval_dice: 0.5024 - val_loss: 7.2742 - val_accuracy: 0.9985 - val_eval_dice: 0.1624 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.1386 - accuracy: 0.9986 - eval_dice: 0.0840\n",
      "Epoch 2: val_loss improved from 7.27421 to 7.07554, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 7.1386 - accuracy: 0.9986 - eval_dice: 0.0840 - val_loss: 7.0755 - val_accuracy: 0.9988 - val_eval_dice: 0.0458 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0419 - accuracy: 0.9986 - eval_dice: 0.0355\n",
      "Epoch 3: val_loss improved from 7.07554 to 6.99073, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 690ms/step - loss: 7.0419 - accuracy: 0.9986 - eval_dice: 0.0355 - val_loss: 6.9907 - val_accuracy: 0.9973 - val_eval_dice: 0.0327 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.9232 - accuracy: 0.9976 - eval_dice: 0.0218\n",
      "Epoch 4: val_loss improved from 6.99073 to 6.88509, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 6.9232 - accuracy: 0.9976 - eval_dice: 0.0218 - val_loss: 6.8851 - val_accuracy: 0.9965 - val_eval_dice: 0.0178 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.6736 - accuracy: 0.9968 - eval_dice: 0.0103\n",
      "Epoch 5: val_loss improved from 6.88509 to 6.42284, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 6.6736 - accuracy: 0.9968 - eval_dice: 0.0103 - val_loss: 6.4228 - val_accuracy: 0.9970 - val_eval_dice: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.0349 - accuracy: 0.9967 - eval_dice: 0.0059\n",
      "Epoch 6: val_loss improved from 6.42284 to 5.79878, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 6.0349 - accuracy: 0.9967 - eval_dice: 0.0059 - val_loss: 5.7988 - val_accuracy: 0.9964 - val_eval_dice: 0.0057 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.4721 - accuracy: 0.9968 - eval_dice: 0.0049\n",
      "Epoch 7: val_loss improved from 5.79878 to 5.27949, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 5.4721 - accuracy: 0.9968 - eval_dice: 0.0049 - val_loss: 5.2795 - val_accuracy: 0.9970 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0701 - accuracy: 0.9967 - eval_dice: 0.0045\n",
      "Epoch 8: val_loss improved from 5.27949 to 5.06323, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 687ms/step - loss: 5.0701 - accuracy: 0.9967 - eval_dice: 0.0045 - val_loss: 5.0632 - val_accuracy: 0.9967 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8737 - accuracy: 0.9969 - eval_dice: 0.0042\n",
      "Epoch 9: val_loss improved from 5.06323 to 4.96396, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 4.8737 - accuracy: 0.9969 - eval_dice: 0.0042 - val_loss: 4.9640 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7673 - accuracy: 0.9970 - eval_dice: 0.0041\n",
      "Epoch 10: val_loss improved from 4.96396 to 4.93758, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 112s 695ms/step - loss: 4.7673 - accuracy: 0.9970 - eval_dice: 0.0041 - val_loss: 4.9376 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6872 - accuracy: 0.9971 - eval_dice: 0.0040\n",
      "Epoch 11: val_loss did not improve from 4.93758\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 4.6872 - accuracy: 0.9971 - eval_dice: 0.0040 - val_loss: 4.9382 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6296 - accuracy: 0.9972 - eval_dice: 0.0039\n",
      "Epoch 12: val_loss improved from 4.93758 to 4.82996, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 4.6296 - accuracy: 0.9972 - eval_dice: 0.0039 - val_loss: 4.8300 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5212 - accuracy: 0.9972 - eval_dice: 0.0039\n",
      "Epoch 13: val_loss did not improve from 4.82996\n",
      "138/138 [==============================] - 110s 688ms/step - loss: 4.5212 - accuracy: 0.9972 - eval_dice: 0.0039 - val_loss: 4.8398 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4599 - accuracy: 0.9972 - eval_dice: 0.0038\n",
      "Epoch 14: val_loss improved from 4.82996 to 4.82948, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 4.4599 - accuracy: 0.9972 - eval_dice: 0.0038 - val_loss: 4.8295 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4143 - accuracy: 0.9973 - eval_dice: 0.0037\n",
      "Epoch 15: val_loss improved from 4.82948 to 4.81471, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 689ms/step - loss: 4.4143 - accuracy: 0.9973 - eval_dice: 0.0037 - val_loss: 4.8147 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3761 - accuracy: 0.9974 - eval_dice: 0.0037\n",
      "Epoch 16: val_loss improved from 4.81471 to 4.80175, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 692ms/step - loss: 4.3761 - accuracy: 0.9974 - eval_dice: 0.0037 - val_loss: 4.8017 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3467 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 17: val_loss improved from 4.80175 to 4.75708, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 689ms/step - loss: 4.3467 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.7571 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2105 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 18: val_loss improved from 4.75708 to 4.69465, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 4.2105 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.6947 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1870 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 19: val_loss did not improve from 4.69465\n",
      "138/138 [==============================] - 111s 690ms/step - loss: 4.1870 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.7238 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1639 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 20: val_loss improved from 4.69465 to 4.68739, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 4.1639 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.6874 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1313 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 21: val_loss improved from 4.68739 to 4.67696, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 692ms/step - loss: 4.1313 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6770 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1121 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 22: val_loss improved from 4.67696 to 4.66685, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 694ms/step - loss: 4.1121 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6669 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1010 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 23: val_loss did not improve from 4.66685\n",
      "138/138 [==============================] - 111s 689ms/step - loss: 4.1010 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.7147 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0947 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 24: val_loss did not improve from 4.66685\n",
      "138/138 [==============================] - 110s 693ms/step - loss: 4.0947 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6955 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9727 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 25: val_loss improved from 4.66685 to 4.57618, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.9727 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5762 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9612 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 26: val_loss did not improve from 4.57618\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 3.9612 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6448 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9589 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 27: val_loss did not improve from 4.57618\n",
      "138/138 [==============================] - 111s 688ms/step - loss: 3.9589 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5811 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9495 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 28: val_loss did not improve from 4.57618\n",
      "138/138 [==============================] - 110s 689ms/step - loss: 3.9495 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5925 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9407 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 29: val_loss did not improve from 4.57618\n",
      "138/138 [==============================] - 110s 685ms/step - loss: 3.9407 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6194 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9319 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss did not improve from 4.57618\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 3.9319 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5792 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9242 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss did not improve from 4.57618\n",
      "138/138 [==============================] - 111s 689ms/step - loss: 3.9242 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6010 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9169 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 32: val_loss did not improve from 4.57618\n",
      "138/138 [==============================] - 110s 690ms/step - loss: 3.9169 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5830 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9189 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 33: val_loss improved from 4.57618 to 4.57029, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 693ms/step - loss: 3.9189 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5703 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9192 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 34: val_loss did not improve from 4.57029\n",
      "138/138 [==============================] - 110s 690ms/step - loss: 3.9192 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5778 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9223 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 35: val_loss did not improve from 4.57029\n",
      "138/138 [==============================] - 111s 692ms/step - loss: 3.9223 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5755 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9271 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 36: val_loss did not improve from 4.57029\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 3.9271 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5770 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9151 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 37: val_loss did not improve from 4.57029\n",
      "138/138 [==============================] - 111s 691ms/step - loss: 3.9151 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5759 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9127 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 38: val_loss improved from 4.57029 to 4.54634, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_4_(2024-06-22)/18.27.48\\cp.ckpt\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 3.9127 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5463 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9159 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 39: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 111s 691ms/step - loss: 3.9159 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5744 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9147 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 40: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 110s 688ms/step - loss: 3.9147 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5909 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9158 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 41: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 110s 688ms/step - loss: 3.9158 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5793 - val_accuracy: 0.9973 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9125 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 42: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 110s 688ms/step - loss: 3.9125 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5900 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9101 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 43: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 111s 690ms/step - loss: 3.9101 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5712 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9070 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 44: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 110s 692ms/step - loss: 3.9070 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5599 - val_accuracy: 0.9974 - val_eval_dice: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9042 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 45: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 112s 687ms/step - loss: 3.9042 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5774 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9051 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 46: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 3.9051 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5760 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9111 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 47: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 111s 691ms/step - loss: 3.9111 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5910 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9127 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 48: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 110s 690ms/step - loss: 3.9127 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5573 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8948 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 49: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 111s 690ms/step - loss: 3.8948 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5479 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8837 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 50: val_loss did not improve from 4.54634\n",
      "138/138 [==============================] - 110s 691ms/step - loss: 3.8837 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5575 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 50: early stopping\n",
      "Fold 5/5\n",
      "Number of training tuple paths: 276\n",
      "Number of validation tuple paths: 69\n",
      "Number of test tuple paths: 84\n",
      "Normalization parameters training: (0.0, 3963.4688)\n",
      "Layer Normalization:  groupnorm\n",
      "Epoch 1/100\n",
      "    138/Unknown - 106s 643ms/step - loss: 8.3615 - accuracy: 0.8023 - eval_dice: 0.5140\n",
      "Epoch 1: val_loss improved from inf to 7.34347, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 118s 726ms/step - loss: 8.3615 - accuracy: 0.8023 - eval_dice: 0.5140 - val_loss: 7.3435 - val_accuracy: 0.9982 - val_eval_dice: 0.1979 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.1698 - accuracy: 0.9985 - eval_dice: 0.1016\n",
      "Epoch 2: val_loss improved from 7.34347 to 7.09029, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 700ms/step - loss: 7.1698 - accuracy: 0.9985 - eval_dice: 0.1016 - val_loss: 7.0903 - val_accuracy: 0.9988 - val_eval_dice: 0.0537 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 7.0652 - accuracy: 0.9987 - eval_dice: 0.0377\n",
      "Epoch 3: val_loss improved from 7.09029 to 7.04826, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 700ms/step - loss: 7.0652 - accuracy: 0.9987 - eval_dice: 0.0377 - val_loss: 7.0483 - val_accuracy: 0.9988 - val_eval_dice: 0.0293 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.9646 - accuracy: 0.9956 - eval_dice: 0.0274\n",
      "Epoch 4: val_loss improved from 7.04826 to 6.86414, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 6.9646 - accuracy: 0.9956 - eval_dice: 0.0274 - val_loss: 6.8641 - val_accuracy: 0.9922 - val_eval_dice: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.7238 - accuracy: 0.9950 - eval_dice: 0.0131\n",
      "Epoch 5: val_loss improved from 6.86414 to 6.56040, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 700ms/step - loss: 6.7238 - accuracy: 0.9950 - eval_dice: 0.0131 - val_loss: 6.5604 - val_accuracy: 0.9959 - val_eval_dice: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 6.3323 - accuracy: 0.9957 - eval_dice: 0.0079\n",
      "Epoch 6: val_loss improved from 6.56040 to 6.16440, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 700ms/step - loss: 6.3323 - accuracy: 0.9957 - eval_dice: 0.0079 - val_loss: 6.1644 - val_accuracy: 0.9961 - val_eval_dice: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.8357 - accuracy: 0.9959 - eval_dice: 0.0060\n",
      "Epoch 7: val_loss improved from 6.16440 to 5.58647, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 698ms/step - loss: 5.8357 - accuracy: 0.9959 - eval_dice: 0.0060 - val_loss: 5.5865 - val_accuracy: 0.9964 - val_eval_dice: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.3673 - accuracy: 0.9965 - eval_dice: 0.0049\n",
      "Epoch 8: val_loss improved from 5.58647 to 5.45728, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 701ms/step - loss: 5.3673 - accuracy: 0.9965 - eval_dice: 0.0049 - val_loss: 5.4573 - val_accuracy: 0.9968 - val_eval_dice: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.1812 - accuracy: 0.9966 - eval_dice: 0.0046\n",
      "Epoch 9: val_loss improved from 5.45728 to 5.25136, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 5.1812 - accuracy: 0.9966 - eval_dice: 0.0046 - val_loss: 5.2514 - val_accuracy: 0.9968 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 5.0449 - accuracy: 0.9968 - eval_dice: 0.0043\n",
      "Epoch 10: val_loss improved from 5.25136 to 5.14192, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 5.0449 - accuracy: 0.9968 - eval_dice: 0.0043 - val_loss: 5.1419 - val_accuracy: 0.9969 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.9655 - accuracy: 0.9969 - eval_dice: 0.0042\n",
      "Epoch 11: val_loss improved from 5.14192 to 5.12862, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 4.9655 - accuracy: 0.9969 - eval_dice: 0.0042 - val_loss: 5.1286 - val_accuracy: 0.9967 - val_eval_dice: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.9164 - accuracy: 0.9970 - eval_dice: 0.0041\n",
      "Epoch 12: val_loss did not improve from 5.12862\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 4.9164 - accuracy: 0.9970 - eval_dice: 0.0041 - val_loss: 5.1398 - val_accuracy: 0.9969 - val_eval_dice: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.8176 - accuracy: 0.9970 - eval_dice: 0.0041\n",
      "Epoch 13: val_loss improved from 5.12862 to 4.97873, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 700ms/step - loss: 4.8176 - accuracy: 0.9970 - eval_dice: 0.0041 - val_loss: 4.9787 - val_accuracy: 0.9968 - val_eval_dice: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.7166 - accuracy: 0.9971 - eval_dice: 0.0040\n",
      "Epoch 14: val_loss improved from 4.97873 to 4.96750, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 4.7166 - accuracy: 0.9971 - eval_dice: 0.0040 - val_loss: 4.9675 - val_accuracy: 0.9970 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6645 - accuracy: 0.9971 - eval_dice: 0.0039\n",
      "Epoch 15: val_loss improved from 4.96750 to 4.94900, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 4.6645 - accuracy: 0.9971 - eval_dice: 0.0039 - val_loss: 4.9490 - val_accuracy: 0.9969 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.6036 - accuracy: 0.9971 - eval_dice: 0.0039\n",
      "Epoch 16: val_loss improved from 4.94900 to 4.85574, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 4.6036 - accuracy: 0.9971 - eval_dice: 0.0039 - val_loss: 4.8557 - val_accuracy: 0.9970 - val_eval_dice: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.5029 - accuracy: 0.9972 - eval_dice: 0.0038\n",
      "Epoch 17: val_loss did not improve from 4.85574\n",
      "138/138 [==============================] - 112s 696ms/step - loss: 4.5029 - accuracy: 0.9972 - eval_dice: 0.0038 - val_loss: 4.8964 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4626 - accuracy: 0.9972 - eval_dice: 0.0038\n",
      "Epoch 18: val_loss did not improve from 4.85574\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 4.4626 - accuracy: 0.9972 - eval_dice: 0.0038 - val_loss: 4.8608 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.4267 - accuracy: 0.9972 - eval_dice: 0.0038\n",
      "Epoch 19: val_loss improved from 4.85574 to 4.81506, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 112s 699ms/step - loss: 4.4267 - accuracy: 0.9972 - eval_dice: 0.0038 - val_loss: 4.8151 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.3585 - accuracy: 0.9973 - eval_dice: 0.0037\n",
      "Epoch 20: val_loss improved from 4.81506 to 4.81456, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 112s 700ms/step - loss: 4.3585 - accuracy: 0.9973 - eval_dice: 0.0037 - val_loss: 4.8146 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.2342 - accuracy: 0.9973 - eval_dice: 0.0037\n",
      "Epoch 21: val_loss improved from 4.81456 to 4.66550, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 112s 700ms/step - loss: 4.2342 - accuracy: 0.9973 - eval_dice: 0.0037 - val_loss: 4.6655 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.1025 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 22: val_loss improved from 4.66550 to 4.65294, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 112s 699ms/step - loss: 4.1025 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.6529 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0875 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 23: val_loss improved from 4.65294 to 4.64665, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 112s 699ms/step - loss: 4.0875 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.6466 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0511 - accuracy: 0.9974 - eval_dice: 0.0036\n",
      "Epoch 24: val_loss improved from 4.64665 to 4.62138, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 112s 699ms/step - loss: 4.0511 - accuracy: 0.9974 - eval_dice: 0.0036 - val_loss: 4.6214 - val_accuracy: 0.9974 - val_eval_dice: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0294 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 25: val_loss did not improve from 4.62138\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 4.0294 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6962 - val_accuracy: 0.9970 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 4.0076 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 26: val_loss improved from 4.62138 to 4.61489, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 112s 699ms/step - loss: 4.0076 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.6149 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9870 - accuracy: 0.9975 - eval_dice: 0.0035\n",
      "Epoch 27: val_loss improved from 4.61489 to 4.57595, saving model to C:/Users/Eduardo/Desktop/dataortho_edu/logs/Linear Interpolation/DATASET_SAGITTAL/Sigma3/GroupNorm/cross_validation/unet3d-GN_fold_5_(2024-06-22)/20.00.41\\cp.ckpt\n",
      "138/138 [==============================] - 111s 699ms/step - loss: 3.9870 - accuracy: 0.9975 - eval_dice: 0.0035 - val_loss: 4.5760 - val_accuracy: 0.9970 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9804 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 28: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.9804 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5854 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9620 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 29: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.9620 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6137 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9528 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 30: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 697ms/step - loss: 3.9528 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6407 - val_accuracy: 0.9971 - val_eval_dice: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9488 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 31: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.9488 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6067 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9412 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 32: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.9412 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6299 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9421 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 33: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 695ms/step - loss: 3.9421 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5896 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9431 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 34: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.9431 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.6177 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9375 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 35: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.9375 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5935 - val_accuracy: 0.9971 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9371 - accuracy: 0.9975 - eval_dice: 0.0034\n",
      "Epoch 36: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.9371 - accuracy: 0.9975 - eval_dice: 0.0034 - val_loss: 4.5762 - val_accuracy: 0.9972 - val_eval_dice: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9241 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 37: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.9241 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.6195 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.9078 - accuracy: 0.9976 - eval_dice: 0.0034\n",
      "Epoch 38: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.9078 - accuracy: 0.9976 - eval_dice: 0.0034 - val_loss: 4.5897 - val_accuracy: 0.9972 - val_eval_dice: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - ETA: 0s - loss: 3.8966 - accuracy: 0.9976 - eval_dice: 0.0033\n",
      "Epoch 39: val_loss did not improve from 4.57595\n",
      "138/138 [==============================] - 111s 696ms/step - loss: 3.8966 - accuracy: 0.9976 - eval_dice: 0.0033 - val_loss: 4.5785 - val_accuracy: 0.9973 - val_eval_dice: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 39: early stopping\n"
     ]
    }
   ],
   "source": [
    "histories = run_kfold_cross_val(n_folds,params,tfrecords_dir,test_subjects,batch_size,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = histories[4].history\n",
    "train_loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "train_accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "visualize_learning_curves(epochs,train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d_38 (Conv3D)             (None, 32, 256, 256  432         ['input_3[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 256, 256  64         ['conv3d_38[0][0]']              \n",
      " alization)                     , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization[0][0]']    \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_39 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_36[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 256, 256  64         ['conv3d_39[0][0]']              \n",
      " rmalization)                   , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_1[0][0]']  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_40 (Conv3D)             (None, 16, 128, 128  13824       ['re_lu_37[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 128, 128  128        ['conv3d_40[0][0]']              \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_2[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_41 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_38[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 128, 128  128        ['conv3d_41[0][0]']              \n",
      " rmalization)                   , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_3[0][0]']  \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_42 (Conv3D)             (None, 8, 64, 64, 6  55296       ['re_lu_39[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 64, 64, 6  256        ['conv3d_42[0][0]']              \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_4[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_43 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_40[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 64, 64, 6  256        ['conv3d_43[0][0]']              \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_5[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_44 (Conv3D)             (None, 4, 32, 32, 1  221184      ['re_lu_41[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 32, 32, 1  512        ['conv3d_44[0][0]']              \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_6[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_45 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_42[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 32, 32, 1  512        ['conv3d_45[0][0]']              \n",
      " rmalization)                   28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_7[0][0]']  \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_46 (Conv3D)             (None, 2, 16, 16, 5  1769472     ['re_lu_43[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2, 16, 16, 5  2048       ['conv3d_46[0][0]']              \n",
      " rmalization)                   12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 2, 16, 16, 5  0           ['batch_normalization_8[0][0]']  \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_47 (Conv3D)             (None, 2, 16, 16, 5  7077888     ['re_lu_44[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2, 16, 16, 5  2048       ['conv3d_47[0][0]']              \n",
      " rmalization)                   12)                                                               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 2, 16, 16, 5  0           ['batch_normalization_9[0][0]']  \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 2, 16, 16, 5  0           ['re_lu_45[0][0]']               \n",
      "                                12)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_8 (Conv3DTran  (None, 4, 32, 32, 1  1769600    ['dropout_2[0][0]']              \n",
      " spose)                         28)                                                               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 4, 32, 32, 2  0           ['conv3d_transpose_8[0][0]',     \n",
      "                                56)                               're_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_48 (Conv3D)             (None, 4, 32, 32, 1  884736      ['concatenate_8[0][0]']          \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_48[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_10[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_49 (Conv3D)             (None, 4, 32, 32, 1  442368      ['re_lu_46[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 4, 32, 32, 1  512        ['conv3d_49[0][0]']              \n",
      " ormalization)                  28)                                                               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 4, 32, 32, 1  0           ['batch_normalization_11[0][0]'] \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_9 (Conv3DTran  (None, 8, 64, 64, 6  221248     ['re_lu_47[0][0]']               \n",
      " spose)                         4)                                                                \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 8, 64, 64, 1  0           ['conv3d_transpose_9[0][0]',     \n",
      "                                28)                               're_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_50 (Conv3D)             (None, 8, 64, 64, 6  221184      ['concatenate_9[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_50[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_12[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_51 (Conv3D)             (None, 8, 64, 64, 6  110592      ['re_lu_48[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 64, 64, 6  256        ['conv3d_51[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 8, 64, 64, 6  0           ['batch_normalization_13[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_transpose_10 (Conv3DTra  (None, 16, 128, 128  55328      ['re_lu_49[0][0]']               \n",
      " nspose)                        , 32)                                                             \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 16, 128, 128  0           ['conv3d_transpose_10[0][0]',    \n",
      "                                , 64)                             're_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_52 (Conv3D)             (None, 16, 128, 128  55296       ['concatenate_10[0][0]']         \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 128, 128  128        ['conv3d_52[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_14[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_53 (Conv3D)             (None, 16, 128, 128  27648       ['re_lu_50[0][0]']               \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 128, 128  128        ['conv3d_53[0][0]']              \n",
      " ormalization)                  , 32)                                                             \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 16, 128, 128  0           ['batch_normalization_15[0][0]'] \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_transpose_11 (Conv3DTra  (None, 32, 256, 256  13840      ['re_lu_51[0][0]']               \n",
      " nspose)                        , 16)                                                             \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 32, 256, 256  0           ['conv3d_transpose_11[0][0]',    \n",
      "                                , 32)                             're_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_54 (Conv3D)             (None, 32, 256, 256  13824       ['concatenate_11[0][0]']         \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 32, 256, 256  64         ['conv3d_54[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_16[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_55 (Conv3D)             (None, 32, 256, 256  6912        ['re_lu_52[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 256, 256  64         ['conv3d_55[0][0]']              \n",
      " ormalization)                  , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 32, 256, 256  0           ['batch_normalization_17[0][0]'] \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_56 (Conv3D)             (None, 32, 256, 256  2165        ['re_lu_53[0][0]']               \n",
      "                                , 5)                                                              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 256, 256  0           ['conv3d_56[0][0]']              \n",
      "                                , 5)                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,558,293\n",
      "Trainable params: 13,554,325\n",
      "Non-trainable params: 3,968\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def _normalization(inputs, name, mode):\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    if name == 'instancenorm':\n",
    "        return tf.keras.layers.LayerNormalization(\n",
    "            axis=[1, 2, 3],  # Normalizing across the spatial dimensions\n",
    "            center=True,\n",
    "            scale=True,\n",
    "            epsilon=1e-6)(inputs)\n",
    "\n",
    "    if name == 'groupnorm':\n",
    "        return tfa.layers.GroupNormalization(\n",
    "            groups=16,\n",
    "            axis=-1,  # Channel axis\n",
    "            epsilon=1e-5)(inputs)\n",
    "\n",
    "    if name == 'batchnorm':\n",
    "        return tf.keras.layers.BatchNormalization(axis=-1, #channels index is the last one\n",
    "                                                  trainable=True,\n",
    "                                                  virtual_batch_size=None)(inputs, training=training)\n",
    "    if name == 'none':\n",
    "        return inputs\n",
    "\n",
    "    raise ValueError('Invalid normalization layer')\n",
    "\n",
    "def _activation(out, activation):\n",
    "    if activation == 'relu':\n",
    "        return tf.keras.layers.ReLU()(out)\n",
    "    if activation == 'leaky_relu':\n",
    "        return tf.keras.layers.LeakyReLU(alpha=0.01)(out)\n",
    "    if activation == 'sigmoid':\n",
    "        return tf.keras.layers.Activation('sigmoid')(out)\n",
    "    if activation == 'softmax':\n",
    "        return tf.keras.layers.Activation('softmax')(out)\n",
    "    if activation == 'none':\n",
    "        return out\n",
    "\n",
    "    raise ValueError(\"Unknown activation {}\".format(activation))\n",
    "\n",
    "def convolution(inputs,  \n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                normalization='batchnorm',\n",
    "                activation='relu',\n",
    "                transpose=False):\n",
    "\n",
    "    if transpose:\n",
    "        conv = tf.keras.layers.Conv3DTranspose\n",
    "    else:\n",
    "        conv = tf.keras.layers.Conv3D\n",
    "    regularizer = None #tf.keras.regularizers.l2(1e-5) # trying L2 Regularization\n",
    "\n",
    "    use_bias = normalization == \"none\"\n",
    "    inputs = conv(filters=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=stride,\n",
    "                  activation=None,\n",
    "                  padding='same',\n",
    "                  data_format='channels_last',\n",
    "                  kernel_initializer=tf.compat.v1.initializers.he_uniform(), # use HE with ReLU\n",
    "                  kernel_regularizer=regularizer,\n",
    "                  bias_initializer='zeros',\n",
    "                  bias_regularizer=regularizer,\n",
    "                  use_bias=use_bias)(inputs)\n",
    "    \n",
    "    # batch normalization before each activation\n",
    "    inputs = _normalization(inputs, normalization, mode)\n",
    "    return _activation(inputs, activation)\n",
    "\n",
    "def input_block(inputs, out_channels, normalization, mode):\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    return inputs\n",
    "\n",
    "def downsample_block(inputs, out_channels, normalization, mode):\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode, stride=2)\n",
    "    return convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "\n",
    "def upsample_block(inputs, skip_connection, out_channels, normalization, mode):\n",
    "    inputs = convolution(inputs, kernel_size=3, out_channels=out_channels, stride=2,\n",
    "                         normalization='none', activation='none', transpose=True)\n",
    "\n",
    "    inputs = tf.keras.layers.Concatenate(axis=-1)([inputs, skip_connection])\n",
    "    \n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    inputs = convolution(inputs, out_channels=out_channels, normalization=normalization, mode=mode)\n",
    "    return inputs\n",
    "\n",
    "def output_layer(inputs, out_channels, activation):\n",
    "    return convolution(inputs, out_channels=out_channels, kernel_size=3, normalization='none', activation=activation)\n",
    "\n",
    "def unet3d_mod(n_classes, mode, features, normalization='none'):\n",
    "\n",
    "    skip_1 = input_block(inputs=features,\n",
    "                         out_channels=16,\n",
    "                         normalization=normalization,\n",
    "                         mode=mode)\n",
    "\n",
    "    skip_2 = downsample_block(inputs=skip_1,\n",
    "                              out_channels=32,\n",
    "                              normalization=normalization,\n",
    "                              mode=mode)\n",
    "\n",
    "    skip_3 = downsample_block(inputs=skip_2,\n",
    "                              out_channels=64,\n",
    "                              normalization=normalization,\n",
    "                              mode=mode)\n",
    "\n",
    "    skip_4 = downsample_block(inputs=skip_3,\n",
    "                              out_channels=128,\n",
    "                              normalization=normalization,\n",
    "                              mode=mode)\n",
    "    # Bridge\n",
    "    out = downsample_block(inputs=skip_4,\n",
    "                           out_channels=512,\n",
    "                           normalization=normalization,\n",
    "                           mode=mode)\n",
    "\n",
    "    out = tf.keras.layers.Dropout(0.5)(out)\n",
    "\n",
    "    out = upsample_block(out, skip_4,\n",
    "                         out_channels=128,\n",
    "                         normalization=normalization,\n",
    "                         mode=mode)\n",
    "\n",
    "    out = upsample_block(out, skip_3,\n",
    "                         out_channels=64,\n",
    "                         normalization=normalization,\n",
    "                         mode=mode)\n",
    "\n",
    "    out = upsample_block(out, skip_2,\n",
    "                         out_channels=32,\n",
    "                         normalization=normalization,\n",
    "                         mode=mode)\n",
    "\n",
    "    out = upsample_block(out, skip_1,\n",
    "                         out_channels=16,\n",
    "                         normalization=normalization,\n",
    "                         mode=mode)\n",
    "\n",
    "    return output_layer(out,\n",
    "                        out_channels=n_classes,\n",
    "                        activation='softmax')\n",
    "\n",
    "# Example usage\n",
    "inputs = tf.keras.Input(shape=(32, 256, 256, 1))\n",
    "model = tf.keras.Model(inputs, unet3d_mod(n_classes=5, mode=tf.estimator.ModeKeys.TRAIN, features=inputs, normalization='batchnorm'))\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
